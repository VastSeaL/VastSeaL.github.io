

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="John Doe">
  <meta name="keywords" content="">
  
    <meta name="description" content="PythonPython内置函数enumerate()函数enumerate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标，一般用在 for 循环当中。 1enumerate(sequence, [start&#x3D;0])  参数 sequence – 一个序列、迭代器或其他支持迭代对象。 start – 下标起始位置的值。  返回值返回 enum">
<meta property="og:type" content="article">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="PythonPython内置函数enumerate()函数enumerate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标，一般用在 for 循环当中。 1enumerate(sequence, [start&#x3D;0])  参数 sequence – 一个序列、迭代器或其他支持迭代对象。 start – 下标起始位置的值。  返回值返回 enum">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/%E7%B1%BB%E7%9A%84%E4%B8%93%E6%9C%89%E6%96%B9%E6%B3%95">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/%E5%87%B8%E5%87%BD%E6%95%B0">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/%E9%9E%8D%E7%82%B9.jpj">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/%E6%8C%87%E6%95%B0%E5%8A%A0%E6%9D%83%E5%9D%87%E5%80%BC">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D.pnj">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/Batch">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD.pnj">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/fanxiangchuanbo.pnj">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/%E6%B1%82%E6%A2%AF%E5%BA%A6.pnj">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/tensor.pnj">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/pytorch%E5%AE%9E%E7%8E%B0">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/%E5%B9%BF%E6%92%AD%E6%9C%BA%E5%88%B6">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/%E4%BB%BF%E5%B0%84%E6%A8%A1%E5%9E%8B.pnj">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/nn_linear.pnj">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B.pnj">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/minist">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/logistic">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/BCE">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/shuffle">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/softmax">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/NLLLoss">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/CNN">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/Convolution">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/MaxPooling">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/concatenate">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/batch_first1">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/batch_first2">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/Dataset">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/Dataset2">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/Tensor">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/transpose">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/squeezw">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/unsqueeze">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/cat">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/device">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/optim">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/optim2">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/notice">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/chainrule">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/backpropagation">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/Backpropagation2">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/backpropagation3">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220164830103.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220165823191.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230216153209267.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230216153429112.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230216155931419.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230216160817270.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230216161736917.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230216162028665.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230216162441172.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230216163421455.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217162531424.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217163405067.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217163545349.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217163840304.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217164009238.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217164404659.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217164553921.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217164710202.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217164849894.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217165040061.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217165245444.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217170146204.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217170342996.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222150042220.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222150507570.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217170703851.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217174738922.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217175230940.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217175445395.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217175935273.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217185855119.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217190539102.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217190851402.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217192854428.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217194431309.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217195204374.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217200343404.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217200535811.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217200708347.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217201131973.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217201303403.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217201537450.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217202010268.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219103610912.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219104510420.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219104723217.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219105222073.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219105414500.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219105807737.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219110213837.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219110527256.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219110610162.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219113320260.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219173231485.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219173402903.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219173520988.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219174817789.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219175650535.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219175745769.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219182432823.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219182959481.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219184733050.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219184845319.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219185255264.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219185732554.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219185906756.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220151750842.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220152751776.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220153041140.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220153440025.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220154709135.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220154902836.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220155117699.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220160235068.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220161633898.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220162817076.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220163803033.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220163905897.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220164300905.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220164324808.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219113538883.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219114058621.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219113906542.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219114343052.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219134611063.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219140424624.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219140828795.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219141400722.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219142322281.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219143624556.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219143741645.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219144104393.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219150624632.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219150949584.png">
<meta property="og:image" content="d:\%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD\photo\pytorch md\image-20230219151206774.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219151432675.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219151632461.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219151824419.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219151902001.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219151916700.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219152147020.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219152515395.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219152656072.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219153140826.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219153347413.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222151535069.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222151614261.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222151643870.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222152253769.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222152423524.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222152447853.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222153444309.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222154525682.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222154753511.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222155100307.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222155207551.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222155229862.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230221190847727.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230221191148146.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222133926254.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222134324377.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222134630110.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222135225522.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222135722131.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222135846875.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222140105874.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222140225472.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222140412998.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222140504306.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222140728856.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222140813030.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222140957944.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222141306342.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222141343778.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222141401887.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222142228736.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222143015795.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222143054258.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222143303706.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222143421544.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222143633013.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222162327297.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222163100727.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222163346290.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222163816076.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222164539375.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222164711179.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222164815484.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222165047469.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222170141809.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222170814869.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223161320964.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223162805885.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223163103560.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223163644962.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223164116773.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223164432190.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223164858274.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223165123881.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223165253237.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223165405133.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223170452941.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223170706124.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223170837944.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223173855690.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223180959958.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223181544814.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230224163731902.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230224164123140.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230224164758954.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230224164821859.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230224165938999.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230224170054154.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230224170251429.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230224171004645.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230224171217528.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230224171522251.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230224174602637.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227155038921.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227155812871.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227161036092.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227161214393.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227161430915.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227161633916.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227162251395.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227162444796.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227162752928.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227163049571.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227163128433.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227163638822.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227164502837.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227164543048.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227164613934.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227164942378.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227172155132.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227172136198.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227172326858.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227172435027.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227172633979.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227173058847.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227173605771.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227174638919.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227175224594.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227175551056.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227175834055.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227175849100.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227180202579.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227180222407.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227180355433.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227180413220.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824094358392.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824094857191.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824094637898.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824094806665.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824095157640.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824095752464.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824100037972.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824100110111.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824100146747.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824100319375.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824100517783.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824101358392.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824101956681.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824102122860.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824102428705.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824102900519.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824102825524.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824103223033.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824103345925.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824103442370.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824103522067.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824105847788.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824110021184.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824110158861.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824110322220.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824110554974.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824111209049.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824112210517.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824112329435.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226104124832.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226104007327.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226104721560.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226104935859.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226105226151.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226105254442.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226105619749.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226105830567.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226110917675.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226111349311.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226111523076.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226111542936.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226120807141.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226114520352.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226114631545.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226114703556.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226115110295.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226115738607.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226115959555.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226120051473.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226120145462.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226121013255.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226121054634.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227142225440.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227142303877.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227142315802.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227142519206.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227142537156.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227142630739.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227142737083.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227142843045.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227142906032.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227143253075.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227143441165.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227143456890.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227143706330.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227144034589.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227144248632.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227144501296.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227144542973.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227144840761.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227145007530.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227145101111.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227145328425.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227145525543.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227145849416.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227145913631.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227150907748.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227151307970.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227151710565.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227152337680.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227152453643.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227152656466.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230825155356180.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230825155510200.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230825155754620.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230825155841487.png">
<meta property="og:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230825160140398.png">
<meta property="article:published_time" content="2024-10-06T07:41:41.880Z">
<meta property="article:modified_time" content="2024-10-06T08:39:51.091Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://example.com/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/%E7%B1%BB%E7%9A%84%E4%B8%93%E6%9C%89%E6%96%B9%E6%B3%95">
  
  
  
  <title>Hexo</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.7","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 7.0.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Fluid</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>Home</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>Archives</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>Categories</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>Tags</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>About</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text=""></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-10-06 15:41" pubdate>
          October 6, 2024 pm
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          5.8k words
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          49 mins
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header"></h1>
            
            
              <div class="markdown-body">
                
                <h1 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h1><h1 id="Python内置函数"><a href="#Python内置函数" class="headerlink" title="Python内置函数"></a>Python内置函数</h1><h3 id="enumerate-函数"><a href="#enumerate-函数" class="headerlink" title="enumerate()函数"></a>enumerate()函数</h3><p>enumerate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标，一般用在 for 循环当中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">enumerate</span>(sequence, [start=<span class="hljs-number">0</span>])<br></code></pre></td></tr></table></figure>

<h3 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h3><ul>
<li>sequence – 一个序列、迭代器或其他支持迭代对象。</li>
<li>start – 下标起始位置的值。</li>
</ul>
<h3 id="返回值"><a href="#返回值" class="headerlink" title="返回值"></a>返回值</h3><p>返回 enumerate(枚举) 对象。</p>
<h1 id="Python面向对象"><a href="#Python面向对象" class="headerlink" title="Python面向对象"></a>Python面向对象</h1><h2 id="类-class"><a href="#类-class" class="headerlink" title="类(class):"></a><strong>类(class)</strong>:</h2><p>用来描述具有相同属性和方法的集合。定义了该集合中每个对象所共有的属性和方法。<strong>对象是类的实例。</strong></p>
<p>###类对象</p>
<p>类对象支持两种操作：属性引用和实例化。</p>
<p>属性引用使用和 Python 中所有的属性引用一样的标准语法：<strong>obj.name</strong>。</p>
<p>类对象创建后，类命名空间中所有的命名都是有效属性名。所以如果类定义是这样:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyClass</span>:<br>    <span class="hljs-string">&quot;&quot;&quot;一个简单的类实例&quot;&quot;&quot;</span><br>    i = <span class="hljs-number">12345</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">f</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;hello world&#x27;</span><br> <br><span class="hljs-comment"># 实例化类</span><br>x = MyClass()<br> <br><span class="hljs-comment"># 访问类的属性和方法</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;MyClass 类的属性 i 为：&quot;</span>, x.i)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;MyClass 类的方法 f 输出为：&quot;</span>, x.f())<br></code></pre></td></tr></table></figure>

<p>##类属性与方法</p>
<p><strong>类的私有属性：</strong><strong>__private_attrs</strong>：两个下划线开头，声明该属性为私有，不能在类的外部被使用或直接访问。在类内部的方法中使用时 <strong>self.__private_attrs</strong>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">JustCounter</span>:<br>    __secretCount = <span class="hljs-number">0</span>  <span class="hljs-comment"># 私有变量</span><br>    publicCount = <span class="hljs-number">0</span>    <span class="hljs-comment"># 公开变量</span><br> <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">count</span>(<span class="hljs-params">self</span>):<br>        self.__secretCount += <span class="hljs-number">1</span><br>        self.publicCount += <span class="hljs-number">1</span><br>        <span class="hljs-built_in">print</span> (self.__secretCount)<br> <br>counter = JustCounter()<br>counter.count()<br>counter.count()<br><span class="hljs-built_in">print</span> (counter.publicCount)<br><span class="hljs-built_in">print</span> (counter.__secretCount)  <span class="hljs-comment"># 报错，实例不能访问私有变量</span><br></code></pre></td></tr></table></figure>

<p>###<strong>类的方法：</strong></p>
<p>在类的内部，使用 def 关键字来定义一个方法，与一般函数定义不同，类方法必须包含参数 <strong>self</strong>，且为第一个参数，<strong>self</strong> 代表的是类的实例。</p>
<p><strong>self</strong> 的名字并不是规定死的，也可以使用 <strong>this</strong>，但是最好还是按照约定使用 <strong>self</strong>。</p>
<h3 id="类的私有方法"><a href="#类的私有方法" class="headerlink" title="类的私有方法"></a>类的私有方法</h3><p><strong>__private_method</strong>：两个下划线开头，声明该方法为私有方法，只能在类的内部调用 ，不能在类的外部调用。<strong>self.__private_methods</strong>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Site</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, name, url</span>):<br>        self.name = name       <span class="hljs-comment"># public</span><br>        self.__url = url   <span class="hljs-comment"># private</span><br> <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">who</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;name  : &#x27;</span>, self.name)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;url : &#x27;</span>, self.__url)<br> <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__foo</span>(<span class="hljs-params">self</span>):          <span class="hljs-comment"># 私有方法</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;这是私有方法&#x27;</span>)<br> <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">foo</span>(<span class="hljs-params">self</span>):            <span class="hljs-comment"># 公共方法</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;这是公共方法&#x27;</span>)<br>        self.__foo()<br> <br>x = Site(<span class="hljs-string">&#x27;菜鸟教程&#x27;</span>, <span class="hljs-string">&#x27;www.runoob.com&#x27;</span>)<br>x.who()        <span class="hljs-comment"># 正常输出</span><br>x.foo()        <span class="hljs-comment"># 正常输出</span><br>x.__foo()      <span class="hljs-comment"># 报错</span><br></code></pre></td></tr></table></figure>

<p>###类的专有方法</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/%E7%B1%BB%E7%9A%84%E4%B8%93%E6%9C%89%E6%96%B9%E6%B3%95" srcset="/img/loading.gif" lazyload alt="image-20221206143413965"></p>
<h2 id="方法："><a href="#方法：" class="headerlink" title="方法："></a><strong>方法</strong>：</h2><p>类中定义的函数。</p>
<ul>
<li><p>类有一个名为  __ init __() 的特殊方法（<strong>构造方法</strong>），该方法在类实例化时会自动调用,</p>
<ul>
<li><p>_ _ init_ <em>() 方法可以有参数，参数通过 _ <em>init</em></em> _() 传递到类的实例化操作上</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Complex</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, realpart, imagpart</span>):<br>        self.r = realpart<br>        self.i = imagpart<br>x = Complex(<span class="hljs-number">3.0</span>, -<span class="hljs-number">4.5</span>)<br><span class="hljs-built_in">print</span>(x.r, x.i)   <span class="hljs-comment"># 输出结果：3.0-4.5</span><br></code></pre></td></tr></table></figure>
</li>
<li><h3 id="self代表类的实例，而非类"><a href="#self代表类的实例，而非类" class="headerlink" title="self代表类的实例，而非类"></a>self代表类的实例，而非类</h3><ul>
<li>类的方法与普通的函数只有一个特别的区别——它们必须有一个额外的<strong>第一个参数名称</strong>, 按照惯例它的名称是 self.</li>
<li>self 代表的是类的实例，代表当前对象的地址，而 self.class 则指向类。</li>
<li>self 不是 python 关键字，我们把他换成 runoob 也是可以正常执行的</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Test</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">prt</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(self)<br>        <span class="hljs-built_in">print</span>(self.__class__)<br> <br>t = Test()<br>t.prt()<br></code></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>类的方法：在类的内部，使用 <strong>def</strong> 关键字来定义一个方法，与一般函数定义不同，类方法必须包含参数 self, 且为第一个参数，self 代表的是类的实例。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs 1">#类定义<br>class people:<br>    #定义基本属性<br>    name = &#x27;&#x27;<br>    age = 0<br>    #定义私有属性,私有属性在类外部无法直接进行访问<br>    __weight = 0<br>    #定义构造方法<br>    def __init__(self,n,a,w):<br>        self.name = n<br>        self.age = a<br>        self.__weight = w<br>    def speak(self):<br>        print(&quot;%s 说: 我 %d 岁。&quot; %(self.name,self.age))<br> <br># 实例化类<br>p = people(&#x27;runoob&#x27;,10,30)<br>p.speak()<br></code></pre></td></tr></table></figure></li>
</ul>
<p>##<strong>类变量：</strong></p>
<p>类变量在整个实例化的对象中是公用的。类变量定义在类中且在函数体之外。类变量通常不作为实例变量使用。</p>
<p>##<strong>数据成员：</strong></p>
<p>类变量或者实例变量用于处理类及其实例对象的相关的数据。</p>
<p>##<strong>方法重写：</strong></p>
<p>如果从父类继承的方法不能满足子类的需求，可以对其进行改写，这个过程叫方法的覆盖（override），也称为方法的重写。</p>
<ul>
<li><pre><code class="python">class Parent:        # 定义父类
   def myMethod(self):
      print (&#39;调用父类方法&#39;)
 
class Child(Parent): # 定义子类
   def myMethod(self):
      print (&#39;调用子类方法&#39;)
 
c = Child()          # 子类实例
c.myMethod()         # 子类调用重写方法
super(Child,c).myMethod() #用子类对象调用父类已被覆盖的方法
<figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs clean"><br>  [super() 函数](https:<span class="hljs-comment">//www.runoob.com/python/python-func-super.html)是用于调用父类(超类)的一个方法。</span><br><br>##**局部变量：**<br><br>定义在方法中的变量，只作用于当前实例的类。<br><br>##**实例变量：**<br><br>在类的声明中，属性是用变量来表示的，这种变量就称为实例变量，实例变量就是一个用 self 修饰的变量。<br><br>##**继承：**<br><br>即一个派生类（derived <span class="hljs-keyword">class</span>）继承基类（base <span class="hljs-keyword">class</span>）的字段和方法。继承也允许把一个派生类的对象作为一个基类对象对待。例如，有这样一个设计：一个Dog类型的对象派生自Animal类，这是模拟<span class="hljs-string">&quot;是一个（is-a）&quot;</span>关系（例图，Dog是一个Animal）。<br><br>- 派生类<br><br>  ```python<br>  <span class="hljs-keyword">class</span> DerivedClassName(BaseClassName):<br>      &lt;statement<span class="hljs-number">-1</span>&gt;<br>      .<br>      .<br>      .<br>      &lt;statement-N&gt;<br></code></pre></td></tr></table></figure>

子类（派生类 DerivedClassName）会继承父类（基类 BaseClassName）的属性和方法。

BaseClassName（实例中的基类名）必须与派生类定义在一个作用域内。除了类，还可以用表达式，基类定义在另一个模块中时这一点非常有用:

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">DerivedClassName</span>(modname.BaseClassName):<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#类定义</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">people</span>:<br>    <span class="hljs-comment">#定义基本属性</span><br>    name = <span class="hljs-string">&#x27;&#x27;</span><br>    age = <span class="hljs-number">0</span><br>    <span class="hljs-comment">#定义私有属性,私有属性在类外部无法直接进行访问</span><br>    __weight = <span class="hljs-number">0</span><br>    <span class="hljs-comment">#定义构造方法</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,n,a,w</span>):<br>        self.name = n<br>        self.age = a<br>        self.__weight = w<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">speak</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;%s 说: 我 %d 岁。&quot;</span> %(self.name,self.age))<br> <br><span class="hljs-comment">#单继承示例</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">student</span>(<span class="hljs-title class_ inherited__">people</span>):<br>    grade = <span class="hljs-string">&#x27;&#x27;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,n,a,w,g</span>):<br>        <span class="hljs-comment">#调用父类的构函</span><br>        people.__init__(self,n,a,w)<br>        self.grade = g<br>    <span class="hljs-comment">#覆写父类的方法</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">speak</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;%s 说: 我 %d 岁了，我在读 %d 年级&quot;</span>%(self.name,self.age,self.grade))<br> <br> <br> <br>s = student(<span class="hljs-string">&#x27;ken&#x27;</span>,<span class="hljs-number">10</span>,<span class="hljs-number">60</span>,<span class="hljs-number">3</span>)<br>s.speak()<br></code></pre></td></tr></table></figure>
</code></pre>
</li>
<li><p>多继承</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">DerivedClassName</span>(Base1, Base2, Base3):<br>    &lt;statement-<span class="hljs-number">1</span>&gt;<br>    .<br>    .<br>    .<br>    &lt;statement-N&gt;<br></code></pre></td></tr></table></figure>

<p>需要注意圆括号中父类的顺序，若是父类中有相同的方法名，而在子类使用时未指定，python从左至右搜索 即方法在子类中未找到时，从左到右查找父类中是否包含方法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#类定义</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">people</span>:<br>    <span class="hljs-comment">#定义基本属性</span><br>    name = <span class="hljs-string">&#x27;&#x27;</span><br>    age = <span class="hljs-number">0</span><br>    <span class="hljs-comment">#定义私有属性,私有属性在类外部无法直接进行访问</span><br>    __weight = <span class="hljs-number">0</span><br>    <span class="hljs-comment">#定义构造方法</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,n,a,w</span>):<br>        self.name = n<br>        self.age = a<br>        self.__weight = w<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">speak</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;%s 说: 我 %d 岁。&quot;</span> %(self.name,self.age))<br> <br><span class="hljs-comment">#单继承示例</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">student</span>(<span class="hljs-title class_ inherited__">people</span>):<br>    grade = <span class="hljs-string">&#x27;&#x27;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,n,a,w,g</span>):<br>        <span class="hljs-comment">#调用父类的构函</span><br>        people.__init__(self,n,a,w)<br>        self.grade = g<br>    <span class="hljs-comment">#覆写父类的方法</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">speak</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;%s 说: 我 %d 岁了，我在读 %d 年级&quot;</span>%(self.name,self.age,self.grade))<br> <br><span class="hljs-comment">#另一个类，多重继承之前的准备</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">speaker</span>():<br>    topic = <span class="hljs-string">&#x27;&#x27;</span><br>    name = <span class="hljs-string">&#x27;&#x27;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,n,t</span>):<br>        self.name = n<br>        self.topic = t<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">speak</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;我叫 %s，我是一个演说家，我演讲的主题是 %s&quot;</span>%(self.name,self.topic))<br> <br><span class="hljs-comment">#多重继承</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">sample</span>(speaker,student):<br>    a =<span class="hljs-string">&#x27;&#x27;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,n,a,w,g,t</span>):<br>        student.__init__(self,n,a,w,g)<br>        speaker.__init__(self,n,t)<br> <br>test = sample(<span class="hljs-string">&quot;Tim&quot;</span>,<span class="hljs-number">25</span>,<span class="hljs-number">80</span>,<span class="hljs-number">4</span>,<span class="hljs-string">&quot;Python&quot;</span>)<br>test.speak()   <span class="hljs-comment">#方法名同，默认调用的是在括号中参数位置排前父类的方法</span><br><span class="hljs-built_in">super</span>(student, test).speak()<br></code></pre></td></tr></table></figure></li>
</ul>
<p>##<strong>实例化：</strong></p>
<p>创建一个类的实例，类的具体对象。</p>
<h2 id="对象："><a href="#对象：" class="headerlink" title="对象："></a><strong>对象：</strong></h2><p>通过类定义的数据结构实例。对象包括两个数据成员（类变量和实例变量）和方法。</p>
<p>#线性模型</p>
<p>##MSE（平均平方误差 Mean Square Error）</p>
<p>![image-20221116141550394](D:\人工智能\photo\pytorch md\d2l-en-pytorch.pdf)</p>
<p>穷举法</p>
<p>#梯度下降算法实践</p>
<p>分治：若是凸函数可用，不是话陷入局部最优</p>
<p> 梯度(Gradient): </p>
<p>梯度下降法也会陷入到局部最优，后来在神经网络中发现用梯度下降算法很难陷入局部最优点</p>
<p>非凸函数： 局部最优</p>
<img src="凸函数" srcset="/img/loading.gif" lazyload alt="image-20221116142311981" style="zoom:50%;" />

<p>鞍点：梯度为0</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/%E9%9E%8D%E7%82%B9.jpj" srcset="/img/loading.gif" lazyload alt="image-20221116142642619"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D" srcset="/img/loading.gif" lazyload alt="image-20221116142925931"></p>
<p>指数加权均值：	C<del>i</del>是当前损失，C^&#96;^<del>i</del>是更新后损失</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/%E6%8C%87%E6%95%B0%E5%8A%A0%E6%9D%83%E5%9D%87%E5%80%BC" srcset="/img/loading.gif" lazyload alt="image-20221116143805313"></p>
<p>训练发散：训练集正确训练后都是收敛的，对于训练发散常见原因是学习率取得太大 </p>
<h2 id="随机梯度下降-SGD"><a href="#随机梯度下降-SGD" class="headerlink" title="随机梯度下降(SGD)"></a>随机梯度下降(SGD)</h2><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D.pnj" srcset="/img/loading.gif" lazyload alt="image-20221116144201757"></p>
<h2 id="Batch"><a href="#Batch" class="headerlink" title="Batch"></a>Batch</h2><p>在梯度下降算法w计算是可以并行的</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/Batch" srcset="/img/loading.gif" lazyload alt="image-20221116145124845"></p>
<p>#Back Propagation 反向传播</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD.pnj" srcset="/img/loading.gif" lazyload alt="image-20221116150521974"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/fanxiangchuanbo.pnj" srcset="/img/loading.gif" lazyload alt="image-20221116151255009"></p>
<h2 id="Chain-Rule-链式法则"><a href="#Chain-Rule-链式法则" class="headerlink" title="Chain Rule 链式法则"></a>Chain Rule 链式法则</h2><p> 前馈</p>
<p>Backward</p>
<p>![image-20221116152120646](chain rule.pnj)</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/%E6%B1%82%E6%A2%AF%E5%BA%A6.pnj" srcset="/img/loading.gif" lazyload alt="image-20221116153023895"></p>
<h2 id="Pytorch中前馈和反馈计算"><a href="#Pytorch中前馈和反馈计算" class="headerlink" title="Pytorch中前馈和反馈计算"></a>Pytorch中前馈和反馈计算</h2><p>tensor:Pytorch中存储数据数据</p>
<p>​			data		grad</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/tensor.pnj" srcset="/img/loading.gif" lazyload alt="image-20221116153512231"></p>
<h1 id="用Pytorch实现线性回归"><a href="#用Pytorch实现线性回归" class="headerlink" title="用Pytorch实现线性回归"></a>用Pytorch实现线性回归</h1><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/pytorch%E5%AE%9E%E7%8E%B0" srcset="/img/loading.gif" lazyload alt="image-20221117134749098"></p>
<h2 id="广播机制"><a href="#广播机制" class="headerlink" title="广播机制"></a>广播机制</h2><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/%E5%B9%BF%E6%92%AD%E6%9C%BA%E5%88%B6" srcset="/img/loading.gif" lazyload alt="image-20221117135124782"></p>
<h2 id="affine-model-仿射模型"><a href="#affine-model-仿射模型" class="headerlink" title="affine model 仿射模型"></a>affine model 仿射模型</h2><p>线性单元</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/%E4%BB%BF%E5%B0%84%E6%A8%A1%E5%9E%8B.pnj" srcset="/img/loading.gif" lazyload alt="image-20221117140010765"></p>
<p>列数为维度，loss为标量</p>
<p>定义模型时必须继承自nn.Module类	构造函数：__ init __() 初始化构造对象使用的函数 和 forward()函数  前馈过程中必须使用的函数 必须定义   backward无是因为Module对象会自动求导</p>
<p>![image-20221117140403006](definite module..pnj)</p>
<p>torch.nn.Linear(,)构造对象</p>
<p>nn: Neural Network</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/nn_linear.pnj" srcset="/img/loading.gif" lazyload alt="image-20221117143117510"></p>
<h2 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h2><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B.pnj" srcset="/img/loading.gif" lazyload alt="image-20221117144717501"></p>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-comment">#1、数据准备</span><br>x_data = torch.Tensor([[<span class="hljs-number">1.0</span>],[<span class="hljs-number">2.0</span>],[<span class="hljs-number">3.0</span>]])<br>y_data = torch.Tensor([[<span class="hljs-number">2.0</span>],[<span class="hljs-number">4.0</span>],[<span class="hljs-number">6.0</span>]])<br><span class="hljs-comment">#2、模型 design model using class</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">LinearModel</span>(torch.nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(LinearModel,self).__init__()<br>        <span class="hljs-comment"># (1,1)是指输入x和输出y的特征维度，这里数据集中的x和y的特征都是1维的</span><br>        <span class="hljs-comment"># 该线性层需要学习的参数是w和b  获取w/b的方式分别是~linear.weight/linear.bias</span><br>        self.linear = torch.nn.Linear(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        y_pred = self.linear(x)<br>        <span class="hljs-keyword">return</span> y_pred<br>    <br>model = LinearModel()<br><span class="hljs-comment">#3、构建损失函数和优化器</span><br>criterion = torch.nn.MSELoss(reduction = <span class="hljs-string">&#x27;sum&#x27;</span>)<br>optimizer = torch.optim.SGD(model.parameters(), lr = <span class="hljs-number">0.01</span>)<br><span class="hljs-comment">#4、训练 training cycle forward, backward, update</span><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100000</span>):<br>    y_pred = model(x_data)<br>    loss = criterion(y_pred,y_data)<br>    <span class="hljs-built_in">print</span>(epoch,loss.item())<br>    <br>    optimizer.zero_grad()<br>    loss.backward()<br>    optimizer.step()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;w = &#x27;</span>, model.linear.weight.item())<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;b = &#x27;</span>, model.linear.bias.item())<br>x_test = torch.tensor([[<span class="hljs-number">4.0</span>]])<br>y_test = model(x_test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;y_pred = &#x27;</span>, y_test.data)<br></code></pre></td></tr></table></figure>

<h1 id="逻辑斯蒂回归-分类-classification"><a href="#逻辑斯蒂回归-分类-classification" class="headerlink" title="逻辑斯蒂回归   分类(classification)"></a>逻辑斯蒂回归   分类(classification)</h1><p>分类问题中输出的是概率</p>
<p>二分类：只有两个类别的分类问题</p>
<h2 id="torchvision"><a href="#torchvision" class="headerlink" title="torchvision"></a>torchvision</h2><p>torchvision中有很多数据集</p>
<p>参数train表示想要下载的是训练集还是测试集</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/minist" srcset="/img/loading.gif" lazyload alt="image-20221121142857457"></p>
<p>##Logistic Function</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/logistic" srcset="/img/loading.gif" lazyload alt="image-20221121144142954"></p>
<p>sigmoid functions</p>
<p>![image-20221121144317732](sigmoid functions)</p>
<p>##Logistic Regression Model</p>
<p>![image-20221121144514372](logistic Regression Model)</p>
<h2 id="Loss-function-for-Binary-Classification"><a href="#Loss-function-for-Binary-Classification" class="headerlink" title="Loss function for Binary Classification"></a>Loss function for Binary Classification</h2><p>此时，我们输出的不在是一个数值而是一个分布</p>
<p>BCE</p>
<p>![image-20221121145001408](Loss function classcification)</p>
<p>两个分布间的差异</p>
<p>交叉熵</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/BCE" srcset="/img/loading.gif" lazyload alt="image-20221121150352368"></p>
<h1 id="处理多维特征的输入"><a href="#处理多维特征的输入" class="headerlink" title="处理多维特征的输入"></a>处理多维特征的输入</h1><p>行——样本(sample)</p>
<p>列——特征(Feature)</p>
<p>并行计算</p>
<p>![image-20221205173832561](mini batch)</p>
<h2 id="构造多层神经网络"><a href="#构造多层神经网络" class="headerlink" title="构造多层神经网络"></a>构造多层神经网络</h2><p>![image-20221205175024819](Linear Layer)</p>
<h1 id="加载数据集"><a href="#加载数据集" class="headerlink" title="加载数据集"></a>加载数据集</h1><p>Dataset——数据集 索引</p>
<p>DataLoader——Mini Batch</p>
<h2 id="Epoch、Batch-Size、Iterations"><a href="#Epoch、Batch-Size、Iterations" class="headerlink" title="Epoch、Batch-Size、Iterations"></a>Epoch、Batch-Size、Iterations</h2><p>Epoch:所有的训练样本进行了一次前向传播和反向传播是1次Epoch</p>
<p>Batch Size : 每次训练所用的样本数量</p>
<p>Iteration:迭代了多少次 </p>
<p>shuffle&#x3D;True 打乱数据集</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/shuffle" srcset="/img/loading.gif" lazyload alt="image-20221205204633113"></p>
<h1 id="多分类问题"><a href="#多分类问题" class="headerlink" title="多分类问题"></a>多分类问题</h1><p>实现输出分类的要求 大于0 和为1</p>
<p>![image-20221208151950706](D:\人工智能\photo\pytorch md\sigmoid)</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/softmax" srcset="/img/loading.gif" lazyload alt="image-20221208152435101"></p>
<p>![image-20221208152553537](softmax example)</p>
<h2 id="NLLLoss"><a href="#NLLLoss" class="headerlink" title="NLLLoss"></a>NLLLoss</h2><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/NLLLoss" srcset="/img/loading.gif" lazyload alt="image-20221208153731662"></p>
<p>![image-20221208153816627](D:\人工智能\photo\pytorch md\torch.crossEntropy)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> transforms<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> datasets<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim<br><br><span class="hljs-comment"># prepare dataset</span><br><br>batch_size = <span class="hljs-number">64</span><br>transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((<span class="hljs-number">0.1307</span>,), (<span class="hljs-number">0.3081</span>,))])  <span class="hljs-comment"># 归一化,均值和方差</span><br><br>train_dataset = datasets.MNIST(root=<span class="hljs-string">&#x27;../dataset/mnist/&#x27;</span>, train=<span class="hljs-literal">True</span>, download=<span class="hljs-literal">True</span>, transform=transform)<br>train_loader = DataLoader(train_dataset, shuffle=<span class="hljs-literal">True</span>, batch_size=batch_size)<br>test_dataset = datasets.MNIST(root=<span class="hljs-string">&#x27;../dataset/mnist/&#x27;</span>, train=<span class="hljs-literal">False</span>, download=<span class="hljs-literal">True</span>, transform=transform)<br>test_loader = DataLoader(test_dataset, shuffle=<span class="hljs-literal">False</span>, batch_size=batch_size)<br><br><br><span class="hljs-comment"># design model using class</span><br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Net</span>(torch.nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(Net, self).__init__()<br>        self.l1 = torch.nn.Linear(<span class="hljs-number">784</span>, <span class="hljs-number">512</span>)<br>        self.l2 = torch.nn.Linear(<span class="hljs-number">512</span>, <span class="hljs-number">256</span>)<br>        self.l3 = torch.nn.Linear(<span class="hljs-number">256</span>, <span class="hljs-number">128</span>)<br>        self.l4 = torch.nn.Linear(<span class="hljs-number">128</span>, <span class="hljs-number">64</span>)<br>        self.l5 = torch.nn.Linear(<span class="hljs-number">64</span>, <span class="hljs-number">10</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = x.view(-<span class="hljs-number">1</span>, <span class="hljs-number">784</span>)  <span class="hljs-comment"># -1其实就是自动获取mini_batch</span><br>        x = F.relu(self.l1(x))<br>        x = F.relu(self.l2(x))<br>        x = F.relu(self.l3(x))<br>        x = F.relu(self.l4(x))<br>        <span class="hljs-keyword">return</span> self.l5(x)  <span class="hljs-comment"># 最后一层不做激活，不进行非线性变换</span><br><br><br>model = Net()<br><br><span class="hljs-comment"># construct loss and optimizer</span><br>criterion = torch.nn.CrossEntropyLoss()<br>optimizer = optim.SGD(model.parameters(), lr=<span class="hljs-number">0.01</span>, momentum=<span class="hljs-number">0.5</span>)<br><br><br><span class="hljs-comment"># training cycle forward, backward, update</span><br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">epoch</span>):<br>    running_loss = <span class="hljs-number">0.0</span><br>    <span class="hljs-keyword">for</span> batch_idx, data <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_loader, <span class="hljs-number">0</span>):<br>        <span class="hljs-comment"># 获得一个批次的数据和标签</span><br>        inputs, target = data<br>        optimizer.zero_grad()<br>        <span class="hljs-comment"># 获得模型预测结果(64, 10)</span><br>        outputs = model(inputs)<br>        <span class="hljs-comment"># 交叉熵代价函数outputs(64,10),target（64）</span><br>        loss = criterion(outputs, target)<br>        loss.backward()<br>        optimizer.step()<br><br>        running_loss += loss.item()<br>        <span class="hljs-keyword">if</span> batch_idx % <span class="hljs-number">300</span> == <span class="hljs-number">299</span>:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;[%d, %5d] loss: %.3f&#x27;</span> % (epoch + <span class="hljs-number">1</span>, batch_idx + <span class="hljs-number">1</span>, running_loss / <span class="hljs-number">300</span>))<br>            running_loss = <span class="hljs-number">0.0</span><br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>():<br>    correct = <span class="hljs-number">0</span><br>    total = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> test_loader:<br>            images, labels = data<br>            outputs = model(images)<br>            _, predicted = torch.<span class="hljs-built_in">max</span>(outputs.data, dim=<span class="hljs-number">1</span>)  <span class="hljs-comment"># dim = 1 列是第0个维度，行是第1个维度</span><br>            total += labels.size(<span class="hljs-number">0</span>)<br>            correct += (predicted == labels).<span class="hljs-built_in">sum</span>().item()  <span class="hljs-comment"># 张量之间的比较运算</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;accuracy on test set: %d %% &#x27;</span> % (<span class="hljs-number">100</span> * correct / total))<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>        train(epoch)<br>        test()<br></code></pre></td></tr></table></figure>

<h1 id="卷积神经网路-CNN"><a href="#卷积神经网路-CNN" class="headerlink" title="卷积神经网路 CNN"></a>卷积神经网路 CNN</h1><p>图片全连接后 可能会丧失一些原有的图片的空间的特征，比如图片中两点列相邻但是全连接后岔开</p>
<p>卷积神经网络将图像按原始空间结构进行保存</p>
<p>输入张量的维度 与 输出张量的维度</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/CNN" srcset="/img/loading.gif" lazyload alt="image-20221208191834585"></p>
<p>Feature Extraction 特征提取器 		Classification 分类器</p>
<h2 id="图像是什么？"><a href="#图像是什么？" class="headerlink" title="图像是什么？"></a>图像是什么？</h2><p>RGB——</p>
<p>栅格图像			矢量图像 </p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/Convolution" srcset="/img/loading.gif" lazyload alt="image-20221208194310511"></p>
<p>![image-20221208195206388](convolution 你inputchannels)</p>
<p>![image-20221208195249426](Convolution n input channels and M output Channels)</p>
<p>![image-20221208202749780](pytorch md\Convolution Layer)</p>
<h2 id="padding"><a href="#padding" class="headerlink" title="padding"></a>padding</h2><p>![image-20221208203047225](D:\人工智能\photo\pytorch md\padding)</p>
<h2 id="stride-步长"><a href="#stride-步长" class="headerlink" title="stride 步长"></a>stride 步长</h2><p>每次索引的坐标+</p>
<p>可有效降低图像的宽度和高度</p>
<h2 id="Max-Pooling-最大池化层"><a href="#Max-Pooling-最大池化层" class="headerlink" title="Max Pooling  最大池化层"></a>Max Pooling  最大池化层</h2><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/MaxPooling" srcset="/img/loading.gif" lazyload alt="image-20221208204115830"></p>
<p>分成n*n组，找每组的最大值</p>
<p>![image-20221208204503171](Simple Example)</p>
<p>减少代码冗余：函数&#x2F;类</p>
<p>Concatenate：拼接 将张量沿着通道连接</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/concatenate" srcset="/img/loading.gif" lazyload alt="image-20221209100738941"></p>
<p>What is 1×1 convolution？</p>
<p>信息融合  改变通道数量</p>
<p>![image-20221209101316370](1×1 convolution) </p>
<p>![image-20221209102406979](why  is 1×1)</p>
<h1 id="循环神经网络-RNN"><a href="#循环神经网络-RNN" class="headerlink" title="循环神经网络 RNN"></a>循环神经网络 RNN</h1><p>DNN：Dense（Deep） 稠密神经网络</p>
<p>RNN：处理具有序列连接的输入数据（例如：金融股市、天气、自然语言处理）</p>
<h2 id="RNN-Cell"><a href="#RNN-Cell" class="headerlink" title="RNN Cell"></a>RNN Cell</h2><p>本质：线形层，把某个维度映射到另一个维度的空间。 Linear</p>
<p>![image-20221214165453611](RNN Cell)</p>
<p>![image-20221214171337356](RNN Cell2)</p>
<p>![image-20221214171356832](D:\人工智能\photo\pytorch md\RNN Cell3)</p>
<p>![image-20221214171723190](RNN Cell in Pytorch)</p>
<p>![image-20221214174335513](RNN Cell in Pytorch 2)</p>
<h2 id="How-to-use-RNNCell"><a href="#How-to-use-RNNCell" class="headerlink" title="How to use RNNCell"></a>How to use RNNCell</h2><p>![image-20221214174455158](use RNNCell1)</p>
<p>![image-20221214174611539](use RNNCell2)</p>
<p>![image-20221214174814307](use RNNCell3)</p>
<h2 id="How-to-use-RNN"><a href="#How-to-use-RNN" class="headerlink" title="How to use RNN"></a>How to use RNN</h2><p>![image-20221214174959457](use RNN1)</p>
<p>![image-20221214180055695](use RNN2)</p>
<p>![image-20221214180951812](use RNN3)</p>
<p>![image-20221214181039389](use RNN4)</p>
<p>![image-20221214181656965](use RNN5)</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/batch_first1" srcset="/img/loading.gif" lazyload alt="image-20221214181925459"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/batch_first2" srcset="/img/loading.gif" lazyload alt="image-20221214182021109"></p>
<h1 id="李宏毅深度学习"><a href="#李宏毅深度学习" class="headerlink" title="李宏毅深度学习"></a>李宏毅深度学习</h1><p>##Pytorch Tutorial</p>
<p>![image-20230214164320489](pytorch turtorial)</p>
<p>###Step1 Load Data</p>
<p>torch.utils.data.Dataset &amp; torch.utils.data.DataLoader</p>
<ul>
<li><p>Dataset:	stores data samples and expected values  将Python定义class将资料一笔笔读进来打包。                 </p>
</li>
<li><p>Dataloader: groups data in batches, enables multiprocessing 将Dataset中一个个的资料合并成一个个batch，平行化处理</p>
</li>
<li><p>dataset &#x3D; MyDataset(file)</p>
</li>
<li><p>dataloader &#x3D; Dataloader(dataset, batch_size, shuffle &#x3D; True)</p>
</li>
</ul>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/Dataset" srcset="/img/loading.gif" lazyload alt="image-20230214144609312"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/Dataset2" srcset="/img/loading.gif" lazyload alt="image-20230214144900704"></p>
<h4 id="Tensors"><a href="#Tensors" class="headerlink" title="Tensors"></a>Tensors</h4><ul>
<li>High-dimensional matrices (arrays)</li>
</ul>
<p><strong>Shape of Tensors</strong></p>
<p>​	Check with .shape() </p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/Tensor" srcset="/img/loading.gif" lazyload alt="image-20230214145346135"></p>
<h5 id="Creating-tensors"><a href="#Creating-tensors" class="headerlink" title="Creating tensors"></a>Creating tensors</h5><p>![image-20230214150139489](creat tensors)</p>
<h5 id="Common-operations"><a href="#Common-operations" class="headerlink" title="Common operations"></a>Common operations</h5><ul>
<li><p>Addition</p>
<p>​						z &#x3D; x + y</p>
<p>​						z&#x3D;torch.add(x,y)</p>
</li>
<li><p>Subtraction</p>
<p>​						z &#x3D; x - y</p>
<p>​						z&#x3D; torch.sub(x,y)</p>
</li>
<li><p>Power</p>
<p>​						y &#x3D; x.pow(2)</p>
</li>
<li><p>Summation</p>
<p>​						y &#x3D; x.sum()</p>
</li>
<li><p>Mean</p>
<p>​						y &#x3D; x.mean()</p>
</li>
<li><p>Transpose:transpose two specified dimensions</p>
<p>​				<img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/transpose" srcset="/img/loading.gif" lazyload alt="image-20230214155039585">		</p>
</li>
<li><p>Squeeze</p>
</li>
</ul>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/squeezw" srcset="/img/loading.gif" lazyload alt="image-20230214155219945"></p>
<ul>
<li>Unsqueeze</li>
</ul>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/unsqueeze" srcset="/img/loading.gif" lazyload alt="image-20230214155829437"></p>
<ul>
<li>Cat</li>
</ul>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/cat" srcset="/img/loading.gif" lazyload alt="image-20230214155853582"></p>
<ul>
<li>Device</li>
</ul>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/device" srcset="/img/loading.gif" lazyload alt="image-20230214161322544"></p>
<h5 id="Gradient-Calculation"><a href="#Gradient-Calculation" class="headerlink" title="Gradient Calculation"></a>Gradient Calculation</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">x = torch.tensor([[<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>], [-<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>]], requires_grad=<span class="hljs-literal">True</span>)<br>z= x.<span class="hljs-built_in">pow</span>(<span class="hljs-number">2</span>).<span class="hljs-built_in">sum</span>()<br>z.backward()<br>x.grad<br></code></pre></td></tr></table></figure>



<p>###Step 2 Define Neural Network</p>
<p><strong>torch.nn.Module</strong></p>
<ul>
<li>Linear Layer(Fully-connected Layer)</li>
<li>Non-Linear Activation Functions</li>
</ul>
<p>####Build your own neural network</p>
<p>![image-20230214163500685](build network)</p>
<p>![image-20230214163623783](build network2)</p>
<h3 id="Step-3-Loss-Function"><a href="#Step-3-Loss-Function" class="headerlink" title="Step 3 Loss Function"></a>Step 3 Loss Function</h3><p>torch.nn.MSELoss<br>torch.nn.CrossEntropyLoss etc.</p>
<p>![image-20230214163759146](Loss functions)</p>
<h3 id="Step-4-Optimization-Algorithm"><a href="#Step-4-Optimization-Algorithm" class="headerlink" title="Step 4 Optimization Algorithm"></a>Step 4 Optimization Algorithm</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/optim" srcset="/img/loading.gif" lazyload alt="image-20230214164200244"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/optim2" srcset="/img/loading.gif" lazyload alt="image-20230214164218386"></p>
<h3 id="Step-5-Entire-Procedure"><a href="#Step-5-Entire-Procedure" class="headerlink" title="Step 5 Entire Procedure"></a>Step 5 Entire Procedure</h3><p>![image-20230214164603078](nn training setup)</p>
<p>![image-20230214164730311](nn training loop)</p>
<p>![image-20230214165115010](nn Validation loop)</p>
<p>![image-20230214165337476](nn testing loop)</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/notice" srcset="/img/loading.gif" lazyload alt="image-20230214170501908"></p>
<h3 id="Save-Load-Trained-Models"><a href="#Save-Load-Trained-Models" class="headerlink" title="Save&#x2F;Load Trained Models"></a>Save&#x2F;Load Trained Models</h3><p>![image-20230214170609228](save load models)</p>
<h2 id="Gradient-Decent"><a href="#Gradient-Decent" class="headerlink" title="Gradient Decent"></a>Gradient Decent</h2><h3 id="Backpropagation"><a href="#Backpropagation" class="headerlink" title="Backpropagation"></a>Backpropagation</h3><p>​	<strong>Chain Rule</strong></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/chainrule" srcset="/img/loading.gif" lazyload alt="image-20230215200837078"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/backpropagation" srcset="/img/loading.gif" lazyload alt="image-20230215200915833"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/Backpropagation2" srcset="/img/loading.gif" lazyload alt="image-20230215201437884"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/backpropagation3" srcset="/img/loading.gif" lazyload alt="image-20230215201710167"></p>
<h2 id="Regression"><a href="#Regression" class="headerlink" title="Regression"></a>Regression</h2><p>[Regression李宏毅]:(<a target="_blank" rel="noopener" href="https://github.com/Fafa-DL/Lhy_Machine_Learning/blob/main/%E9%80%89%E4%BF%AE">https://github.com/Fafa-DL/Lhy_Machine_Learning/blob/main/选修</a> To Learn More&#x2F;第一节&#x2F;Regression.pdf)</p>
<h3 id="Step-1-Model"><a href="#Step-1-Model" class="headerlink" title="Step 1 Model"></a>Step 1 Model</h3><p>![image-20230216104238590](regression model)</p>
<h3 id="Step2-Goodness-of-Function"><a href="#Step2-Goodness-of-Function" class="headerlink" title="Step2 Goodness of Function"></a>Step2 Goodness of Function</h3><p>![image-20230216104604935](regression goodnessof function)</p>
<h3 id="Step3-Best-Function"><a href="#Step3-Best-Function" class="headerlink" title="Step3 Best Function"></a>Step3 Best Function</h3><p>![image-20230216104653344](regression best function)</p>
<p>![image-20230216104725243](gradient descent)</p>
<p>Local minima 				Global minima</p>
<h3 id="Model-Selection"><a href="#Model-Selection" class="headerlink" title="Model Selection"></a>Model Selection</h3><p>![image-20230216104921552](regression model selection)</p>
<p><strong><strong>Overfitting</strong>:   A  more complex model does not always lead to better performance on testing data.</strong></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220164830103.png" srcset="/img/loading.gif" lazyload alt="image-20230220164830103"></p>
<p>[回归 模型选择](<a target="_blank" rel="noopener" href="https://github.com/Fafa-DL/Lhy_Machine_Learning/blob/main/%E9%80%89%E4%BF%AE">https://github.com/Fafa-DL/Lhy_Machine_Learning/blob/main/选修</a> To Learn More&#x2F;第一节&#x2F;Regression.pdf)</p>
<h3 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a><strong>Regularization</strong></h3><p>Redefine Loss function</p>
<p>![image-20230216105114915](regression regularization)</p>
<p><strong>Smoother</strong>：meaning is when the input change, the output change smaller(smooth)</p>
<p>Why we want a smooth function?: If some noises corrupt input x<del>i</del> When testing， a smooth function has less influence.</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220165823191.png" srcset="/img/loading.gif" lazyload alt="image-20230220165823191"></p>
<h2 id="Classification"><a href="#Classification" class="headerlink" title="Classification"></a>Classification</h2><h3 id="Gaussian-Distribution"><a href="#Gaussian-Distribution" class="headerlink" title="Gaussian Distribution"></a>Gaussian Distribution</h3><p>![image-20230216142409305](gaussian diutution)</p>
<p>![image-20230216142609834](probability from class)</p>
<p>![image-20230216142701986](Maximum Likehood)</p>
<p>![image-20230216143712066](maximum likehood2)</p>
<h2 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h2><p>![image-20230216144705245](Logistic regree)</p>
<p>![image-20230216144840928](logistic regree2)</p>
<p>![image-20230216150359309](logistic regree3)</p>
<p>![image-20230216150747837](logistic regress4)</p>
<p>![image-20230216152128713](logistic regree5)</p>
<p>![image-20230216153003383](logistic regree6)</p>
<p>![image-20230216153048539](logistic regree7)</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230216153209267.png" srcset="/img/loading.gif" lazyload alt="image-20230216153209267"></p>
<p> <img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230216153429112.png" srcset="/img/loading.gif" lazyload alt="image-20230216153429112"></p>
<p>![image-20230216154717652](cross entropy)</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230216155931419.png" srcset="/img/loading.gif" lazyload alt="image-20230216155931419"></p>
<p>Generative model 进行了一定的假设</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230216160817270.png" srcset="/img/loading.gif" lazyload alt="image-20230216160817270"></p>
<h3 id="Multi-class-Classfication"><a href="#Multi-class-Classfication" class="headerlink" title="Multi-class Classfication"></a>Multi-class Classfication</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230216161736917.png" srcset="/img/loading.gif" lazyload alt="image-20230216161736917"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230216162028665.png" srcset="/img/loading.gif" lazyload alt="image-20230216162028665"></p>
<h3 id="Limitation-of-Logistic-Regression"><a href="#Limitation-of-Logistic-Regression" class="headerlink" title="Limitation of Logistic Regression"></a>Limitation of Logistic Regression</h3><p>Feature Transformation</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230216162441172.png" srcset="/img/loading.gif" lazyload alt="image-20230216162441172"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230216163421455.png" srcset="/img/loading.gif" lazyload alt="image-20230216163421455"></p>
<h2 id="General-Guidance"><a href="#General-Guidance" class="headerlink" title="General Guidance"></a>General Guidance</h2><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217162531424.png" srcset="/img/loading.gif" lazyload alt="image-20230217162531424"></p>
<h3 id="Model-Bias"><a href="#Model-Bias" class="headerlink" title="Model Bias"></a>Model Bias</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217163405067.png" srcset="/img/loading.gif" lazyload alt="image-20230217163405067"></p>
<h3 id="OPtimization-Issue"><a href="#OPtimization-Issue" class="headerlink" title="OPtimization Issue"></a>OPtimization Issue</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217163545349.png" srcset="/img/loading.gif" lazyload alt="image-20230217163545349"></p>
<h3 id="Overfitting"><a href="#Overfitting" class="headerlink" title="Overfitting"></a>Overfitting</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217163840304.png" srcset="/img/loading.gif" lazyload alt="image-20230217163840304"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217164009238.png" srcset="/img/loading.gif" lazyload alt="image-20230217164009238"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217164404659.png" srcset="/img/loading.gif" lazyload alt="image-20230217164404659"></p>
<p><strong>Data augmentation 要根据资料特性合理设置</strong></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217164553921.png" srcset="/img/loading.gif" lazyload alt="image-20230217164553921"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217164710202.png" srcset="/img/loading.gif" lazyload alt="image-20230217164710202"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217164849894.png" srcset="/img/loading.gif" lazyload alt="image-20230217164849894"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217165040061.png" srcset="/img/loading.gif" lazyload alt="image-20230217165040061"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217165245444.png" srcset="/img/loading.gif" lazyload alt="image-20230217165245444"></p>
<p><strong>模型选择 有可能恰好模型产生随机全正确</strong></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217170146204.png" srcset="/img/loading.gif" lazyload alt="image-20230217170146204"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217170342996.png" srcset="/img/loading.gif" lazyload alt="image-20230217170342996"></p>
<h4 id="used-a-validation-set-but-model-still-overfitted"><a href="#used-a-validation-set-but-model-still-overfitted" class="headerlink" title="used a validation set, but model still overfitted?"></a>used a validation set, but model still overfitted?</h4><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222150042220.png" srcset="/img/loading.gif" lazyload alt="image-20230222150042220"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222150507570.png" srcset="/img/loading.gif" lazyload alt="image-20230222150507570"></p>
<h3 id="Mismatch"><a href="#Mismatch" class="headerlink" title="Mismatch"></a>Mismatch</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217170703851.png" srcset="/img/loading.gif" lazyload alt="image-20230217170703851"></p>
<h2 id="ptimization-Fails"><a href="#ptimization-Fails" class="headerlink" title="ptimization Fails"></a>ptimization Fails</h2><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217174738922.png" srcset="/img/loading.gif" lazyload alt="image-20230217174738922"></p>
<h3 id="local-minima"><a href="#local-minima" class="headerlink" title="local minima"></a>local minima</h3><h3 id="saddle-point"><a href="#saddle-point" class="headerlink" title="saddle point"></a>saddle point</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217175230940.png" srcset="/img/loading.gif" lazyload alt="image-20230217175230940"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217175445395.png" srcset="/img/loading.gif" lazyload alt="image-20230217175445395"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217175935273.png" srcset="/img/loading.gif" lazyload alt="image-20230217175935273"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217185855119.png" srcset="/img/loading.gif" lazyload alt="image-20230217185855119"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217190539102.png" srcset="/img/loading.gif" lazyload alt="image-20230217190539102"></p>
<h4 id="Don’t-afraid-of-saddle-point"><a href="#Don’t-afraid-of-saddle-point" class="headerlink" title="Don’t afraid of saddle point"></a>Don’t afraid of saddle point</h4><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217190851402.png" srcset="/img/loading.gif" lazyload alt="image-20230217190851402"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217192854428.png" srcset="/img/loading.gif" lazyload alt="image-20230217192854428"></p>
<h2 id="Batch-and-Momentum"><a href="#Batch-and-Momentum" class="headerlink" title="Batch and Momentum"></a>Batch and Momentum</h2><h3 id="Batch-1"><a href="#Batch-1" class="headerlink" title="Batch"></a>Batch</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217194431309.png" srcset="/img/loading.gif" lazyload alt="image-20230217194431309"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217195204374.png" srcset="/img/loading.gif" lazyload alt="image-20230217195204374"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217200343404.png" srcset="/img/loading.gif" lazyload alt="image-20230217200343404"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217200535811.png" srcset="/img/loading.gif" lazyload alt="image-20230217200535811"></p>
<p>   <img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217200708347.png" srcset="/img/loading.gif" lazyload alt="image-20230217200708347"></p>
<p>·Small batch is better on testing data</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217201131973.png" srcset="/img/loading.gif" lazyload alt="image-20230217201131973"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217201303403.png" srcset="/img/loading.gif" lazyload alt="image-20230217201303403"></p>
<h3 id="Momentum"><a href="#Momentum" class="headerlink" title="Momentum"></a>Momentum</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217201537450.png" srcset="/img/loading.gif" lazyload alt="image-20230217201537450"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217202010268.png" srcset="/img/loading.gif" lazyload alt="image-20230217202010268"></p>
<h2 id="Adptive-Learning-Rate"><a href="#Adptive-Learning-Rate" class="headerlink" title="Adptive Learning Rate"></a>Adptive Learning Rate</h2><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219103610912.png" srcset="/img/loading.gif" lazyload alt="image-20230219103610912"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219104510420.png" srcset="/img/loading.gif" lazyload alt="image-20230219104510420"></p>
<p><strong>在某一个方向上梯度小希望学习率大一些，在某个方向梯度大一些希望学习率小一些</strong></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219104723217.png" srcset="/img/loading.gif" lazyload alt="image-20230219104723217"></p>
<p>###Root Mean Square</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219105222073.png" srcset="/img/loading.gif" lazyload alt="image-20230219105222073"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219105414500.png" srcset="/img/loading.gif" lazyload alt="image-20230219105414500"></p>
<p> <img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219105807737.png" srcset="/img/loading.gif" lazyload alt="image-20230219105807737"></p>
<h3 id="RMSProop"><a href="#RMSProop" class="headerlink" title="RMSProop"></a>RMSProop</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219110213837.png" srcset="/img/loading.gif" lazyload alt="image-20230219110213837"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219110527256.png" srcset="/img/loading.gif" lazyload alt="image-20230219110527256"></p>
<h4 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h4><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219110610162.png" srcset="/img/loading.gif" lazyload alt="image-20230219110610162"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219113320260.png" srcset="/img/loading.gif" lazyload alt="image-20230219113320260"></p>
<h3 id="New-Optimizers-for-Deep-Learning"><a href="#New-Optimizers-for-Deep-Learning" class="headerlink" title="New Optimizers for Deep Learning"></a>New Optimizers for Deep Learning</h3><p>[Lhy_Machine_Learning&#x2F;Optimization.pdf at main · Fafa-DL&#x2F;Lhy_Machine_Learning (github.com)](<a target="_blank" rel="noopener" href="https://github.com/Fafa-DL/Lhy_Machine_Learning/blob/main/%E9%80%89%E4%BF%AE">https://github.com/Fafa-DL/Lhy_Machine_Learning/blob/main/选修</a> To Learn More&#x2F;第二节&#x2F;Optimization.pdf)</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219173231485.png" srcset="/img/loading.gif" lazyload alt="image-20230219173231485"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219173402903.png" srcset="/img/loading.gif" lazyload alt="image-20230219173402903"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219173520988.png" srcset="/img/loading.gif" lazyload alt="image-20230219173520988"></p>
<h4 id="SGD"><a href="#SGD" class="headerlink" title="SGD"></a>SGD</h4><h4 id="SGD-with-Momentum-SGDM"><a href="#SGD-with-Momentum-SGDM" class="headerlink" title="SGD with Momentum (SGDM)"></a>SGD with Momentum (SGDM)</h4><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219174817789.png" srcset="/img/loading.gif" lazyload alt="image-20230219174817789"></p>
<h4 id="Adagraad"><a href="#Adagraad" class="headerlink" title="Adagraad"></a>Adagraad</h4><h4 id="RMSProp"><a href="#RMSProp" class="headerlink" title="RMSProp"></a>RMSProp</h4><h4 id="Adam-1"><a href="#Adam-1" class="headerlink" title="Adam"></a>Adam</h4><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219175650535.png" srcset="/img/loading.gif" lazyload alt="image-20230219175650535"></p>
<img src="image-20230219175745769.png" srcset="/img/loading.gif" lazyload alt="image-20230219175745769" style="zoom:50%;" />

<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219182432823.png" srcset="/img/loading.gif" lazyload alt="image-20230219182432823"></p>
<p>尝试解释为什么Adam和SGDM训练不一样：</p>
<p>​		Loss Function比较平坦，训练和测试的的Minimum就会比较接近</p>
<h5 id="Simply-combine-Adam-with-SGDM？—-SWATS"><a href="#Simply-combine-Adam-with-SGDM？—-SWATS" class="headerlink" title="Simply combine Adam with SGDM？—-SWATS"></a>Simply combine Adam with SGDM？—-SWATS</h5><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219182959481.png" srcset="/img/loading.gif" lazyload alt="image-20230219182959481"></p>
<h5 id="Towards-Improving-Adam"><a href="#Towards-Improving-Adam" class="headerlink" title="Towards Improving Adam"></a>Towards Improving Adam</h5><p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1VN4y1P7Zj?t=2352.9&p=26">视频解释 39:00</a></p>
<p>假设β<del>1</del>&#x3D;0，则未使用m<del>t</del>，focous adaptive learning rate对Adam造成的影响。通过v<del>t</del>表达式可知v<del>t</del>受到梯度的影响会维持1&#x2F;(1-0.999)</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219184733050.png" srcset="/img/loading.gif" lazyload alt="image-20230219184733050"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219184845319.png" srcset="/img/loading.gif" lazyload alt="image-20230219184845319"></p>
<h6 id="AMSGrad"><a href="#AMSGrad" class="headerlink" title="AMSGrad"></a>AMSGrad</h6><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219185255264.png" srcset="/img/loading.gif" lazyload alt="image-20230219185255264"></p>
<h5 id="Towards-Improving-SGDM"><a href="#Towards-Improving-SGDM" class="headerlink" title="Towards Improving SGDM"></a>Towards Improving SGDM</h5><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219185732554.png" srcset="/img/loading.gif" lazyload alt="image-20230219185732554"></p>
<p><strong>Engineering：learning rate很小或很大精度都不会很好，适中</strong></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219185906756.png" srcset="/img/loading.gif" lazyload alt="image-20230219185906756"></p>
<h5 id="Does-Adam-need-warm-up"><a href="#Does-Adam-need-warm-up" class="headerlink" title="Does Adam need warm-up?"></a>Does Adam need warm-up?</h5><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220151750842.png" srcset="/img/loading.gif" lazyload alt="image-20230220151750842"></p>
<p>为什么Adam已经Adaptive rate为什么还需要warm up?：上图实际实验说明（横轴为Iteration，纵轴为gradient 的distribution），前几步的估计不准</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220152751776.png" srcset="/img/loading.gif" lazyload alt="image-20230220152751776"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220153041140.png" srcset="/img/loading.gif" lazyload alt="image-20230220153041140"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220153440025.png" srcset="/img/loading.gif" lazyload alt="image-20230220153440025"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220154709135.png" srcset="/img/loading.gif" lazyload alt="image-20230220154709135"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220154902836.png" srcset="/img/loading.gif" lazyload alt="image-20230220154902836"></p>
<h5 id="More-than-momentum"><a href="#More-than-momentum" class="headerlink" title="More than momentum"></a>More than momentum</h5><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220155117699.png" srcset="/img/loading.gif" lazyload alt="image-20230220155117699"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220160235068.png" srcset="/img/loading.gif" lazyload alt="image-20230220160235068"></p>
<p><strong>▽L(θ<del>t-1</del>-λm<del>t-1</del>)表示预测下一点的梯度时如何</strong></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220161633898.png" srcset="/img/loading.gif" lazyload alt="image-20230220161633898"></p>
<h5 id="Nadam"><a href="#Nadam" class="headerlink" title="Nadam"></a>Nadam</h5><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220162817076.png" srcset="/img/loading.gif" lazyload alt="image-20230220162817076"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220163803033.png" srcset="/img/loading.gif" lazyload alt="image-20230220163803033"></p>
<h4 id="Something-helps-optimization"><a href="#Something-helps-optimization" class="headerlink" title="Something helps optimization"></a>Something helps optimization</h4><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220163905897.png" srcset="/img/loading.gif" lazyload alt="image-20230220163905897"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220164300905.png" srcset="/img/loading.gif" lazyload alt="image-20230220164300905"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220164324808.png" srcset="/img/loading.gif" lazyload alt="image-20230220164324808"></p>
<h2 id="Learning-Rate-Scheduling"><a href="#Learning-Rate-Scheduling" class="headerlink" title="Learning Rate Scheduling"></a>Learning Rate Scheduling</h2><p>将Learning Rate与时间有关</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219113538883.png" srcset="/img/loading.gif" lazyload alt="image-20230219113538883"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219114058621.png" srcset="/img/loading.gif" lazyload alt="image-20230219114058621"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219113906542.png" srcset="/img/loading.gif" lazyload alt="image-20230219113906542"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219114343052.png" srcset="/img/loading.gif" lazyload alt="image-20230219114343052"></p>
<h2 id="再探宝可梦、数码宝贝分类器—浅谈机器学习原理"><a href="#再探宝可梦、数码宝贝分类器—浅谈机器学习原理" class="headerlink" title="再探宝可梦、数码宝贝分类器—浅谈机器学习原理"></a>再探宝可梦、数码宝贝分类器—浅谈机器学习原理</h2><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219134611063.png" srcset="/img/loading.gif" lazyload alt="image-20230219134611063"></p>
<h4 id="模型复杂度"><a href="#模型复杂度" class="headerlink" title="模型复杂度"></a>模型复杂度</h4><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219140424624.png" srcset="/img/loading.gif" lazyload alt="image-20230219140424624"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219140828795.png" srcset="/img/loading.gif" lazyload alt="image-20230219140828795"></p>
<h4 id="i-i-d"><a href="#i-i-d" class="headerlink" title="i.i.d"></a>i.i.d</h4><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219141400722.png" srcset="/img/loading.gif" lazyload alt="image-20230219141400722"></p>
<p>![image-20230219141507996](D:\人工智能\photo\pytorch md\image-20230219141507996.png)</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219142322281.png" srcset="/img/loading.gif" lazyload alt="image-20230219142322281"></p>
<h3 id="What-train-sample-do-we-want"><a href="#What-train-sample-do-we-want" class="headerlink" title="What train sample do we want?"></a>What train sample do we want?</h3><p><strong>train得到的模型好坏取决于sample时的资料</strong></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219143624556.png" srcset="/img/loading.gif" lazyload alt="image-20230219143624556"></p>
<p>L(h^all^, D<del>all</del> )一定会比L(h^train^, D<del>all</del> )小</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219143741645.png" srcset="/img/loading.gif" lazyload alt="image-20230219143741645"></p>
<p>![image-20230219143939593](D:\人工智能\photo\pytorch md\image-20230219143939593.png)</p>
<h3 id="General"><a href="#General" class="headerlink" title="General"></a>General</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219144104393.png" srcset="/img/loading.gif" lazyload alt="image-20230219144104393"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219150624632.png" srcset="/img/loading.gif" lazyload alt="image-20230219150624632"></p>
<img src="image-20230219150949584.png" srcset="/img/loading.gif" lazyload alt="image-20230219150949584" style="zoom: 50%;" />

<img src="D:\人工智能\photo\pytorch md\image-20230219151206774.png" srcset="/img/loading.gif" lazyload alt="image-20230219151206774" style="zoom:50%;" />

<img src="image-20230219151432675.png" srcset="/img/loading.gif" lazyload alt="image-20230219151432675" style="zoom:50%;" />

<img src="image-20230219151632461.png" srcset="/img/loading.gif" lazyload alt="image-20230219151632461" style="zoom:50%;" />

<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219151824419.png" srcset="/img/loading.gif" lazyload alt="image-20230219151824419"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219151902001.png" srcset="/img/loading.gif" lazyload alt="image-20230219151902001"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219151916700.png" srcset="/img/loading.gif" lazyload alt="image-20230219151916700"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219152147020.png" srcset="/img/loading.gif" lazyload alt="image-20230219152147020"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219152515395.png" srcset="/img/loading.gif" lazyload alt="image-20230219152515395"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219152656072.png" srcset="/img/loading.gif" lazyload alt="image-20230219152656072"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219153140826.png" srcset="/img/loading.gif" lazyload alt="image-20230219153140826"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219153347413.png" srcset="/img/loading.gif" lazyload alt="image-20230219153347413"></p>
<h3 id="Why-more-parameters-are-easier-to-overfit"><a href="#Why-more-parameters-are-easier-to-overfit" class="headerlink" title="Why more parameters are easier to overfit?"></a>Why more parameters are easier to overfit?</h3><h2 id="鱼与熊掌可以兼得的机器学习"><a href="#鱼与熊掌可以兼得的机器学习" class="headerlink" title="鱼与熊掌可以兼得的机器学习"></a>鱼与熊掌可以兼得的机器学习</h2><h3 id="Review：Why-hidden-layer"><a href="#Review：Why-hidden-layer" class="headerlink" title="Review：Why hidden layer?"></a>Review：Why hidden layer?</h3><p>可以通过一个hidden layer找出所有可能的function</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222151535069.png" srcset="/img/loading.gif" lazyload alt="image-20230222151535069"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222151614261.png" srcset="/img/loading.gif" lazyload alt="image-20230222151614261"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222151643870.png" srcset="/img/loading.gif" lazyload alt="image-20230222151643870"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222152253769.png" srcset="/img/loading.gif" lazyload alt="image-20230222152253769"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222152423524.png" srcset="/img/loading.gif" lazyload alt="image-20230222152423524"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222152447853.png" srcset="/img/loading.gif" lazyload alt="image-20230222152447853"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222153444309.png" srcset="/img/loading.gif" lazyload alt="image-20230222153444309"></p>
<p>探讨网络深层的作用</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222154525682.png" srcset="/img/loading.gif" lazyload alt="image-20230222154525682"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222154753511.png" srcset="/img/loading.gif" lazyload alt="image-20230222154753511"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222155100307.png" srcset="/img/loading.gif" lazyload alt="image-20230222155100307"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222155207551.png" srcset="/img/loading.gif" lazyload alt="image-20230222155207551"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222155229862.png" srcset="/img/loading.gif" lazyload alt="image-20230222155229862"></p>
<h2 id="HW2"><a href="#HW2" class="headerlink" title="HW2"></a>HW2</h2><h2 id="Concolutional-Neural-Network-CNN"><a href="#Concolutional-Neural-Network-CNN" class="headerlink" title="Concolutional Neural Network(CNN)"></a>Concolutional Neural Network(CNN)</h2><p><strong>Network Architecture designed for Image</strong></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230221190847727.png" srcset="/img/loading.gif" lazyload alt="image-20230221190847727"></p>
<p>对电脑来说一张图片是什么？</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230221191148146.png" srcset="/img/loading.gif" lazyload alt="image-20230221191148146"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222133926254.png" srcset="/img/loading.gif" lazyload alt="image-20230222133926254"></p>
<p>参数过多容易overfitting</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222134324377.png" srcset="/img/loading.gif" lazyload alt="image-20230222134324377"></p>
<h3 id="Receptive-field"><a href="#Receptive-field" class="headerlink" title="Receptive field"></a>Receptive field</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222134630110.png" srcset="/img/loading.gif" lazyload alt="image-20230222134630110"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222135225522.png" srcset="/img/loading.gif" lazyload alt="image-20230222135225522"></p>
<p>·</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222135722131.png" srcset="/img/loading.gif" lazyload alt="image-20230222135722131"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222135846875.png" srcset="/img/loading.gif" lazyload alt="image-20230222135846875"></p>
<p>parameter sharing</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222140105874.png" srcset="/img/loading.gif" lazyload alt="image-20230222140105874"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222140225472.png" srcset="/img/loading.gif" lazyload alt="image-20230222140225472"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222140412998.png" srcset="/img/loading.gif" lazyload alt="image-20230222140412998"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222140504306.png" srcset="/img/loading.gif" lazyload alt="image-20230222140504306"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222140728856.png" srcset="/img/loading.gif" lazyload alt="image-20230222140728856"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222140813030.png" srcset="/img/loading.gif" lazyload alt="image-20230222140813030"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222140957944.png" srcset="/img/loading.gif" lazyload alt="image-20230222140957944"></p>
<p>若filter大小一直设置3*3，会使network不能看更大的图吗？</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222141306342.png" srcset="/img/loading.gif" lazyload alt="image-20230222141306342"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222141343778.png" srcset="/img/loading.gif" lazyload alt="image-20230222141343778"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222141401887.png" srcset="/img/loading.gif" lazyload alt="image-20230222141401887"></p>
<p>同样的小目标可以出现在不同地方所以不同区域可以共用参数。</p>
<h3 id="Pooling-Max-Pooling"><a href="#Pooling-Max-Pooling" class="headerlink" title="Pooling-Max Pooling"></a>Pooling-Max Pooling</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222142228736.png" srcset="/img/loading.gif" lazyload alt="image-20230222142228736"></p>
<p>Max Pooling作用：把图片变小</p>
<p>Pooling主要的作用是减少运算量</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222143015795.png" srcset="/img/loading.gif" lazyload alt="image-20230222143015795"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222143054258.png" srcset="/img/loading.gif" lazyload alt="image-20230222143054258"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222143303706.png" srcset="/img/loading.gif" lazyload alt="image-20230222143303706"> </p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222143421544.png" srcset="/img/loading.gif" lazyload alt="image-20230222143421544"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222143633013.png" srcset="/img/loading.gif" lazyload alt="image-20230222143633013"></p>
<h2 id="Spatial-Transformer-Layer"><a href="#Spatial-Transformer-Layer" class="headerlink" title="Spatial Transformer Layer"></a>Spatial Transformer Layer</h2><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222162327297.png" srcset="/img/loading.gif" lazyload alt="image-20230222162327297"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222163100727.png" srcset="/img/loading.gif" lazyload alt="image-20230222163100727"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222163346290.png" srcset="/img/loading.gif" lazyload alt="image-20230222163346290"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222163816076.png" srcset="/img/loading.gif" lazyload alt="image-20230222163816076"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222164539375.png" srcset="/img/loading.gif" lazyload alt="image-20230222164539375"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222164711179.png" srcset="/img/loading.gif" lazyload alt="image-20230222164711179"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222164815484.png" srcset="/img/loading.gif" lazyload alt="image-20230222164815484"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222165047469.png" srcset="/img/loading.gif" lazyload alt="image-20230222165047469"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222170141809.png" srcset="/img/loading.gif" lazyload alt="image-20230222170141809"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222170814869.png" srcset="/img/loading.gif" lazyload alt="image-20230222170814869"></p>
<h2 id="Self-attention"><a href="#Self-attention" class="headerlink" title="Self-attention"></a>Self-attention</h2><p>解决问题：network input is a set of vectors not a vector</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223161320964.png" srcset="/img/loading.gif" lazyload alt="image-20230223161320964"></p>
<p>例子：文字处理，假设处理的是句子每个句子的长度都不一样，将句子每一个词汇都描绘成向量，则句子是一个Vector Set</p>
<p>如何将词汇表示成向量？—One-hot Encoding，问题假设每个词汇之间没有关系</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223162805885.png" srcset="/img/loading.gif" lazyload alt="image-20230223162805885"></p>
<p>例子2：声音讯号</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223163103560.png" srcset="/img/loading.gif" lazyload alt="image-20230223163103560"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223163644962.png" srcset="/img/loading.gif" lazyload alt="image-20230223163644962"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223164116773.png" srcset="/img/loading.gif" lazyload alt="image-20230223164116773"></p>
<p>![image-20230223164131670](D:\人工智能\photo\pytorch md\image-20230223164131670.png)</p>
<h3 id="Sequence-Labeling"><a href="#Sequence-Labeling" class="headerlink" title="Sequence Labeling"></a>Sequence Labeling</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223164432190.png" srcset="/img/loading.gif" lazyload alt="image-20230223164432190"></p>
<h3 id="Self-attention-1"><a href="#Self-attention-1" class="headerlink" title="Self-attention"></a>Self-attention</h3><p><strong>How working?</strong></p>
<p>self-attention会接收一整个sequence资料，input 多少vector就输出多少vector，输出vector考虑一整个sequence得到。</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223164858274.png" srcset="/img/loading.gif" lazyload alt="image-20230223164858274"></p>
<p>self-attention可以很多次，fully connection network和self-attention可以交替使用，fully connection network处理某一位置资料，self-attention处理整个sequence</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223165123881.png" srcset="/img/loading.gif" lazyload alt="image-20230223165123881"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223165253237.png" srcset="/img/loading.gif" lazyload alt="image-20230223165253237"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223165405133.png" srcset="/img/loading.gif" lazyload alt="image-20230223165405133"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223170452941.png" srcset="/img/loading.gif" lazyload alt="image-20230223170452941"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223170706124.png" srcset="/img/loading.gif" lazyload alt="image-20230223170706124"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223170837944.png" srcset="/img/loading.gif" lazyload alt="image-20230223170837944"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223173855690.png" srcset="/img/loading.gif" lazyload alt="image-20230223173855690"></p>
<p>从矩阵乘法解释Self-attention：</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223180959958.png" srcset="/img/loading.gif" lazyload alt="image-20230223180959958"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223181544814.png" srcset="/img/loading.gif" lazyload alt="image-20230223181544814"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230224163731902.png" srcset="/img/loading.gif" lazyload alt="image-20230224163731902"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230224164123140.png" srcset="/img/loading.gif" lazyload alt="image-20230224164123140"></p>
<h4 id="Multi-head-Self-attention"><a href="#Multi-head-Self-attention" class="headerlink" title="Multi-head Self-attention"></a>Multi-head Self-attention</h4><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230224164758954.png" srcset="/img/loading.gif" lazyload alt="image-20230224164758954"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230224164821859.png" srcset="/img/loading.gif" lazyload alt="image-20230224164821859"></p>
<p>Self attention没有位置信息</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230224165938999.png" srcset="/img/loading.gif" lazyload alt="image-20230224165938999"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230224170054154.png" srcset="/img/loading.gif" lazyload alt="image-20230224170054154"></p>
<p>语言辨识：输入向量会很大，只看很小范围。</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230224170251429.png" srcset="/img/loading.gif" lazyload alt="image-20230224170251429"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230224171004645.png" srcset="/img/loading.gif" lazyload alt="image-20230224171004645"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230224171217528.png" srcset="/img/loading.gif" lazyload alt="image-20230224171217528"></p>
<p>CNN是self-attention的特例</p>
<p>Self-attention与CNN比较，模型复杂，容易过拟合</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230224171522251.png" srcset="/img/loading.gif" lazyload alt="image-20230224171522251"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230224174602637.png" srcset="/img/loading.gif" lazyload alt="image-20230224174602637"></p>
<h3 id="各式各样的Attention"><a href="#各式各样的Attention" class="headerlink" title="各式各样的Attention"></a>各式各样的Attention</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227155038921.png" srcset="/img/loading.gif" lazyload alt="image-20230227155038921"></p>
<p>N×N的计算量特别大</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227155812871.png" srcset="/img/loading.gif" lazyload alt="image-20230227155812871"></p>
<p>当Input的N非常大时，以下的处理才会很有效果。</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227161036092.png" srcset="/img/loading.gif" lazyload alt="image-20230227161036092"></p>
<p>####Skip Some Calculations</p>
<p>N×N矩阵中有些位置不需要计算</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227161214393.png" srcset="/img/loading.gif" lazyload alt="image-20230227161214393"></p>
<h5 id="Local-Attention-Truncated-Attention"><a href="#Local-Attention-Truncated-Attention" class="headerlink" title="Local Attention&#x2F;Truncated Attention"></a>Local Attention&#x2F;Truncated Attention</h5><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227161430915.png" srcset="/img/loading.gif" lazyload alt="image-20230227161430915"></p>
<p>每次attention只能看见小范围，与CNN相似</p>
<h5 id="Stride-Attention"><a href="#Stride-Attention" class="headerlink" title="Stride Attention"></a>Stride Attention</h5><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227161633916.png" srcset="/img/loading.gif" lazyload alt="image-20230227161633916"></p>
<h5 id="Global-Attention"><a href="#Global-Attention" class="headerlink" title="Global Attention"></a>Global Attention</h5><p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1VN4y1P7Zj?t=871.0&p=51">讲解 第14分钟</a></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227162251395.png" srcset="/img/loading.gif" lazyload alt="image-20230227162251395"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227162444796.png" srcset="/img/loading.gif" lazyload alt="image-20230227162444796"></p>
<p><strong>用Multi-head attention</strong></p>
<p>![image-20230227162554550]image-20230227162554550.png)</p>
<h3 id="Focous-on-Critical-Pats"><a href="#Focous-on-Critical-Pats" class="headerlink" title="Focous on Critical Pats"></a>Focous on Critical Pats</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227162752928.png" srcset="/img/loading.gif" lazyload alt="image-20230227162752928"></p>
<h4 id="Clustering"><a href="#Clustering" class="headerlink" title="Clustering"></a>Clustering</h4><p>相近的vector属于相同的cluster，不相近的属于不同的cluster。</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227163049571.png" srcset="/img/loading.gif" lazyload alt="image-20230227163049571"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227163128433.png" srcset="/img/loading.gif" lazyload alt="image-20230227163128433"></p>
<h3 id="Learnable-Patterns"><a href="#Learnable-Patterns" class="headerlink" title="Learnable Patterns"></a>Learnable Patterns</h3><p>通过Learned计算哪些地方需要计算</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227163638822.png" srcset="/img/loading.gif" lazyload alt="image-20230227163638822"></p>
<p>Sinkhorn Sorting Network如何实现加速的？<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1VN4y1P7Zj?t=1802.4&p=51">解释 第28分钟</a></p>
<h3 id="Do-we-need-full-attention-matrix"><a href="#Do-we-need-full-attention-matrix" class="headerlink" title="Do we need full attention matrix?"></a>Do we need full attention matrix?</h3><p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1VN4y1P7Zj?t=1802.4&p=51">定位 第31分钟</a></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227164502837.png" srcset="/img/loading.gif" lazyload alt="image-20230227164502837"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227164543048.png" srcset="/img/loading.gif" lazyload alt="image-20230227164543048"></p>
<p> <img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227164613934.png" srcset="/img/loading.gif" lazyload alt="image-20230227164613934"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227164942378.png" srcset="/img/loading.gif" lazyload alt="image-20230227164942378"></p>
<p>处理query根据问题考虑，若是作业2那种会减少label数量</p>
<h4 id="Reduce-Nember-of-Keys"><a href="#Reduce-Nember-of-Keys" class="headerlink" title="Reduce Nember of Keys"></a>Reduce Nember of Keys</h4><p>![image-20230227171901971]image-20230227171901971.png)</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227172155132.png" srcset="/img/loading.gif" lazyload alt="image-20230227172155132"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227172136198.png" srcset="/img/loading.gif" lazyload alt="image-20230227172136198"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227172326858.png" srcset="/img/loading.gif" lazyload alt="image-20230227172326858"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227172435027.png" srcset="/img/loading.gif" lazyload alt="image-20230227172435027"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227172633979.png" srcset="/img/loading.gif" lazyload alt="image-20230227172633979"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227173058847.png" srcset="/img/loading.gif" lazyload alt="image-20230227173058847"></p>
<p>![image-20230227173153780](D:\人工智能\photo\pytorch md\image-20230227173153780.png)</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227173605771.png" srcset="/img/loading.gif" lazyload alt="image-20230227173605771"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227174638919.png" srcset="/img/loading.gif" lazyload alt="image-20230227174638919"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227175224594.png" srcset="/img/loading.gif" lazyload alt="image-20230227175224594"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227175551056.png" srcset="/img/loading.gif" lazyload alt="image-20230227175551056"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227175834055.png" srcset="/img/loading.gif" lazyload alt="image-20230227175834055"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227175849100.png" srcset="/img/loading.gif" lazyload alt="image-20230227175849100"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227180202579.png" srcset="/img/loading.gif" lazyload alt="image-20230227180202579"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227180222407.png" srcset="/img/loading.gif" lazyload alt="image-20230227180222407"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227180355433.png" srcset="/img/loading.gif" lazyload alt="image-20230227180355433"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227180413220.png" srcset="/img/loading.gif" lazyload alt="image-20230227180413220"></p>
<h4 id="Synthesizer"><a href="#Synthesizer" class="headerlink" title="Synthesizer"></a>Synthesizer</h4><h2 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h2><p><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=xCGidAeyS4M">RNN PART1</a></p>
<p><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=rTqmWlnwz_0">RNN PART2</a></p>
<h3 id="Example-Application"><a href="#Example-Application" class="headerlink" title="Example Application"></a>Example Application</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824094358392.png" srcset="/img/loading.gif" lazyload alt="image-20230824094358392"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824094857191.png" srcset="/img/loading.gif" lazyload alt="image-20230824094857191"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824094637898.png" srcset="/img/loading.gif" lazyload alt="image-20230824094637898"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824094806665.png" srcset="/img/loading.gif" lazyload alt="image-20230824094806665"></p>
<p>希望神经网络是有记忆的：如输入台北只能输出是目的地而不能分辨此时的台北是出发地还是到达地</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824095157640.png" srcset="/img/loading.gif" lazyload alt="image-20230824095157640"></p>
<p>###ElmanNetwork</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824095752464.png" srcset="/img/loading.gif" lazyload alt="image-20230824095752464"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824100037972.png" srcset="/img/loading.gif" lazyload alt="image-20230824100037972"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824100110111.png" srcset="/img/loading.gif" lazyload alt="image-20230824100110111"></p>
<p> <img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824100146747.png" srcset="/img/loading.gif" lazyload alt="image-20230824100146747"></p>
<h3 id="Jordan-Network"><a href="#Jordan-Network" class="headerlink" title="Jordan Network"></a>Jordan Network</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824100319375.png" srcset="/img/loading.gif" lazyload alt="image-20230824100319375"></p>
<p>Jordan Network学习效果可能比较好</p>
<h3 id="Bidirectional-RNN"><a href="#Bidirectional-RNN" class="headerlink" title="Bidirectional RNN"></a>Bidirectional RNN</h3><p>产生输出时看的学习到的范围比较广</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824100517783.png" srcset="/img/loading.gif" lazyload alt="image-20230824100517783"></p>
<h3 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h3><p>Long Short-term MEMORY</p>
<p>Input Gate：只有打开时才能将值写入Memory Cell，打开关闭可以有NN自己学习</p>
<p>Output Gate：决定外界可不可以将值读出来</p>
<p>Forget Gate：决定何时将Memory Cell忘掉，打开时代表记住，关闭代表遗忘</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824101358392.png" srcset="/img/loading.gif" lazyload alt="image-20230824101358392"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824101956681.png" srcset="/img/loading.gif" lazyload alt="image-20230824101956681"></p>
<p>激活函数通常旋转sigmoid是因为此值在0-1.可以代表打开程度</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824102122860.png" srcset="/img/loading.gif" lazyload alt="image-20230824102122860"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824102428705.png" srcset="/img/loading.gif" lazyload alt="image-20230824102428705"></p>
<h3 id="Difference-between-RNN-and-LSTM"><a href="#Difference-between-RNN-and-LSTM" class="headerlink" title="Difference between RNN and LSTM"></a>Difference between RNN and LSTM</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824102900519.png" srcset="/img/loading.gif" lazyload alt="image-20230824102900519"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824102825524.png" srcset="/img/loading.gif" lazyload alt="image-20230824102825524"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824103223033.png" srcset="/img/loading.gif" lazyload alt="image-20230824103223033"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824103345925.png" srcset="/img/loading.gif" lazyload alt="image-20230824103345925"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824103442370.png" srcset="/img/loading.gif" lazyload alt="image-20230824103442370"></p>
<h3 id="Multiple-layer-LSTM"><a href="#Multiple-layer-LSTM" class="headerlink" title="Multiple-layer LSTM"></a>Multiple-layer LSTM</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824103522067.png" srcset="/img/loading.gif" lazyload alt="image-20230824103522067"></p>
<h3 id="Learning-Target"><a href="#Learning-Target" class="headerlink" title="Learning Target"></a>Learning Target</h3><p>结果的cost:每个RNN的output和reference vector的cross entropy和 去minimize</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824105847788.png" srcset="/img/loading.gif" lazyload alt="image-20230824105847788"></p>
<h3 id="BPTT"><a href="#BPTT" class="headerlink" title="BPTT"></a>BPTT</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824110021184.png" srcset="/img/loading.gif" lazyload alt="image-20230824110021184"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824110158861.png" srcset="/img/loading.gif" lazyload alt="image-20230824110158861"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824110322220.png" srcset="/img/loading.gif" lazyload alt="image-20230824110322220"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824110554974.png" srcset="/img/loading.gif" lazyload alt="image-20230824110554974"></p>
<p>Clipping： 当gradient大于某个threshold时，就不要超过threshold</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824111209049.png" srcset="/img/loading.gif" lazyload alt="image-20230824111209049"></p>
<p>为什么RNN误差会很崎岖：RNN训练问题，源自在时间和时间转换transition时反复使用，从memory接到neuron的一组weight反复被使用，所以ｗ有变化，则会产生如上图gradient会有时很大有时很小</p>
<p>使用LSTM时候可以避免gradient平坦，因此可以将ｌｅａｒｎｉｎｇ　ｒａｔｅ设的小，如下图</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824112210517.png" srcset="/img/loading.gif" lazyload alt="image-20230824112210517"></p>
<p>参数多可能会带来Over fitting的情况</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824112329435.png" srcset="/img/loading.gif" lazyload alt="image-20230824112329435"></p>
<h2 id="GNN"><a href="#GNN" class="headerlink" title="GNN"></a>GNN</h2><p>暂时略过</p>
<h2 id="Quick-Introduction-of-Batch-Normalization"><a href="#Quick-Introduction-of-Batch-Normalization" class="headerlink" title="Quick Introduction of Batch Normalization"></a>Quick Introduction of Batch Normalization</h2><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226104124832.png" srcset="/img/loading.gif" lazyload alt="image-20230226104124832"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226104007327.png" srcset="/img/loading.gif" lazyload alt="image-20230226104007327"></p>
<p>难训练</p>
<p>给feature中不同的dimension，有同样的数值范围。</p>
<h3 id="Feature-Normalization"><a href="#Feature-Normalization" class="headerlink" title="Feature Normalization"></a>Feature Normalization</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226104721560.png" srcset="/img/loading.gif" lazyload alt="image-20230226104721560"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226104935859.png" srcset="/img/loading.gif" lazyload alt="image-20230226104935859"></p>
<p>x正规化后，W作用也可能会使训练困难，feature Normalization可以选择在激活函数之前或之后；选择sigmoid做激活函数推荐对z做feature Normalization。</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226105226151.png" srcset="/img/loading.gif" lazyload alt="image-20230226105226151"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226105254442.png" srcset="/img/loading.gif" lazyload alt="image-20230226105254442"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226105619749.png" srcset="/img/loading.gif" lazyload alt="image-20230226105619749"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226105830567.png" srcset="/img/loading.gif" lazyload alt="image-20230226105830567"></p>
<p>β、γ使Z均值不为0，β初始值1，γ初始值0.</p>
<h3 id="Batch-Normalization-—Testing"><a href="#Batch-Normalization-—Testing" class="headerlink" title="Batch Normalization —Testing"></a>Batch Normalization —Testing</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226110917675.png" srcset="/img/loading.gif" lazyload alt="image-20230226110917675"></p>
<h3 id="How-does-Batch-Normalization-Help-Optimization？—–Internal-Covariate-Shift？"><a href="#How-does-Batch-Normalization-Help-Optimization？—–Internal-Covariate-Shift？" class="headerlink" title="How does Batch Normalization Help Optimization？—–Internal Covariate Shift？"></a>How does Batch Normalization Help Optimization？—–Internal Covariate Shift？</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226111349311.png" srcset="/img/loading.gif" lazyload alt="image-20230226111349311"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226111523076.png" srcset="/img/loading.gif" lazyload alt="image-20230226111523076"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226111542936.png" srcset="/img/loading.gif" lazyload alt="image-20230226111542936"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226120807141.png" srcset="/img/loading.gif" lazyload alt="image-20230226120807141"></p>
<h1 id="PyTorch数据集归一化-torchvision-transforms-Normalize"><a href="#PyTorch数据集归一化-torchvision-transforms-Normalize" class="headerlink" title="PyTorch数据集归一化- torchvision.transforms.Normalize()"></a><a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=PyTorch&spm=1001.2101.3001.7020">PyTorch</a>数据集归一化- torchvision.transforms.Normalize()</h1><p>Pytorch数据归一化</p>
<h3 id="图像处理为什么要归一化？"><a href="#图像处理为什么要归一化？" class="headerlink" title="图像处理为什么要归一化？"></a>图像处理为什么要归一化？</h3><p>对于网络模型训练等，是为了加速神经网络训练收敛，以及保证程序运行时收敛加快。</p>
<p>数据归一化的概念是一个通用概念，指的是将数据集的原始值转换为新值的行为。新值通常是相对于数据集本身进行编码的，并以某种方式进行缩放。</p>
<p><strong>特征缩放</strong></p>
<p>出于这个原因，有时数据归一化的另一个名称是特征缩放。这个术语指的是，在对数据进行归一化时，我们经常会将给定数据集的不同特征转化为相近的范围。</p>
<p>在这种情况下，我们不仅仅是考虑一个值的数据集，还要<strong>考虑一个具有多个特征的元素的数据集，及每个特征的值</strong>。</p>
<p>举例来说，假设我们要处理的是一个人的数据集，我们的数据集中有两个相关的特征，年龄和体重。在这种情况下，我们可以观察到，这两个特征集的大小或尺度是不同的，即体重平均大于年龄。</p>
<p>在使用机器学习算法进行比较或计算时，这种幅度上的差异可能是个问题。因此，这可能是我们希望通过特征缩放将这些特征的值缩放到一些相近尺度的原因之一。<br><strong>规范化示例</strong><br>当我们对数据集进行归一化时，我们通常会对相对于数据集的每个特定值进行某种形式的信息编码，然后重新缩放数据。考虑下面这个例子：</p>
<p>假设我们有一个正数集合 S 。现在，假设我们从集合s 随机选择一个 x 值并思考：这个 x 值是集合s中最大的数嘛 ？<br>在这种情况下，答案是我们不知道。我们只是没有足够的信息来回答问题。<br>但是，现在假设我们被告知 集合 S 通过将每个值除以集合内的最大值进行归一化。通过此标准化过程，已对值最大的信息进行了编码，并对数据进行了重新缩放。<br>集合中最大的成员是 1，并且数据已按比例缩放到间隔 [0,1]。</p>
<h2 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h2><p>Seq2Seq</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226114520352.png" srcset="/img/loading.gif" lazyload alt="image-20230226114520352"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226114631545.png" srcset="/img/loading.gif" lazyload alt="image-20230226114631545"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226114703556.png" srcset="/img/loading.gif" lazyload alt="image-20230226114703556"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226115110295.png" srcset="/img/loading.gif" lazyload alt="image-20230226115110295"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226115738607.png" srcset="/img/loading.gif" lazyload alt="image-20230226115738607"></p>
<p>###Seq2seq</p>
<p>  <img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226115959555.png" srcset="/img/loading.gif" lazyload alt="image-20230226115959555"></p>
<h3 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226120051473.png" srcset="/img/loading.gif" lazyload alt="image-20230226120051473"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226120145462.png" srcset="/img/loading.gif" lazyload alt="image-20230226120145462"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226121013255.png" srcset="/img/loading.gif" lazyload alt="image-20230226121013255"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226121054634.png" srcset="/img/loading.gif" lazyload alt="image-20230226121054634"></p>
<h3 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h3><p>Decoder:把Encoder产生的输出都读进去，</p>
<p>BEGIN（special token）：Decoder开始符号，</p>
<h4 id="Autoregressive-AT"><a href="#Autoregressive-AT" class="headerlink" title="Autoregressive(AT)"></a>Autoregressive(AT)</h4><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227142225440.png" srcset="/img/loading.gif" lazyload alt="image-20230227142225440"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227142303877.png" srcset="/img/loading.gif" lazyload alt="image-20230227142303877"></p>
<p>Decoder看见的输入其实是前一个时间点自己的输出</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227142315802.png" srcset="/img/loading.gif" lazyload alt="image-20230227142315802"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227142519206.png" srcset="/img/loading.gif" lazyload alt="image-20230227142519206"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227142537156.png" srcset="/img/loading.gif" lazyload alt="image-20230227142537156"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227142630739.png" srcset="/img/loading.gif" lazyload alt="image-20230227142630739"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227142737083.png" srcset="/img/loading.gif" lazyload alt="image-20230227142737083"></p>
<p><strong>Masked</strong>：产生b<del>i</del>时候，不能看比i大的信息</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227142843045.png" srcset="/img/loading.gif" lazyload alt="image-20230227142843045"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227142906032.png" srcset="/img/loading.gif" lazyload alt="image-20230227142906032"></p>
<p><strong>Why masked?</strong> Consider how does decoder work.</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227143253075.png" srcset="/img/loading.gif" lazyload alt="image-20230227143253075"></p>
<p><strong>Adding “Stop Token”</strong></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227143441165.png" srcset="/img/loading.gif" lazyload alt="image-20230227143441165"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227143456890.png" srcset="/img/loading.gif" lazyload alt="image-20230227143456890"></p>
<h4 id="NAT-Non-autoregressive"><a href="#NAT-Non-autoregressive" class="headerlink" title="NAT Non-autoregressive"></a>NAT Non-autoregressive</h4><p>一次把整个句子产生出来</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227143706330.png" srcset="/img/loading.gif" lazyload alt="image-20230227143706330"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227144034589.png" srcset="/img/loading.gif" lazyload alt="image-20230227144034589"></p>
<h3 id="Encoder-2-Decoder"><a href="#Encoder-2-Decoder" class="headerlink" title="Encoder 2 Decoder"></a>Encoder 2 Decoder</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227144248632.png" srcset="/img/loading.gif" lazyload alt="image-20230227144248632"></p>
<h4 id="Cross-attention"><a href="#Cross-attention" class="headerlink" title="Cross attention"></a>Cross attention</h4><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227144501296.png" srcset="/img/loading.gif" lazyload alt="image-20230227144501296"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227144542973.png" srcset="/img/loading.gif" lazyload alt="image-20230227144542973"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227144840761.png" srcset="/img/loading.gif" lazyload alt="image-20230227144840761"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227145007530.png" srcset="/img/loading.gif" lazyload alt="image-20230227145007530"></p>
<h3 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227145101111.png" srcset="/img/loading.gif" lazyload alt="image-20230227145101111"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227145328425.png" srcset="/img/loading.gif" lazyload alt="image-20230227145328425"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227145525543.png" srcset="/img/loading.gif" lazyload alt="image-20230227145525543"></p>
<p>Decoder输入的时候，给Decoder输入正确的答案——<strong>Teacher Forcing</strong>：using the ground truth as input.</p>
<h4 id="Tips"><a href="#Tips" class="headerlink" title="Tips"></a>Tips</h4><p>#####Copy Mechanism</p>
<p>一些情况下不需要decoder创造输出出来，可能需要从输入中复制一些出来；例如聊天机器人、摘要提取</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227145849416.png" srcset="/img/loading.gif" lazyload alt="image-20230227145849416"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227145913631.png" srcset="/img/loading.gif" lazyload alt="image-20230227145913631"></p>
<p>######<strong>Pointer Network</strong></p>
<h5 id="Guided-Attention"><a href="#Guided-Attention" class="headerlink" title="Guided Attention"></a>Guided Attention</h5><p>强迫将输入的每个东西都学习</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227150907748.png" srcset="/img/loading.gif" lazyload alt="image-20230227150907748"></p>
<h5 id="Beam-Search"><a href="#Beam-Search" class="headerlink" title="Beam Search"></a>Beam Search</h5><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227151307970.png" srcset="/img/loading.gif" lazyload alt="image-20230227151307970"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227151710565.png" srcset="/img/loading.gif" lazyload alt="image-20230227151710565"></p>
<p>Beam search并不是都是结果好的，要根据任务决定，如果任务目的非常明确（语音辨识）Beam search会很有帮助，若需要一些创造（可能会有不止一个答案）随机性可能会更好。</p>
<p>TTS：语音合成</p>
<h4 id="Blue-score"><a href="#Blue-score" class="headerlink" title="Blue score"></a>Blue score</h4><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227152337680.png" srcset="/img/loading.gif" lazyload alt="image-20230227152337680"></p>
<h4 id="Exposure-bias"><a href="#Exposure-bias" class="headerlink" title="Exposure bias"></a>Exposure bias</h4><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227152453643.png" srcset="/img/loading.gif" lazyload alt="image-20230227152453643"></p>
<p>training是Decoder输入是正确的，但是测试时Decoder输入会有错误，为避免在Ground Truth加入一些错误。</p>
<h5 id="Scheduled-Sampling"><a href="#Scheduled-Sampling" class="headerlink" title="Scheduled Sampling"></a>Scheduled Sampling</h5><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227152656466.png" srcset="/img/loading.gif" lazyload alt="image-20230227152656466"></p>
<h2 id="Generation"><a href="#Generation" class="headerlink" title="Generation"></a>Generation</h2><h2 id="Reinforcement-Learning"><a href="#Reinforcement-Learning" class="headerlink" title="Reinforcement Learning"></a>Reinforcement Learning</h2><h1 id="李沐动手深度学习"><a href="#李沐动手深度学习" class="headerlink" title="李沐动手深度学习"></a>李沐动手深度学习</h1><h2 id="Resnet-残差网络"><a href="#Resnet-残差网络" class="headerlink" title="Resnet 残差网络"></a>Resnet 残差网络</h2><p>为了提到模型预测的精度，想要提高模型的复杂度如下图左所示，但是学习产生模型偏差。Resnet设计每次更复杂的模型使包含上次模型。</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230825155356180.png" srcset="/img/loading.gif" lazyload alt="image-20230825155356180"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230825155510200.png" srcset="/img/loading.gif" lazyload alt="image-20230825155510200"></p>
<p>复杂模型包含小模型。</p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230825155754620.png" srcset="/img/loading.gif" lazyload alt="image-20230825155754620"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230825155841487.png" srcset="/img/loading.gif" lazyload alt="image-20230825155841487"></p>
<p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230825160140398.png" srcset="/img/loading.gif" lazyload alt="image-20230825160140398"></p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div></div>
      <div>http://example.com/2024/10/06/pytorch框架/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>Author</div>
          <div>John Doe</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Posted on</div>
          <div>October 6, 2024</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>Licensed under</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - Attribution">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2024/01/19/%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C%E7%94%A8%E8%AF%8D/" title="">
                        <span class="hidden-mobile"></span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>Table of Contents</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>
</body>
</html>
