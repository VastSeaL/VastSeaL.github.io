<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title></title>
    <link href="/2025/07/18/Python%E5%BA%93%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/"/>
    <url>/2025/07/18/Python%E5%BA%93%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="Argparse-Tutorial"><a href="#Argparse-Tutorial" class="headerlink" title="Argparse Tutorial"></a>Argparse Tutorial</h1><p><a href="https://youtu.be/aGy7U5ItLRk">https://youtu.be/aGy7U5ItLRk</a></p><p><a href="https://docs.python.org/3/library/argparse.html?utm_source=chatgpt.com">https://docs.python.org/3/library/argparse.html?utm_source=chatgpt.com</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">from</span> argparse <span class="hljs-keyword">import</span> ArgumentParser, Namespace<br><br>parser = ArgumentParser() <span class="hljs-comment">#创建实例化解析器</span><br><br>parser.add_argument(<span class="hljs-string">&#x27;echo&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;Echos the given string&#x27;</span>)<br>parser.add_argument(<span class="hljs-string">&#x27;square&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;Squares a given number&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>)<br><br>args:Namespace = parser.parse_args() <span class="hljs-comment">#解析命令行输入</span><br>    <br><span class="hljs-built_in">print</span>(args.echo)<br><span class="hljs-built_in">print</span>(args.square ** <span class="hljs-number">2</span>)<br><br><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string"># 命令行操作</span><br><span class="hljs-string">python main.py hello</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><br><span class="hljs-comment">## END END</span><br><br><span class="hljs-keyword">from</span> argparse <span class="hljs-keyword">import</span> ArgumentParser, Namespace<br><br>parser = ArgumentParser() <span class="hljs-comment">#创建实例化解析器</span><br><br>parser.add_argument(<span class="hljs-string">&#x27;square&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;Squares a given number&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>)<br>parser.add_argument(<span class="hljs-string">&#x27;-v&#x27;</span>, <span class="hljs-string">&#x27;--verbose&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;Provides a verbose desc&#x27;</span>, action=<span class="hljs-string">&#x27;store_true&#x27;</span>)<span class="hljs-comment">#提供位置参数 #如果加入required=True 则命令行中必须提供定义</span><br><br>args:Namespace = parser.parse_args() <span class="hljs-comment">#解析命令行输入</span><br>    <br><span class="hljs-keyword">if</span> args.verbose:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;args.square&#125;</span> squared is: <span class="hljs-subst">&#123;args.square ** <span class="hljs-number">2</span>&#125;</span>&#x27;</span>)<br><span class="hljs-keyword">else</span>:<br>    <span class="hljs-built_in">print</span>(args.square ** <span class="hljs-number">2</span>)<br><br><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string"># 命令行操作</span><br><span class="hljs-string">python main.py 10</span><br><span class="hljs-string">out : 100</span><br><span class="hljs-string"></span><br><span class="hljs-string">python main.py 10 -v</span><br><span class="hljs-string">out : 10 squared is: 100</span><br><span class="hljs-string"></span><br><span class="hljs-string">python main.py -v 10  ##参数位置不重要</span><br><span class="hljs-string">out : 10 squared is: 100</span><br><span class="hljs-string"></span><br><span class="hljs-string">python main.py 10 --verbose</span><br><span class="hljs-string">out : 10 squared is: 100</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><br><span class="hljs-comment">## END END</span><br><br><span class="hljs-keyword">from</span> argparse <span class="hljs-keyword">import</span> ArgumentParser, Namespace<br><br>parser = ArgumentParser() <span class="hljs-comment">#创建实例化解析器</span><br><br>parser.add_argument(<span class="hljs-string">&#x27;square&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;Squares a given number&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>)<br>parser.add_argument(<span class="hljs-string">&#x27;-v&#x27;</span>, <span class="hljs-string">&#x27;--verbose&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;Provides a verbose desc&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, choices=[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>])<span class="hljs-comment">#提供位置参数 #如果加入required=True 则命令行中必须提供定义</span><br><br>args:Namespace = parser.parse_args() <span class="hljs-comment">#解析命令行输入</span><br>    <br><span class="hljs-keyword">if</span> args.verbose == <span class="hljs-number">0</span>:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Option 1&#x27;</span>)<br><span class="hljs-keyword">elif</span> args.verbose == <span class="hljs-number">1</span>:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Option 2&#x27;</span>)<br><span class="hljs-keyword">elif</span> args.verbose == <span class="hljs-number">2</span>:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Option 3&#x27;</span>)<br>    <br><span class="hljs-built_in">print</span>(args.square ** <span class="hljs-number">2</span>)<br><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string"># 命令行操作</span><br><span class="hljs-string">python main.py 2 -v</span><br><span class="hljs-string">out : 系统报错 expected one argument</span><br><span class="hljs-string"></span><br><span class="hljs-string">pythob main.py 2 -v 0</span><br><span class="hljs-string">out : Option 1</span><br><span class="hljs-string">4</span><br><span class="hljs-string"></span><br><span class="hljs-string">pythob main.py 2 -v 4</span><br><span class="hljs-string">out : invalid choice : 4</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><br><span class="hljs-comment">## END END</span><br><br><br><span class="hljs-keyword">from</span> argparse <span class="hljs-keyword">import</span> ArgumentParser, Namespace<br><br>parser = ArgumentParser() <span class="hljs-comment">#创建实例化解析器</span><br><br>parser.add_argument(<span class="hljs-string">&#x27;square&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;Squares a given number&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">0</span>, nargs=<span class="hljs-string">&#x27;?&#x27;</span>)<br>parser.add_argument(<span class="hljs-string">&#x27;-v&#x27;</span>, <span class="hljs-string">&#x27;--verbose&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;verbose descroption. Use -vv for extra verbose&#x27;</span>, action=<span class="hljs-string">&#x27;count&#x27;</span>)<span class="hljs-comment">#提供可选参数 #如果加入required=True 则命令行中必须提供定义</span><br><br>args:Namespace = parser.parse_args() <span class="hljs-comment">#解析命令行输入</span><br><br>result: <span class="hljs-built_in">int</span> = args.square ** <span class="hljs-number">2</span><br><span class="hljs-keyword">if</span> args.verbose == <span class="hljs-number">1</span>:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;The result is :<span class="hljs-subst">&#123;result&#125;</span>&#x27;</span>)<br><span class="hljs-keyword">elif</span> args.verbose == <span class="hljs-number">2</span>:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;args.square&#125;</span> ** <span class="hljs-subst">&#123;args.square&#125;</span> = <span class="hljs-subst">&#123;result&#125;</span>&#x27;</span>)<br><span class="hljs-keyword">else</span>:<br>    <span class="hljs-built_in">print</span>(result)<br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string"># 命令行操作</span><br><span class="hljs-string">python main.py</span><br><span class="hljs-string">out : 0</span><br><span class="hljs-string"></span><br><span class="hljs-string">pythob main.py 2 -v </span><br><span class="hljs-string">out : The result is: 4</span><br><span class="hljs-string"></span><br><span class="hljs-string">python main.py 2 -vv</span><br><span class="hljs-string">out : 2 **2 = 4</span><br><span class="hljs-string"></span><br><span class="hljs-string">python main.py 2 -vvvv</span><br><span class="hljs-string">out : 4</span><br><span class="hljs-string"></span><br><span class="hljs-string">python main.py 2 --verbose --verbose</span><br><span class="hljs-string">out : 2 **2 = 4</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><br><span class="hljs-comment">## END END</span><br><br><span class="hljs-keyword">from</span> argparse <span class="hljs-keyword">import</span> ArgumentParser, Namespace<br><br>parser = ArgumentParser() <span class="hljs-comment">#创建实例化解析器</span><br>group = parser.add_mutually_exclusive_group()<br>parser.usage = <span class="hljs-string">&quot;Use it like this&quot;</span><br><br>parser.add_argument(<span class="hljs-string">&#x27;a&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;The base value&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>)<br>parser.add_argument(<span class="hljs-string">&#x27;b&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;The exponent&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>)<br>group.add_argument(<span class="hljs-string">&#x27;-v&#x27;</span>, <span class="hljs-string">&#x27;--verbose&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;Provides a verbose descroption. Use -vv for extra verbose&#x27;</span>, action=<span class="hljs-string">&#x27;count&#x27;</span>)<br>group.add_argument(<span class="hljs-string">&#x27;-s&#x27;</span>, <span class="hljs-string">&#x27;--silence&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;Generate a silent version of the output&#x27;</span>, action=<span class="hljs-string">&#x27;store_true&#x27;</span>) <span class="hljs-comment">#group 告诉程序使得在给定时刻只运行其中一个选项</span><br><br>args: Namespace = parser.parse_args()<br>result:<span class="hljs-built_in">int</span> = args.a ** args.b<br><br><span class="hljs-keyword">if</span> args.silence:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Silenced!&#x27;</span>)<br><span class="hljs-keyword">else</span>:<br>    <span class="hljs-keyword">match</span> args.verbose:<br>        <span class="hljs-keyword">case</span> <span class="hljs-number">1</span>:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;The result is <span class="hljs-subst">&#123;result&#125;</span>&#x27;</span>)<br>        <span class="hljs-keyword">case</span> <span class="hljs-number">2</span>:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;args.a0&#125;</span> ** <span class="hljs-subst">&#123;args.b&#125;</span> == <span class="hljs-subst">&#123;result&#125;</span>&#x27;</span>)<br>        <span class="hljs-keyword">case</span> _:<br>            <span class="hljs-built_in">print</span>(result)<br></code></pre></td></tr></table></figure><p><img src="/Python%E5%BA%93%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/image-20250718153326180.png" alt="image-20250718153326180"></p><p><img src="/Python%E5%BA%93%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/image-20250718154021928.png" alt="image-20250718154021928"></p><p><img src="/Python%E5%BA%93%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/image-20250718154036497.png" alt="image-20250718154036497"></p><p><img src="/Python%E5%BA%93%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/image-20250718154052971.png" alt="image-20250718154052971"></p><p><img src="/Python%E5%BA%93%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/image-20250718154115195.png" alt="image-20250718154115195"></p><p><img src="/Python%E5%BA%93%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/image-20250718154124967.png" alt="image-20250718154124967"></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2024/10/11/Python%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    <url>/2024/10/11/Python%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/</url>
    
    <content type="html"><![CDATA[<h1 id="Matplotlib"><a href="#Matplotlib" class="headerlink" title="Matplotlib"></a>Matplotlib</h1><p>##2.1matplotlib之HelloWorld</p><h3 id="2-1-1什么是matplotlob"><a href="#2-1-1什么是matplotlob" class="headerlink" title="2.1.1什么是matplotlob"></a>2.1.1什么是matplotlob</h3><p>专门用于开发2D（3D）图标</p><p>使用起来简单</p><p>以渐进、交互方式实现数据可视化</p><p>数据可视化——帮助理解数据，方便选择更适合的分析方法</p><p>js库： D3  echarts</p><h3 id="matplotlib图像结构"><a href="#matplotlib图像结构" class="headerlink" title="matplotlib图像结构"></a>matplotlib图像结构</h3><h4 id="matplotlib三层结构"><a href="#matplotlib三层结构" class="headerlink" title="matplotlib三层结构"></a>matplotlib三层结构</h4><p>​1、容器层</p><p>​画板层(Canvas )：位于最底层，用户一般接触不到</p><p>​画布层（FIgure) :plt.figure()建立在Canvas之上</p><p>​绘图区(AXES)、坐标系(axis)pil.subplots()</p><p>​x、y轴张成的区域</p><p>​2、辅助显示层</p><p>​3、图像层</p><p>​根据函数绘制图像</p><h2 id="折线图绘制-plot-与基础绘图功能"><a href="#折线图绘制-plot-与基础绘图功能" class="headerlink" title="折线图绘制(plot)与基础绘图功能"></a>折线图绘制(plot)与基础绘图功能</h2><h3 id="基本步骤"><a href="#基本步骤" class="headerlink" title="基本步骤"></a>基本步骤</h3><p>1、创建画布</p><p>2、绘制图像</p><p>3、显示图像</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#1创建画布</span><br>plt.figure(figsize=(<span class="hljs-number">20</span>,<span class="hljs-number">8</span>),dpi=<span class="hljs-number">80</span>)<br><span class="hljs-comment">### figsize : 画布大小</span><br><span class="hljs-comment">### dpi : dot per inch 图像的清晰度,每英寸显示点数</span><br><span class="hljs-comment">#2绘制图像</span><br>plt.plot([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>],[<span class="hljs-number">6</span>,<span class="hljs-number">7</span>,<span class="hljs-number">8</span>,<span class="hljs-number">9</span>,<span class="hljs-number">10</span>])<br><br><span class="hljs-comment">#保存图像(注意保存图片代码应位于plt.show()之前)</span><br>plt.savefig(<span class="hljs-string">&quot;test.png&quot;</span>)<br><br><span class="hljs-comment">#3显示图像</span><br>plt.show()<br><span class="hljs-comment">#plt.show()会释放figsure资源</span><br></code></pre></td></tr></table></figure><h3 id="完善原始折线图（辅助显示层）"><a href="#完善原始折线图（辅助显示层）" class="headerlink" title="完善原始折线图（辅助显示层）"></a>完善原始折线图（辅助显示层）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 需求：再添加一个城市的温度变化</span><br><span class="hljs-comment"># 收集到北京当天温度变化情况，温度在1度到3度。 </span><br><br><span class="hljs-comment"># 1、准备数据 x y</span><br>x = <span class="hljs-built_in">range</span>(<span class="hljs-number">60</span>)<br>y_shanghai = [random.uniform(<span class="hljs-number">15</span>, <span class="hljs-number">18</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> x]<br>y_beijing = [random.uniform(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> x]<br><br><span class="hljs-comment"># 中文显示问题</span><br>plt.rcParams[<span class="hljs-string">&#x27;font.sans-serif&#x27;</span>]=[<span class="hljs-string">&#x27;SimHei&#x27;</span>] <span class="hljs-comment">#用来正常显示中文标签</span><br>plt.rcParams[<span class="hljs-string">&#x27;axes.unicode_minus&#x27;</span>]=<span class="hljs-literal">False</span> <span class="hljs-comment">#用来正常显示负号</span><br><br><br><span class="hljs-comment"># 2、创建画布</span><br>plt.figure(figsize=(<span class="hljs-number">20</span>, <span class="hljs-number">8</span>), dpi=<span class="hljs-number">80</span>)<br><br><span class="hljs-comment"># 3、绘制图像</span><br>plt.plot(x, y_shanghai, color=<span class="hljs-string">&quot;r&quot;</span>, linestyle=<span class="hljs-string">&quot;-.&quot;</span>, label=<span class="hljs-string">&quot;上海&quot;</span>)<br>plt.plot(x, y_beijing, color=<span class="hljs-string">&quot;b&quot;</span>, label=<span class="hljs-string">&quot;北京&quot;</span>)<br><br><span class="hljs-comment"># 显示图例，这里显示图例的前提是plt.plot时要添加标签lsbel=“”</span><br>plt.legend()<span class="hljs-comment">#legend有自己的参数可以控制图例位置</span><br><br><span class="hljs-comment"># 修改x、y刻度</span><br><span class="hljs-comment"># 准备x的刻度说明  ticks表示刻度</span><br>x_label = [<span class="hljs-string">&quot;11点&#123;&#125;分&quot;</span>.<span class="hljs-built_in">format</span>(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> x]<br>plt.xticks(x[::<span class="hljs-number">5</span>], x_label[::<span class="hljs-number">5</span>])<br><span class="hljs-comment">#步长为5，即不让刻度显示过于密集第一处的x[::5]也要写，应该是用来给x_label定位的</span><br>plt.yticks(<span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-number">40</span>, <span class="hljs-number">5</span>))<br><br><span class="hljs-comment"># 添加网格显示，其中的alpha是网格的透明程度</span><br>plt.grid(linestyle=<span class="hljs-string">&quot;--&quot;</span>, alpha=<span class="hljs-number">0.5</span>)<br><br><span class="hljs-comment"># 添加描述信息</span><br>plt.xlabel(<span class="hljs-string">&quot;时间变化&quot;</span>)<br>plt.ylabel(<span class="hljs-string">&quot;温度变化&quot;</span>)<br>plt.title(<span class="hljs-string">&quot;上海、北京11点到12点每分钟的温度变化状况&quot;</span>)<br><br><span class="hljs-comment"># 4、显示图</span><br>plt.show()<br><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 需求：再添加一个城市的温度变化</span><br><span class="hljs-comment"># 收集到北京当天温度变化情况，温度在1度到3度。 </span><br><br><span class="hljs-comment"># 1、准备数据 x y</span><br>x = <span class="hljs-built_in">range</span>(<span class="hljs-number">60</span>)<br>y_shanghai = [random.uniform(<span class="hljs-number">15</span>, <span class="hljs-number">18</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> x]<br>y_beijing = [random.uniform(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> x]<br><br><span class="hljs-comment"># 中文显示问题</span><br>plt.rcParams[<span class="hljs-string">&#x27;font.sans-serif&#x27;</span>]=[<span class="hljs-string">&#x27;SimHei&#x27;</span>] <span class="hljs-comment">#用来正常显示中文标签</span><br>plt.rcParams[<span class="hljs-string">&#x27;axes.unicode_minus&#x27;</span>]=<span class="hljs-literal">False</span> <span class="hljs-comment">#用来正常显示负号</span><br><br><br><span class="hljs-comment"># 2、创建画布</span><br>plt.figure(figsize=(<span class="hljs-number">20</span>, <span class="hljs-number">8</span>), dpi=<span class="hljs-number">80</span>)<br><br><span class="hljs-comment"># 3、绘制图像</span><br>plt.plot(x, y_shanghai, color=<span class="hljs-string">&quot;r&quot;</span>, linestyle=<span class="hljs-string">&quot;-.&quot;</span>, label=<span class="hljs-string">&quot;上海&quot;</span>)<br>plt.plot(x, y_beijing, color=<span class="hljs-string">&quot;b&quot;</span>, label=<span class="hljs-string">&quot;北京&quot;</span>)<br><br><span class="hljs-comment"># 显示图例，这里显示图例的前提是plt.plot时要添加标签lsbel=“”</span><br>plt.legend()<span class="hljs-comment">#legend有自己的参数可以控制图例位置</span><br><br><span class="hljs-comment"># 修改x、y刻度</span><br><span class="hljs-comment"># 准备x的刻度说明  ticks表示刻度</span><br>x_label = [<span class="hljs-string">&quot;11点&#123;&#125;分&quot;</span>.<span class="hljs-built_in">format</span>(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> x]<br>plt.xticks(x[::<span class="hljs-number">5</span>], x_label[::<span class="hljs-number">5</span>])<br><span class="hljs-comment">#步长为5，即不让刻度显示过于密集第一处的x[::5]也要写，应该是用来给x_label定位的</span><br>plt.yticks(<span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-number">40</span>, <span class="hljs-number">5</span>))<br><br><span class="hljs-comment"># 添加网格显示，其中的alpha是网格的透明程度</span><br>plt.grid(linestyle=<span class="hljs-string">&quot;--&quot;</span>, alpha=<span class="hljs-number">0.5</span>)<br><br><span class="hljs-comment"># 添加描述信息</span><br>plt.xlabel(<span class="hljs-string">&quot;时间变化&quot;</span>)<br>plt.ylabel(<span class="hljs-string">&quot;温度变化&quot;</span>)<br>plt.title(<span class="hljs-string">&quot;上海、北京11点到12点每分钟的温度变化状况&quot;</span>)<br><br><span class="hljs-comment"># 4、显示图</span><br>plt.show()<br><br></code></pre></td></tr></table></figure><h3 id="多个坐标系显示-plt-subplots（面向对象的画图方法）"><a href="#多个坐标系显示-plt-subplots（面向对象的画图方法）" class="headerlink" title="多个坐标系显示-plt.subplots（面向对象的画图方法）"></a>多个坐标系显示-plt.subplots（面向对象的画图方法）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#主要区别：</span><br><span class="hljs-comment">#figure, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 8), dpi=80)</span><br><br><span class="hljs-comment"># 需求：再添加一个城市的温度变化</span><br><span class="hljs-comment"># 收集到北京当天温度变化情况，温度在1度到3度。 </span><br><br><span class="hljs-comment"># 1、准备数据 x y</span><br>x = <span class="hljs-built_in">range</span>(<span class="hljs-number">60</span>)<br>y_shanghai = [random.uniform(<span class="hljs-number">15</span>, <span class="hljs-number">18</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> x]<br>y_beijing = [random.uniform(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> x]<br><br><span class="hljs-comment"># 2、创建画布</span><br><span class="hljs-comment"># plt.figure(figsize=(20, 8), dpi=80)</span><br>figure, axes = plt.subplots(nrows=<span class="hljs-number">1</span>, ncols=<span class="hljs-number">2</span>, figsize=(<span class="hljs-number">20</span>, <span class="hljs-number">8</span>), dpi=<span class="hljs-number">80</span>)<br><br><span class="hljs-comment"># 3、绘制图像</span><br>axes[<span class="hljs-number">0</span>].plot(x, y_shanghai, color=<span class="hljs-string">&quot;r&quot;</span>, linestyle=<span class="hljs-string">&quot;-.&quot;</span>, label=<span class="hljs-string">&quot;上海&quot;</span>)<br>axes[<span class="hljs-number">1</span>].plot(x, y_beijing, color=<span class="hljs-string">&quot;b&quot;</span>, label=<span class="hljs-string">&quot;北京&quot;</span>)<br><br><span class="hljs-comment"># 显示图例</span><br>axes[<span class="hljs-number">0</span>].legend()<br>axes[<span class="hljs-number">1</span>].legend()<br><br><span class="hljs-comment"># 修改x、y刻度</span><br><span class="hljs-comment"># 准备x的刻度说明</span><br>x_label = [<span class="hljs-string">&quot;11点&#123;&#125;分&quot;</span>.<span class="hljs-built_in">format</span>(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> x]<br>axes[<span class="hljs-number">0</span>].set_xticks(x[::<span class="hljs-number">5</span>])<br>axes[<span class="hljs-number">0</span>].set_xticklabels(x_label)<br>axes[<span class="hljs-number">0</span>].set_yticks(<span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-number">40</span>, <span class="hljs-number">5</span>))<br>axes[<span class="hljs-number">1</span>].set_xticks(x[::<span class="hljs-number">5</span>])<br>axes[<span class="hljs-number">1</span>].set_xticklabels(x_label)<br>axes[<span class="hljs-number">1</span>].set_yticks(<span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-number">40</span>, <span class="hljs-number">5</span>))<br><br><span class="hljs-comment"># 添加网格显示</span><br>axes[<span class="hljs-number">0</span>].grid(linestyle=<span class="hljs-string">&quot;--&quot;</span>, alpha=<span class="hljs-number">0.5</span>)<br>axes[<span class="hljs-number">1</span>].grid(linestyle=<span class="hljs-string">&quot;--&quot;</span>, alpha=<span class="hljs-number">0.5</span>)<br><br><span class="hljs-comment"># 添加描述信息</span><br>axes[<span class="hljs-number">0</span>].set_xlabel(<span class="hljs-string">&quot;时间变化&quot;</span>)<br>axes[<span class="hljs-number">0</span>].set_ylabel(<span class="hljs-string">&quot;温度变化&quot;</span>)<br>axes[<span class="hljs-number">0</span>].set_title(<span class="hljs-string">&quot;上海11点到12点每分钟的温度变化状况&quot;</span>)<br>axes[<span class="hljs-number">1</span>].set_xlabel(<span class="hljs-string">&quot;时间变化&quot;</span>)<br>axes[<span class="hljs-number">1</span>].set_ylabel(<span class="hljs-string">&quot;温度变化&quot;</span>)<br>axes[<span class="hljs-number">1</span>].set_title(<span class="hljs-string">&quot;北京11点到12点每分钟的温度变化状况&quot;</span>)<br><br><span class="hljs-comment"># 4、显示图</span><br>plt.show()<br><br></code></pre></td></tr></table></figure><h2 id="常见图形种类及意义"><a href="#常见图形种类及意义" class="headerlink" title="常见图形种类及意义"></a>常见图形种类及意义</h2><p>​折线图plot</p><p>​散点图scatter</p><p>​关系&#x2F;规律</p><p>​柱状图bar</p><p>​统计&#x2F;对比</p><p>​直方图histogram</p><p>​分布状况</p><p>​饼图pie</p><p>​占比</p><h3 id="散点图绘制"><a href="#散点图绘制" class="headerlink" title="散点图绘制"></a>散点图绘制</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 需求：探究房屋面积和房屋价格的关系</span><br><br><span class="hljs-comment"># 1、准备数据</span><br>x = [<span class="hljs-number">225.98</span>, <span class="hljs-number">247.07</span>, <span class="hljs-number">253.14</span>, <span class="hljs-number">457.85</span>, <span class="hljs-number">241.58</span>, <span class="hljs-number">301.01</span>,  <span class="hljs-number">20.67</span>, <span class="hljs-number">288.64</span>,<br>       <span class="hljs-number">163.56</span>, <span class="hljs-number">120.06</span>, <span class="hljs-number">207.83</span>, <span class="hljs-number">342.75</span>, <span class="hljs-number">147.9</span> ,  <span class="hljs-number">53.06</span>, <span class="hljs-number">224.72</span>,  <span class="hljs-number">29.51</span>,<br>        <span class="hljs-number">21.61</span>, <span class="hljs-number">483.21</span>, <span class="hljs-number">245.25</span>, <span class="hljs-number">399.25</span>, <span class="hljs-number">343.35</span>]<br><br>y = [<span class="hljs-number">196.63</span>, <span class="hljs-number">203.88</span>, <span class="hljs-number">210.75</span>, <span class="hljs-number">372.74</span>, <span class="hljs-number">202.41</span>, <span class="hljs-number">247.61</span>,  <span class="hljs-number">24.9</span> , <span class="hljs-number">239.34</span>,<br>       <span class="hljs-number">140.32</span>, <span class="hljs-number">104.15</span>, <span class="hljs-number">176.84</span>, <span class="hljs-number">288.23</span>, <span class="hljs-number">128.79</span>,  <span class="hljs-number">49.64</span>, <span class="hljs-number">191.74</span>,  <span class="hljs-number">33.1</span> ,<br>        <span class="hljs-number">30.74</span>, <span class="hljs-number">400.02</span>, <span class="hljs-number">205.35</span>, <span class="hljs-number">330.64</span>, <span class="hljs-number">283.45</span>]<br><span class="hljs-comment"># 2、创建画布</span><br>plt.figure(figsize=(<span class="hljs-number">20</span>, <span class="hljs-number">8</span>), dpi=<span class="hljs-number">80</span>)<br><br><span class="hljs-comment"># 3、绘制图像</span><br>plt.scatter(x, y)<br><br><span class="hljs-comment"># 4、显示图像</span><br>plt.show()<br><br></code></pre></td></tr></table></figure><h2 id="柱状图绘制"><a href="#柱状图绘制" class="headerlink" title="柱状图绘制"></a>柱状图绘制</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">##绘制票房分布直方图</span><br><br><span class="hljs-comment"># 1、准备数据</span><br>movie_names = [<span class="hljs-string">&#x27;雷神3：诸神黄昏&#x27;</span>,<span class="hljs-string">&#x27;正义联盟&#x27;</span>,<span class="hljs-string">&#x27;东方快车谋杀案&#x27;</span>,<span class="hljs-string">&#x27;寻梦环游记&#x27;</span>,<span class="hljs-string">&#x27;全球风暴&#x27;</span>, <span class="hljs-string">&#x27;降魔传&#x27;</span>,<span class="hljs-string">&#x27;追捕&#x27;</span>,<span class="hljs-string">&#x27;七十七天&#x27;</span>,<span class="hljs-string">&#x27;密战&#x27;</span>,<span class="hljs-string">&#x27;狂兽&#x27;</span>,<span class="hljs-string">&#x27;其它&#x27;</span>]<br>tickets = [<span class="hljs-number">73853</span>,<span class="hljs-number">57767</span>,<span class="hljs-number">22354</span>,<span class="hljs-number">15969</span>,<span class="hljs-number">14839</span>,<span class="hljs-number">8725</span>,<span class="hljs-number">8716</span>,<span class="hljs-number">8318</span>,<span class="hljs-number">7916</span>,<span class="hljs-number">6764</span>,<span class="hljs-number">52222</span>]<br><br><span class="hljs-comment"># 2、创建画布</span><br>plt.figure(figsize=(<span class="hljs-number">20</span>, <span class="hljs-number">8</span>), dpi=<span class="hljs-number">80</span>)<br><br><br><br><br><span class="hljs-comment"># 3、绘制柱状图</span><br>x_ticks = <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(movie_names))<br>plt.bar(x_ticks, tickets,width=[<span class="hljs-number">0.2</span> <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(x_ticks)],color=[<span class="hljs-string">&#x27;b&#x27;</span>,<span class="hljs-string">&#x27;r&#x27;</span>,<span class="hljs-string">&#x27;g&#x27;</span>,<span class="hljs-string">&#x27;y&#x27;</span>,<span class="hljs-string">&#x27;c&#x27;</span>,<span class="hljs-string">&#x27;m&#x27;</span>,<span class="hljs-string">&#x27;y&#x27;</span>,<span class="hljs-string">&#x27;k&#x27;</span>,<span class="hljs-string">&#x27;c&#x27;</span>,<span class="hljs-string">&#x27;g&#x27;</span>,<span class="hljs-string">&#x27;b&#x27;</span>])<br><span class="hljs-comment">#主要参数x列表，y列表，width列表，color列表</span><br><br><br><span class="hljs-comment"># 修改x刻度</span><br>plt.xticks(x_ticks, movie_names)<br><br><span class="hljs-comment"># 添加标题</span><br>plt.title(<span class="hljs-string">&quot;电影票房收入对比&quot;</span>)<br><br><span class="hljs-comment"># 添加网格显示</span><br>plt.grid(linestyle=<span class="hljs-string">&quot;--&quot;</span>, alpha=<span class="hljs-number">0.5</span>)<br><br><span class="hljs-comment"># 4、显示图像</span><br>plt.show()<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 1、准备数据</span><br>movie_name = [<span class="hljs-string">&#x27;雷神3：诸神黄昏&#x27;</span>,<span class="hljs-string">&#x27;正义联盟&#x27;</span>,<span class="hljs-string">&#x27;寻梦环游记&#x27;</span>]<br><br>first_day = [<span class="hljs-number">10587.6</span>,<span class="hljs-number">10062.5</span>,<span class="hljs-number">1275.7</span>]<br>first_weekend=[<span class="hljs-number">36224.9</span>,<span class="hljs-number">34479.6</span>,<span class="hljs-number">11830</span>]<br><br><span class="hljs-comment"># 2、创建画布</span><br>plt.figure(figsize=(<span class="hljs-number">20</span>, <span class="hljs-number">8</span>), dpi=<span class="hljs-number">80</span>)<br><br><span class="hljs-comment"># 3、绘制柱状图</span><br>x_ticks=[i <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>)]<br>plt.bar(x_ticks, first_day, width=<span class="hljs-number">0.2</span>, label=<span class="hljs-string">&quot;首日票房&quot;</span>)<br>plt.bar([i+<span class="hljs-number">0.2</span> <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> x_ticks], first_weekend, width=<span class="hljs-number">0.2</span>, label=<span class="hljs-string">&quot;首周票房&quot;</span>)<br><span class="hljs-comment">##########为何是i+0.2呢，因为前面设置的柱状图宽度width=0.2，为了紧密相连，同时没有重合，因此设置0.2</span><br><br><br><span class="hljs-comment"># 显示图例</span><br>plt.legend()<br><br><span class="hljs-comment"># 修改刻度,即显示坐标轴上的数字或字符，本例即显示电影名字</span><br>plt.xticks([i+<span class="hljs-number">0.1</span> <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> x_ticks], movie_name)<br><span class="hljs-comment">###########柱状图宽度为0.2，为了字符名字在中间，因此相对于前面是加了0.1</span><br><br><span class="hljs-comment"># 4、显示图像</span><br>plt.show()<br><br></code></pre></td></tr></table></figure><h2 id="直方图"><a href="#直方图" class="headerlink" title="直方图"></a>直方图</h2><p>组数：在统计数据时，我们把数据按照不同的范围分成几个组，分成的组的个数称为组数</p><p>组距：每一组两个端点的差</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 需求：电影时长分布状况</span><br><span class="hljs-comment"># 1、准备数据</span><br>time = [<span class="hljs-number">131</span>,  <span class="hljs-number">98</span>, <span class="hljs-number">125</span>, <span class="hljs-number">131</span>, <span class="hljs-number">124</span>, <span class="hljs-number">139</span>, <span class="hljs-number">131</span>, <span class="hljs-number">117</span>, <span class="hljs-number">128</span>, <span class="hljs-number">108</span>, <span class="hljs-number">135</span>, <span class="hljs-number">138</span>, <span class="hljs-number">131</span>, <span class="hljs-number">102</span>, <span class="hljs-number">107</span>, <span class="hljs-number">114</span>, <span class="hljs-number">119</span>, <span class="hljs-number">128</span>, <span class="hljs-number">121</span>, <span class="hljs-number">142</span>, <span class="hljs-number">127</span>, <span class="hljs-number">130</span>, <span class="hljs-number">124</span>, <span class="hljs-number">101</span>, <span class="hljs-number">110</span>, <span class="hljs-number">116</span>, <span class="hljs-number">117</span>, <span class="hljs-number">110</span>, <span class="hljs-number">128</span>, <span class="hljs-number">128</span>, <span class="hljs-number">115</span>,  <span class="hljs-number">99</span>, <span class="hljs-number">136</span>, <span class="hljs-number">126</span>, <span class="hljs-number">134</span>,  <span class="hljs-number">95</span>, <span class="hljs-number">138</span>, <span class="hljs-number">117</span>, <span class="hljs-number">111</span>,<span class="hljs-number">78</span>, <span class="hljs-number">132</span>, <span class="hljs-number">124</span>, <span class="hljs-number">113</span>, <span class="hljs-number">150</span>, <span class="hljs-number">110</span>, <span class="hljs-number">117</span>,  <span class="hljs-number">86</span>,  <span class="hljs-number">95</span>, <span class="hljs-number">144</span>, <span class="hljs-number">105</span>, <span class="hljs-number">126</span>, <span class="hljs-number">130</span>,<span class="hljs-number">126</span>, <span class="hljs-number">130</span>, <span class="hljs-number">126</span>, <span class="hljs-number">116</span>, <span class="hljs-number">123</span>, <span class="hljs-number">106</span>, <span class="hljs-number">112</span>, <span class="hljs-number">138</span>, <span class="hljs-number">123</span>,  <span class="hljs-number">86</span>, <span class="hljs-number">101</span>,  <span class="hljs-number">99</span>, <span class="hljs-number">136</span>,<span class="hljs-number">123</span>, <span class="hljs-number">117</span>, <span class="hljs-number">119</span>, <span class="hljs-number">105</span>, <span class="hljs-number">137</span>, <span class="hljs-number">123</span>, <span class="hljs-number">128</span>, <span class="hljs-number">125</span>, <span class="hljs-number">104</span>, <span class="hljs-number">109</span>, <span class="hljs-number">134</span>, <span class="hljs-number">125</span>, <span class="hljs-number">127</span>,<span class="hljs-number">105</span>, <span class="hljs-number">120</span>, <span class="hljs-number">107</span>, <span class="hljs-number">129</span>, <span class="hljs-number">116</span>, <span class="hljs-number">108</span>, <span class="hljs-number">132</span>, <span class="hljs-number">103</span>, <span class="hljs-number">136</span>, <span class="hljs-number">118</span>, <span class="hljs-number">102</span>, <span class="hljs-number">120</span>, <span class="hljs-number">114</span>,<span class="hljs-number">105</span>, <span class="hljs-number">115</span>, <span class="hljs-number">132</span>, <span class="hljs-number">145</span>, <span class="hljs-number">119</span>, <span class="hljs-number">121</span>, <span class="hljs-number">112</span>, <span class="hljs-number">139</span>, <span class="hljs-number">125</span>, <span class="hljs-number">138</span>, <span class="hljs-number">109</span>, <span class="hljs-number">132</span>, <span class="hljs-number">134</span>,<span class="hljs-number">156</span>, <span class="hljs-number">106</span>, <span class="hljs-number">117</span>, <span class="hljs-number">127</span>, <span class="hljs-number">144</span>, <span class="hljs-number">139</span>, <span class="hljs-number">139</span>, <span class="hljs-number">119</span>, <span class="hljs-number">140</span>,  <span class="hljs-number">83</span>, <span class="hljs-number">110</span>, <span class="hljs-number">102</span>,<span class="hljs-number">123</span>,<span class="hljs-number">107</span>, <span class="hljs-number">143</span>, <span class="hljs-number">115</span>, <span class="hljs-number">136</span>, <span class="hljs-number">118</span>, <span class="hljs-number">139</span>, <span class="hljs-number">123</span>, <span class="hljs-number">112</span>, <span class="hljs-number">118</span>, <span class="hljs-number">125</span>, <span class="hljs-number">109</span>, <span class="hljs-number">119</span>, <span class="hljs-number">133</span>,<span class="hljs-number">112</span>, <span class="hljs-number">114</span>, <span class="hljs-number">122</span>, <span class="hljs-number">109</span>, <span class="hljs-number">106</span>, <span class="hljs-number">123</span>, <span class="hljs-number">116</span>, <span class="hljs-number">131</span>, <span class="hljs-number">127</span>, <span class="hljs-number">115</span>, <span class="hljs-number">118</span>, <span class="hljs-number">112</span>, <span class="hljs-number">135</span>,<span class="hljs-number">115</span>, <span class="hljs-number">146</span>, <span class="hljs-number">137</span>, <span class="hljs-number">116</span>, <span class="hljs-number">103</span>, <span class="hljs-number">144</span>,  <span class="hljs-number">83</span>, <span class="hljs-number">123</span>, <span class="hljs-number">111</span>, <span class="hljs-number">110</span>, <span class="hljs-number">111</span>, <span class="hljs-number">100</span>, <span class="hljs-number">154</span>,<span class="hljs-number">136</span>, <span class="hljs-number">100</span>, <span class="hljs-number">118</span>, <span class="hljs-number">119</span>, <span class="hljs-number">133</span>, <span class="hljs-number">134</span>, <span class="hljs-number">106</span>, <span class="hljs-number">129</span>, <span class="hljs-number">126</span>, <span class="hljs-number">110</span>, <span class="hljs-number">111</span>, <span class="hljs-number">109</span>, <span class="hljs-number">141</span>,<span class="hljs-number">120</span>, <span class="hljs-number">117</span>, <span class="hljs-number">106</span>, <span class="hljs-number">149</span>, <span class="hljs-number">122</span>, <span class="hljs-number">122</span>, <span class="hljs-number">110</span>, <span class="hljs-number">118</span>, <span class="hljs-number">127</span>, <span class="hljs-number">121</span>, <span class="hljs-number">114</span>, <span class="hljs-number">125</span>, <span class="hljs-number">126</span>,<span class="hljs-number">114</span>, <span class="hljs-number">140</span>, <span class="hljs-number">103</span>, <span class="hljs-number">130</span>, <span class="hljs-number">141</span>, <span class="hljs-number">117</span>, <span class="hljs-number">106</span>, <span class="hljs-number">114</span>, <span class="hljs-number">121</span>, <span class="hljs-number">114</span>, <span class="hljs-number">133</span>, <span class="hljs-number">137</span>,  <span class="hljs-number">92</span>,<span class="hljs-number">121</span>, <span class="hljs-number">112</span>, <span class="hljs-number">146</span>,  <span class="hljs-number">97</span>, <span class="hljs-number">137</span>, <span class="hljs-number">105</span>,  <span class="hljs-number">98</span>, <span class="hljs-number">117</span>, <span class="hljs-number">112</span>,  <span class="hljs-number">81</span>,  <span class="hljs-number">97</span>, <span class="hljs-number">139</span>, <span class="hljs-number">113</span>,<span class="hljs-number">134</span>, <span class="hljs-number">106</span>, <span class="hljs-number">144</span>, <span class="hljs-number">110</span>, <span class="hljs-number">137</span>, <span class="hljs-number">137</span>, <span class="hljs-number">111</span>, <span class="hljs-number">104</span>, <span class="hljs-number">117</span>, <span class="hljs-number">100</span>, <span class="hljs-number">111</span>, <span class="hljs-number">101</span>, <span class="hljs-number">110</span>,<span class="hljs-number">105</span>, <span class="hljs-number">129</span>, <span class="hljs-number">137</span>, <span class="hljs-number">112</span>, <span class="hljs-number">120</span>, <span class="hljs-number">113</span>, <span class="hljs-number">133</span>, <span class="hljs-number">112</span>,  <span class="hljs-number">83</span>,  <span class="hljs-number">94</span>, <span class="hljs-number">146</span>, <span class="hljs-number">133</span>, <span class="hljs-number">101</span>,<span class="hljs-number">131</span>, <span class="hljs-number">116</span>, <span class="hljs-number">111</span>,  <span class="hljs-number">84</span>, <span class="hljs-number">137</span>, <span class="hljs-number">115</span>, <span class="hljs-number">122</span>, <span class="hljs-number">106</span>, <span class="hljs-number">144</span>, <span class="hljs-number">109</span>, <span class="hljs-number">123</span>, <span class="hljs-number">116</span>, <span class="hljs-number">111</span>,<span class="hljs-number">111</span>, <span class="hljs-number">133</span>, <span class="hljs-number">150</span>]<br><br><span class="hljs-comment"># 2、创建画布</span><br>plt.figure(figsize=(<span class="hljs-number">20</span>, <span class="hljs-number">8</span>), dpi=<span class="hljs-number">80</span>)<br><br><span class="hljs-comment"># 3、绘制直方图</span><br>distance = <span class="hljs-number">2</span><span class="hljs-comment">#组距</span><br>group_num = <span class="hljs-built_in">int</span>((<span class="hljs-built_in">max</span>(time) - <span class="hljs-built_in">min</span>(time)) / distance)<span class="hljs-comment">#组数=极差/组距</span><br><br>plt.hist(time, bins=group_num, density=<span class="hljs-literal">True</span>)<br><span class="hljs-comment">##第一个参数是数据，第二个参数是组数，第三个参数是density默认为False</span><br><span class="hljs-comment">##False显示的是频数，True显示的是频率</span><br><br><span class="hljs-comment"># 修改x轴刻度</span><br>plt.xticks(<span class="hljs-built_in">range</span>(<span class="hljs-built_in">min</span>(time), <span class="hljs-built_in">max</span>(time) + <span class="hljs-number">2</span>, distance))<br><br><span class="hljs-comment"># 添加网格</span><br>plt.grid(linestyle=<span class="hljs-string">&quot;--&quot;</span>, alpha=<span class="hljs-number">0.5</span>)<br><br><span class="hljs-comment"># 4、显示图像</span><br>plt.show()<br><br></code></pre></td></tr></table></figure><h2 id="饼图"><a href="#饼图" class="headerlink" title="饼图"></a>饼图</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 1、准备数据</span><br>movie_name = [<span class="hljs-string">&#x27;雷神3：诸神黄昏&#x27;</span>,<span class="hljs-string">&#x27;正义联盟&#x27;</span>,<span class="hljs-string">&#x27;东方快车谋杀案&#x27;</span>,<span class="hljs-string">&#x27;寻梦环游记&#x27;</span>,<span class="hljs-string">&#x27;全球风暴&#x27;</span>,<span class="hljs-string">&#x27;降魔传&#x27;</span>,<span class="hljs-string">&#x27;追捕&#x27;</span>,<span class="hljs-string">&#x27;七十七天&#x27;</span>,<span class="hljs-string">&#x27;密战&#x27;</span>,<span class="hljs-string">&#x27;狂兽&#x27;</span>,<span class="hljs-string">&#x27;其它&#x27;</span>]<br><br>place_count = [<span class="hljs-number">60605</span>,<span class="hljs-number">54546</span>,<span class="hljs-number">45819</span>,<span class="hljs-number">28243</span>,<span class="hljs-number">13270</span>,<span class="hljs-number">9945</span>,<span class="hljs-number">7679</span>,<span class="hljs-number">6799</span>,<span class="hljs-number">6101</span>,<span class="hljs-number">4621</span>,<span class="hljs-number">20105</span>]<br><br><span class="hljs-comment"># 2、创建画布</span><br>plt.figure(figsize=(<span class="hljs-number">20</span>, <span class="hljs-number">8</span>), dpi=<span class="hljs-number">80</span>)<br><br><span class="hljs-comment"># 3、绘制饼图</span><br>plt.pie(place_count, labels=movie_name, colors=[<span class="hljs-string">&#x27;b&#x27;</span>,<span class="hljs-string">&#x27;r&#x27;</span>,<span class="hljs-string">&#x27;g&#x27;</span>,<span class="hljs-string">&#x27;y&#x27;</span>,<span class="hljs-string">&#x27;c&#x27;</span>,<span class="hljs-string">&#x27;m&#x27;</span>,<span class="hljs-string">&#x27;y&#x27;</span>,<span class="hljs-string">&#x27;k&#x27;</span>,<span class="hljs-string">&#x27;c&#x27;</span>,<span class="hljs-string">&#x27;g&#x27;</span>,<span class="hljs-string">&#x27;y&#x27;</span>], autopct=<span class="hljs-string">&quot;%1.2f%%&quot;</span>)<br><br><span class="hljs-comment"># 显示图例</span><br>plt.legend()<br><br>plt.axis(<span class="hljs-string">&#x27;equal&#x27;</span>)<br><span class="hljs-comment">##表示横纵轴比相同，即显示为圆形</span><br><br><span class="hljs-comment"># 4、显示图像</span><br>plt.show()<br><br></code></pre></td></tr></table></figure><h1 id="3-Numpy"><a href="#3-Numpy" class="headerlink" title="3.Numpy"></a>3.Numpy</h1><p>高效的运算工具</p><h2 id="3-1-Numpy介绍-数值计算库"><a href="#3-1-Numpy介绍-数值计算库" class="headerlink" title="3.1 Numpy介绍 数值计算库"></a>3.1 Numpy介绍 数值计算库</h2><h2 id="ndarray优势"><a href="#ndarray优势" class="headerlink" title="ndarray优势"></a>ndarray优势</h2><p>​1）存储风格</p><p>​ndarray – 相同类型 – 通用性不强</p><p>​list–  不同类型 – 通用性很强</p><p>​2）并行化运算</p><p>​ndarray支持向量化运算</p><p>​3）底层语言</p><h3 id="3-2-1ndarray属性"><a href="#3-2-1ndarray属性" class="headerlink" title="3.2.1ndarray属性"></a>3.2.1ndarray属性</h3><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td>属性名字</td><td>属性解释</td></tr><tr><td>ndarray.shape</td><td>数组维度的元组</td></tr><tr><td>ndarray.ndim</td><td>数组维数</td></tr><tr><td>ndarray.size</td><td>数组中的元素数量</td></tr><tr><td>ndarray.itemsize</td><td>一个数组元素的长度（字节）</td></tr><tr><td>ndarray.dtype</td><td>数组元素的类型</td></tr><tr><td>使用方法 数组名.函数名</td><td></td></tr></tbody></table><h3 id="3-2-2-ndarray的形状"><a href="#3-2-2-ndarray的形状" class="headerlink" title="3.2.2 ndarray的形状"></a>3.2.2 ndarray的形状</h3><h3 id="3-2-3-ndarray的类型"><a href="#3-2-3-ndarray的类型" class="headerlink" title="3.2.3 ndarray的类型"></a>3.2.3 ndarray的类型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">a = np.array([[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>],[<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>]], dtype = <span class="hljs-string">&quot;float32&quot;</span>)<br>a = np.array([[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>],[<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>]], dtype = np.float32)<br></code></pre></td></tr></table></figure><h2 id="3-3基本操作"><a href="#3-3基本操作" class="headerlink" title="3.3基本操作"></a>3.3基本操作</h2><p>​adarray.方法()</p><p>​np.函数名()</p><h3 id="3-3-1生成数组的方法"><a href="#3-3-1生成数组的方法" class="headerlink" title="3.3.1生成数组的方法"></a>3.3.1生成数组的方法</h3><ol><li><p>生成0和1数组</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># np.zeros(shape)</span><br><span class="hljs-comment"># np.ones(shape)</span><br>zero = np.zeros(shape=(<span class="hljs-number">3</span>,<span class="hljs-number">4</span>), dtype =<span class="hljs-string">&#x27;int32&#x27;</span>)<br>ones = np.ones(shape=[<span class="hljs-number">3</span>,<span class="hljs-number">4</span>], dtype =<span class="hljs-string">&#x27;int32&#x27;</span>)<span class="hljs-comment">#此时指定属性时，既可以是元组也可以是列表</span><br></code></pre></td></tr></table></figure></li><li><p>从现有数组生成</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#np.array()</span><br><span class="hljs-comment">#np.copy()</span><br><span class="hljs-comment">#np.asarray()</span><br>data1=np.array(score)<br>data2=np.copy(score)<br><span class="hljs-comment">#data1、data2深拷贝</span><br>data3=np.asarray(score)<br><span class="hljs-comment">#data3浅拷贝</span><br></code></pre></td></tr></table></figure></li><li><p>生成固定范围数组</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">np.linspace(<span class="hljs-number">0</span>,<span class="hljs-number">10</span>,<span class="hljs-number">100</span>)<span class="hljs-comment">#[0,10] 等距离</span><br><br>np.arange(<span class="hljs-number">0</span>,<span class="hljs-number">10</span>,<span class="hljs-number">2</span>)<span class="hljs-comment">#[a,b） c是步长</span><br></code></pre></td></tr></table></figure></li><li><p>生成随机数组</p><p>分布状况—直方图</p><p>均匀分布</p><ul><li><p>np.random模块</p><ol><li><pre><code class="python">np.random.uniform(low = 0.0, high = 1.0, size = none)#功能：从一个均匀分布中[low,high)中随机采样，左闭右开#low:采样下界，float类型，默认值为0；#high:采样上界，float类型，默认值为1#size:输出样本数目，为int或元组类型，例如。size=(m,n,k),则输出mnk个样本，缺省时输出1个值#返回值：ndarray类型，其形状和参数size中描述一致<figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli"><br>   正态分布：是一种概率分布。具有两个参数μ和σ的连续型随机变量的分布。μ是服从正太分布的随机变量的均值，σ是此随机变量的标准差，记为N<span class="hljs-params">(μ，σ)</span><br><br>```python<br>np.random.normal<span class="hljs-params">(<span class="hljs-attr">loc</span>=1.75,<span class="hljs-attr">scale</span>=0.1,<span class="hljs-attr">size</span>=10000)</span><br></code></pre></td></tr></table></figure></code></pre></li></ol></li></ul></li></ol><h3 id="3-3-2数组的索引、切片"><a href="#3-3-2数组的索引、切片" class="headerlink" title="3.3.2数组的索引、切片"></a>3.3.2数组的索引、切片</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">atock_change = np.random.normal(loc = <span class="hljs-number">0</span>, scale = <span class="hljs-number">1</span>, size =(<span class="hljs-number">8</span>,<span class="hljs-number">10</span>))<br>atock_change<br><span class="hljs-comment">#获取第一支股票的前三个交易日的涨跌幅数据</span><br>atock_change[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>:<span class="hljs-number">3</span>]<span class="hljs-comment">#二维数组索引</span><br>a1 = np.array([[[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>],[<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>]],[[<span class="hljs-number">12</span>,<span class="hljs-number">3</span>,<span class="hljs-number">34</span>],[<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>]]])<br>a1 <span class="hljs-comment">#(2,2,3)</span><br>a1.shape<br>a1[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">2</span>]<span class="hljs-comment">#三维数组索引</span><br>a1[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">2</span>]=<span class="hljs-number">100000</span><br><span class="hljs-comment">#负数对应np中数组从后向前，-1对应最后一个数</span><br><br></code></pre></td></tr></table></figure><h3 id="3-3-3形状修改"><a href="#3-3-3形状修改" class="headerlink" title="3.3.3形状修改"></a>3.3.3形状修改</h3><p>ndarray.reshape()</p><p>ndarray.resize()</p><p>ndarray.T()</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">stock_change.reshape((<span class="hljs-number">10</span>, <span class="hljs-number">8</span>)) <span class="hljs-comment"># 返回新的ndarray, 原始数据没有改变</span><br>stock_change.resize((<span class="hljs-number">10</span>, <span class="hljs-number">8</span>)) <span class="hljs-comment"># 没有返回值， 对原始的ndarray进行了修改</span><br>stock_change.T <span class="hljs-comment"># 转置 行变成列，列变成行  返回一个ndarray，原数据未改变</span><br><br><br><span class="hljs-comment">##reshape()是一个函数，因此第一个括号是函数个括号，而第二个括号是因为传入了一个元##组，其实用列表也可</span><br><br></code></pre></td></tr></table></figure><h3 id="3-3-4类型改变"><a href="#3-3-4类型改变" class="headerlink" title="3.3.4类型改变"></a>3.3.4类型改变</h3><p>ndarray.astype(type)</p><p>ndarray序列化到本地</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">stock_change.astype(<span class="hljs-string">&quot;int32&quot;</span>)<br>stock_change.tostring() <span class="hljs-comment"># ndarray序列化到本地？？？？？？</span><br></code></pre></td></tr></table></figure><h3 id="3-3-5数组的去重"><a href="#3-3-5数组的去重" class="headerlink" title="3.3.5数组的去重"></a>3.3.5数组的去重</h3><p>ndarray.unique</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">temp = np.array([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>],[<span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>]])<br>np.unique(temp)<br><span class="hljs-built_in">set</span>(temp.flatten())<span class="hljs-comment">##set的操作对象需要时一维的，.flatten()可以压缩为一维的</span><br></code></pre></td></tr></table></figure><p>##3.4ndarray运算</p><h3 id="3-4-1逻辑运算"><a href="#3-4-1逻辑运算" class="headerlink" title="3.4.1逻辑运算"></a>3.4.1逻辑运算</h3><p>​运算符 布尔索引</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">stock_change = np.random.uniform(low=-<span class="hljs-number">1</span>, high=<span class="hljs-number">1</span>, size=(<span class="hljs-number">5</span>,<span class="hljs-number">10</span>))<br><span class="hljs-comment"># 逻辑判断, 如果涨跌幅大于0.5就标记为True 否则为False</span><br>stock_change &gt; <span class="hljs-number">0.5</span>     <br><span class="hljs-comment">#返回一个True和False的等大小矩阵</span><br><br>stock_change[stock_change &gt; <span class="hljs-number">0.5</span>] = <span class="hljs-number">1.1</span>  <br><span class="hljs-comment">#将&gt;0.5的全部改为1</span><br></code></pre></td></tr></table></figure><p>通用判断函数</p><p>np.all(布尔值)</p><p>​只要有一个False就返回False，只有全是True才返回True</p><p>np.any(布尔值)</p><p>​只要有一个True就返回True，只有全是False才返回False</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#以下两者均只返回一个布尔值</span><br><br><span class="hljs-comment"># 判断stock_change[0:2, 0:5]是否全是上涨的</span><br>np.<span class="hljs-built_in">all</span>(stock_change[<span class="hljs-number">0</span>:<span class="hljs-number">2</span>, <span class="hljs-number">0</span>:<span class="hljs-number">5</span>] &gt; <span class="hljs-number">0</span>) <br><span class="hljs-comment"># 判断前5只股票这段期间是否有上涨的</span><br>np.<span class="hljs-built_in">any</span>(stock_change[:<span class="hljs-number">5</span>, :] &gt; <span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><p>三元运算符</p><p>np.where()</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># np.where(布尔表达式，True的位置的值，False的位置的值)，类似于三元运算符，不# 过需要利用函数</span><br>np.where(temp &gt; <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>)<br><span class="hljs-comment">###涉及符合逻辑需要额外的函数logical_and/or</span><br><span class="hljs-comment"># 大于0.5且小于1</span><br>np.where(np.logical_and(temp &gt; <span class="hljs-number">0.5</span>, temp &lt; <span class="hljs-number">1</span>), <span class="hljs-number">1</span>, <span class="hljs-number">0</span>)<br><span class="hljs-comment"># 大于0.5或小于-0.5</span><br>np.where(np.logical_or(temp &gt; <span class="hljs-number">0.5</span>, temp &lt; -<span class="hljs-number">0.5</span>), <span class="hljs-number">11</span>, <span class="hljs-number">3</span>)<br></code></pre></td></tr></table></figure><h3 id="3-4-2统计运算"><a href="#3-4-2统计运算" class="headerlink" title="3.4.2统计运算"></a>3.4.2统计运算</h3><p>统计指标函数</p><ul><li><p>主要函数：min max mean median(中位数) var(方差) std(标准差)</p></li><li><p>使用方法：np.函数名(数组名) 或 数组名.方法名</p></li><li><p>同时应当注意 axis的使用。 axis&#x3D;0表示列 axis&#x3D;1表示行 axis&#x3D;-1 表示最后一维度</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">###返回值</span><br>stock_change.<span class="hljs-built_in">max</span>()  <span class="hljs-comment">#将返回最大值</span><br>np.<span class="hljs-built_in">max</span>(stock_change,axis=<span class="hljs-number">1</span>)<span class="hljs-comment">#将返回一个向量，即所有行的最大值</span><br><br><br><span class="hljs-comment">###返回索引</span><br>np.argmax(tem,axis=<span class="hljs-number">0</span>)<br>np.argmin(tem,axis=<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure></li></ul><p>返回最大值、最小值所在位置</p><h3 id="3-4-3数组运算"><a href="#3-4-3数组运算" class="headerlink" title="3.4.3数组运算"></a>3.4.3数组运算</h3><p>数组与数的运算</p><p>​正常的运算即可 <strong>加减乘除等</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">arr = np.array([[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">3</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>],[<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">6</span>,<span class="hljs-number">5</span>,<span class="hljs-number">4</span>]])<br>arr+<span class="hljs-number">1</span><br>arr/<span class="hljs-number">2</span><br></code></pre></td></tr></table></figure><p>数组与数组的运算</p><p><img src="https://img-blog.csdnimg.cn/c87823ff98b74249a11890471cd9462f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5aSp5aSp5YaZ54K55Luj56CB,size_10,color_FFFFFF,t_70,g_se,x_16" alt="img"></p><p>广播机制</p><p>执行broadcast的前提在于，两个nadarray执行的是element-wise的运算，Broadcast机制的功能是为了方便不同形状的ndarray(numpy库的核心数据结构)进行数学运算。</p><p>当操作两个数组时，numpy会逐个比较它们的shape(构成的元组tuple)，只有在下述情况下，两个数组才能够进行数组与数组的运算。</p><ul><li>纬度相等</li><li>shape(其中相对应的一个地方为1)</li></ul><h2 id="3-4-4矩阵运算"><a href="#3-4-4矩阵运算" class="headerlink" title="3.4.4矩阵运算"></a>3.4.4矩阵运算</h2><p>matrix,和array的区别是矩阵必须是二维的，但是array可以是多维的</p><p>矩阵&amp;二维数组(不满足广播机制不能进行计算)</p><p>两种方法存储矩阵</p><p>​1)ndarray 二维数组</p><p>​2)matrix数据结构</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#array存储矩阵</span><br>data = np.array([[<span class="hljs-number">80</span>,<span class="hljs-number">86</span>],<br>                [<span class="hljs-number">82</span>,<span class="hljs-number">80</span>],<br>                [<span class="hljs-number">85</span>,<span class="hljs-number">78</span>],<br>                [<span class="hljs-number">90</span>,<span class="hljs-number">90</span>],<br>                [<span class="hljs-number">86</span>,<span class="hljs-number">82</span>],<br>                [<span class="hljs-number">82</span>,<span class="hljs-number">90</span>],<br>                [<span class="hljs-number">78</span>,<span class="hljs-number">80</span>],<br>                [<span class="hljs-number">92</span>,<span class="hljs-number">94</span>]])<br><span class="hljs-comment">#matrix存储矩阵</span><br>data2=np.mat([[<span class="hljs-number">80</span>, <span class="hljs-number">86</span>],<br>       [<span class="hljs-number">82</span>, <span class="hljs-number">80</span>],<br>       [<span class="hljs-number">85</span>, <span class="hljs-number">78</span>],<br>       [<span class="hljs-number">90</span>, <span class="hljs-number">90</span>],<br>       [<span class="hljs-number">86</span>, <span class="hljs-number">82</span>],<br>       [<span class="hljs-number">82</span>, <span class="hljs-number">90</span>],<br>       [<span class="hljs-number">78</span>, <span class="hljs-number">80</span>],<br>       [<span class="hljs-number">92</span>, <span class="hljs-number">94</span>]])<br></code></pre></td></tr></table></figure><ul><li><p>矩阵乘法运算</p><ul><li><p>形状改变</p><p>（m<em>n） * （n</em>m）</p></li><li><p>运算规则</p><p>矩阵的乘法必须满足运算规则，即(m,n)*(n,l)&#x3D;(m,l)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#如果是二维数组实现矩阵运算</span><br>np.dot(data,data1)<br>np.matmul(data,data1)<br>data @ data1<br><br><span class="hljs-comment">#如果是矩阵进行运算</span><br>data1*data23<span class="hljs-number">.5</span><br></code></pre></td></tr></table></figure></li></ul></li></ul><h2 id="3-5-合并与分隔"><a href="#3-5-合并与分隔" class="headerlink" title="3.5 合并与分隔"></a>3.5 合并与分隔</h2><h3 id="3-5-1合并"><a href="#3-5-1合并" class="headerlink" title="3.5.1合并"></a>3.5.1合并</h3><ul><li><p>numpy.hstack 水平拼接</p></li><li><p>numpy.vstack 竖拼接</p></li><li><p>numpy.concatenate((a1,a2),axis&#x3D;0|1) 水平|竖拼接</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">data1 = np.mat([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>])<br>data2 = np.mat([<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>])<br>np.vstack((data1,data2))<br>np.hstack((data1,data2))<br>np.concatenate((data1,data2),axis=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure></li></ul><h3 id="3-5-2-分隔"><a href="#3-5-2-分隔" class="headerlink" title="3.5.2 分隔"></a>3.5.2 分隔</h3><h2 id="3-6-IO操作与数据处理"><a href="#3-6-IO操作与数据处理" class="headerlink" title="3.6 IO操作与数据处理"></a>3.6 IO操作与数据处理</h2><p>data &#x3D; np.genfromtxt(“text.csv”, delimeter &#x3D; “,”)</p><h3 id="3-6-1numpy读取"><a href="#3-6-1numpy读取" class="headerlink" title="3.6.1numpy读取"></a>3.6.1numpy读取</h3><h3 id="3-6-2-如何处理缺失值"><a href="#3-6-2-如何处理缺失值" class="headerlink" title="3.6.2 如何处理缺失值"></a>3.6.2 如何处理缺失值</h3><ul><li>直接删除含有缺失值的样本</li><li>替补&#x2F;插补；</li></ul><h1 id="4-Pandas"><a href="#4-Pandas" class="headerlink" title="4 Pandas"></a>4 Pandas</h1><h2 id="4-1Pandas介绍"><a href="#4-1Pandas介绍" class="headerlink" title="4.1Pandas介绍"></a>4.1Pandas介绍</h2><ul><li>Pandas&#x3D;panel+data+analysis<br>专门用于数据挖掘的开源Python库<br>以Numpy为基础，借力Numpy模块在计算方面性能高的优势<br>基于matplotlib，能够简便的画图<br>独特的数据结构<br>便捷的数据处理能力<br>读取文件方便<br>封装了Matplotlib、Numpy的画图和计算</li></ul><h3 id="4-1-3-DataFrame"><a href="#4-1-3-DataFrame" class="headerlink" title="4.1.3 DataFrame"></a>4.1.3 DataFrame</h3><p>​结构：既有行索引又有列索引的二维数组</p><ul><li><p>索引：行索引-index，横向索引；列索引-columns，纵向索引</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">pd.DataFrame(stock_change)<br><span class="hljs-comment">#添加行索引</span><br>stock = [<span class="hljs-string">&quot;股票&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>)]<br>pd.DataFrame(stock_change, index = stock)<br><span class="hljs-comment">#添加列索引</span><br>date = pd.date_range(start=<span class="hljs-string">&quot;20100101&quot;</span>,periods = <span class="hljs-number">5</span>, freq= <span class="hljs-string">&quot;B&quot;</span>)<br>pd.DataFrame(stock_change, index = stock, columns = date)<br></code></pre></td></tr></table></figure></li><li><p>值：values，利用values即可直接获得去除索引的数据（数组）</p></li><li><p>shape：表明形状 (形状不含索引的行列)</p></li><li><p>T：行列转置</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#获取局部展示</span><br>b.head()<span class="hljs-comment">#默认展示前5行，可在head()加入数字，展示前几行</span><br>b.tail()<span class="hljs-comment">#默认展示后5行，可在tail()加入数字，展示后几行</span><br><br><span class="hljs-comment">#获取索引和值</span><br>b.index<span class="hljs-comment">#获取行索引</span><br><span class="hljs-comment">#####返回一个类似列表的东西，也可以利用数字继续索引例:a.index[1]</span><br>b.columns<span class="hljs-comment">#获取列索引</span><br>b.values<span class="hljs-comment">#获取数据值（数组，不含索引）</span><br>b.shape<span class="hljs-comment">#获取DataFrame的维度数据</span><br>b.T<span class="hljs-comment">#获取转制后的dataframe</span><br><br><span class="hljs-comment">#设置行列索引</span><br><span class="hljs-comment"># 创建一个符合正态分布的10个股票5天的涨跌幅数据</span><br>stock_change = np.random.normal(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, (<span class="hljs-number">10</span>, <span class="hljs-number">5</span>))<br>pd.DataFrame(stock_change)<br><span class="hljs-comment">#设置行列索引</span><br>stock = [<span class="hljs-string">&quot;股票&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>)]<br>date = pd.date_range(start=<span class="hljs-string">&quot;20200101&quot;</span>, periods=<span class="hljs-number">5</span>, freq=<span class="hljs-string">&quot;B&quot;</span>)<span class="hljs-comment">#这个是pandas中设置日期的</span><br><span class="hljs-comment"># 添加行列索引</span><br>data = pd.DataFrame(stock_change, index=stock, columns=date)<br></code></pre></td></tr></table></figure><p> DataeFrame索引的设置</p><ul><li><p>修改行列索引值</p><p>​不能单独修改所以，只能整体修改索引</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#不能单独修改行列总某一个索引的值，可以替换整行或整列   例：b.index[2]=&#x27;股票1&#x27;  错误</span><br>data.index=新行索引<br><span class="hljs-comment">#重设索引</span><br>data.reset_index(drop=<span class="hljs-literal">False</span>)<br><span class="hljs-comment">#drop参数默认为False，表示将原来的索引替换掉，换新索引为数字递增，原来的索引将变为数据的一部分。True表示，将原来的索引删除，更换为数字递增。如下图</span><br></code></pre></td></tr></table></figure><ul><li>重设索引</li><li>设置新索引</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 设置新索引</span><br>df = pd.DataFrame(&#123;<span class="hljs-string">&#x27;month&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">4</span>, <span class="hljs-number">7</span>, <span class="hljs-number">10</span>],<br>                    <span class="hljs-string">&#x27;year&#x27;</span>: [<span class="hljs-number">2012</span>, <span class="hljs-number">2014</span>, <span class="hljs-number">2013</span>, <span class="hljs-number">2014</span>],<br>                    <span class="hljs-string">&#x27;sale&#x27;</span>:[<span class="hljs-number">55</span>, <span class="hljs-number">40</span>, <span class="hljs-number">84</span>, <span class="hljs-number">31</span>]&#125;)<br><span class="hljs-comment"># 以月份设置新的索引</span><br>df.set_index(<span class="hljs-string">&quot;month&quot;</span>, drop=<span class="hljs-literal">True</span>)<br><span class="hljs-comment">#见下图，即将原本数据中的一列拿出来作为index</span><br>new_df = df.set_index([<span class="hljs-string">&quot;year&quot;</span>, <span class="hljs-string">&quot;month&quot;</span>])<span class="hljs-comment"># 设置多个索引，以年和月份   多个索引其实就是MultiIndex</span><br></code></pre></td></tr></table></figure><h3 id="4-1-4-MultiIndex"><a href="#4-1-4-MultiIndex" class="headerlink" title="4.1.4 MultiIndex"></a>4.1.4 MultiIndex</h3><p>分级或分层索引对象</p><ul><li>Index属性<ul><li>names: levels的名称</li><li>levels:每个level的元组值</li></ul></li></ul><h2 id="4-1-5-Panel"><a href="#4-1-5-Panel" class="headerlink" title="4.1.5 Panel"></a>4.1.5 Panel</h2><p>pandas.Panel(data&#x3D;None,items&#x3D;None,major_axis&#x3D;None,minor_axis&#x3D;None,copy&#x3D;False,dtype&#x3D;None)</p><p>存储3维数组的Panel结构</p><ul><li>items - axis 0，每个项目对应于内部包含的数据帧(DataFrame)。</li><li>major_axis - axis 1，它是每个数据帧(DataFrame)的索引(行)。</li><li>minor_axis - axis 2，它是每个数据帧(DataFrame)的列。</li></ul><h2 id="4-1-6-Series"><a href="#4-1-6-Series" class="headerlink" title="4.1.6 Series"></a>4.1.6 Series</h2><p>​带索引的一维数组</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 创建</span><br>pd.Series(np.arange(<span class="hljs-number">3</span>, <span class="hljs-number">9</span>, <span class="hljs-number">2</span>), index=[<span class="hljs-string">&quot;a&quot;</span>, <span class="hljs-string">&quot;b&quot;</span>, <span class="hljs-string">&quot;c&quot;</span>])<br><span class="hljs-comment"># 或</span><br>pd.Series(&#123;<span class="hljs-string">&#x27;red&#x27;</span>:<span class="hljs-number">100</span>, <span class="hljs-string">&#x27;blue&#x27;</span>:<span class="hljs-number">200</span>, <span class="hljs-string">&#x27;green&#x27;</span>: <span class="hljs-number">500</span>, <span class="hljs-string">&#x27;yellow&#x27;</span>:<span class="hljs-number">1000</span>&#125;)<br><br>sr = data.iloc[<span class="hljs-number">1</span>, :]<br>sr.index <span class="hljs-comment"># 索引</span><br>sr.values <span class="hljs-comment"># 值</span><br><br><span class="hljs-comment">#####就是从dataframe中抽出一行或一列来观察</span><br></code></pre></td></tr></table></figure><h2 id="4-2基本数据操作"><a href="#4-2基本数据操作" class="headerlink" title="4.2基本数据操作"></a>4.2基本数据操作</h2><h3 id="4-2-1-索引操作"><a href="#4-2-1-索引操作" class="headerlink" title="4.2.1 索引操作"></a>4.2.1 索引操作</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python">data=pd.read_csv(<span class="hljs-string">&quot;./stock_day/stock_day.csv&quot;</span>)<span class="hljs-comment">#读入文件的前5行表示如下</span><br><span class="hljs-comment">######利用drop删除某些行列，需要利用axis告知函数是行索引还是列索引</span><br>data=data.drop([<span class="hljs-string">&quot;ma5&quot;</span>,<span class="hljs-string">&quot;ma10&quot;</span>,<span class="hljs-string">&quot;ma20&quot;</span>,<span class="hljs-string">&quot;v_ma5&quot;</span>,<span class="hljs-string">&quot;v_ma10&quot;</span>,<span class="hljs-string">&quot;v_ma20&quot;</span>], axis=<span class="hljs-number">1</span>) <span class="hljs-comment"># 去掉一些不要的列</span><br>data[<span class="hljs-string">&quot;open&quot;</span>][<span class="hljs-string">&quot;2018-02-26&quot;</span>] <span class="hljs-comment"># 直接索引，但需要遵循先列后行</span><br><br><span class="hljs-comment">#####按名字索引利用.loc函数可以不遵循列行先后关系</span><br>data.loc[<span class="hljs-string">&quot;2018-02-26&quot;</span>][<span class="hljs-string">&quot;open&quot;</span>] <span class="hljs-comment"># 按名字索引</span><br>data.loc[<span class="hljs-string">&quot;2018-02-26&quot;</span>, <span class="hljs-string">&quot;open&quot;</span>]<br><br><br><span class="hljs-comment">#####利用.iloc函数可以只利用数字进行索引</span><br>data.iloc[<span class="hljs-number">1</span>][<span class="hljs-number">0</span>] <span class="hljs-comment"># 数字索引</span><br>data.iloc[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>]<br><br><br><span class="hljs-comment"># 组合索引</span><br><span class="hljs-comment"># 获取行第1天到第4天，[&#x27;open&#x27;, &#x27;close&#x27;, &#x27;high&#x27;, &#x27;low&#x27;]这个四个指标的结果</span><br>data.ix[:<span class="hljs-number">4</span>, [<span class="hljs-string">&#x27;open&#x27;</span>, <span class="hljs-string">&#x27;close&#x27;</span>, <span class="hljs-string">&#x27;high&#x27;</span>, <span class="hljs-string">&#x27;low&#x27;</span>]] <span class="hljs-comment"># 现在不推荐用了</span><br><span class="hljs-comment">###但仍可利用loc和iloc</span><br>data.loc[data.index[<span class="hljs-number">0</span>:<span class="hljs-number">4</span>], [<span class="hljs-string">&#x27;open&#x27;</span>, <span class="hljs-string">&#x27;close&#x27;</span>, <span class="hljs-string">&#x27;high&#x27;</span>, <span class="hljs-string">&#x27;low&#x27;</span>]]<br>data.iloc[<span class="hljs-number">0</span>:<span class="hljs-number">4</span>, data.columns.get_indexer([<span class="hljs-string">&#x27;open&#x27;</span>, <span class="hljs-string">&#x27;close&#x27;</span>, <span class="hljs-string">&#x27;high&#x27;</span>, <span class="hljs-string">&#x27;low&#x27;</span>])]<br></code></pre></td></tr></table></figure><pre><code class="hljs">#### 4.2.1.1 直接索引</code></pre><h4 id="4-2-1-2-按名字索引"><a href="#4-2-1-2-按名字索引" class="headerlink" title="4.2.1.2 按名字索引"></a>4.2.1.2 按名字索引</h4><h4 id="4-2-1-3-按数组索引"><a href="#4-2-1-3-按数组索引" class="headerlink" title="4.2.1.3 按数组索引"></a>4.2.1.3 按数组索引</h4><h3 id="4-2-2-赋值操作"><a href="#4-2-2-赋值操作" class="headerlink" title="4.2.2 赋值操作"></a>4.2.2 赋值操作</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">data.<span class="hljs-built_in">open</span>=<span class="hljs-number">100</span><br>data[<span class="hljs-string">&#x27;open&#x27;</span>]=<span class="hljs-number">100</span><br><span class="hljs-comment">###两种方式均可</span><br>data.iloc[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>]=<span class="hljs-number">100</span><br><span class="hljs-comment">###找好索引即可</span><br></code></pre></td></tr></table></figure><h3 id="4-2-3排序"><a href="#4-2-3排序" class="headerlink" title="4.2.3排序"></a>4.2.3排序</h3><p>sort_values （比较values进行排序） sort_index （比较行索引进行排序，不行可以先转置简介对列排序）</p><p>内容排序</p><p>索引排序</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">data.sort_values(by=<span class="hljs-string">&quot;high&quot;</span>, ascending=<span class="hljs-literal">False</span>) <span class="hljs-comment"># DataFrame内容排序，ascending表示升序还是降序，默认True升序</span><br><br>data.sort_values(by=[<span class="hljs-string">&quot;high&quot;</span>, <span class="hljs-string">&quot;p_change&quot;</span>], ascending=<span class="hljs-literal">False</span>).head() <span class="hljs-comment"># 多个列内容排序。给出的优先级进行排序</span><br><br>data.sort_index(ascending=<span class="hljs-literal">True</span>)<span class="hljs-comment">###对行索引进行排序</span><br><br><span class="hljs-comment">#这里是取出了一列 “price_change”列，为serise，用法同上</span><br>sr = data[<span class="hljs-string">&quot;price_change&quot;</span>]<br>sr.sort_values(ascending=<span class="hljs-literal">False</span>)<br>sr.sort_index()<br></code></pre></td></tr></table></figure><h2 id="4-3-DataFrame运算"><a href="#4-3-DataFrame运算" class="headerlink" title="4.3 DataFrame运算"></a>4.3 DataFrame运算</h2><h3 id="4-3-1算术运算"><a href="#4-3-1算术运算" class="headerlink" title="4.3.1算术运算"></a>4.3.1算术运算</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#正常的加减乘除等的运算即可</span><br>data[<span class="hljs-string">&quot;open&quot;</span>] + <span class="hljs-number">3</span><br>data[<span class="hljs-string">&quot;open&quot;</span>].add(<span class="hljs-number">3</span>) <span class="hljs-comment"># open统一加3  </span><br>data.sub(<span class="hljs-number">100</span>)<span class="hljs-comment"># 所有统一减100 data - 100</span><br>(data[<span class="hljs-string">&quot;close&quot;</span>]-(data[<span class="hljs-string">&quot;open&quot;</span>])).head() <span class="hljs-comment"># close减open</span><br></code></pre></td></tr></table></figure><h3 id="4-3-2-逻辑运算"><a href="#4-3-2-逻辑运算" class="headerlink" title="4.3.2 逻辑运算"></a>4.3.2 逻辑运算</h3><p>逻辑运算 ：&lt; ; &gt; ; | ; &amp; 利用逻辑符号或者函数query</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 例如筛选p_change &gt; 2的日期数据</span><br>data[data[<span class="hljs-string">&quot;p_change&quot;</span>] &gt; <span class="hljs-number">2</span>].head()<br><span class="hljs-comment"># 完成一个多个逻辑判断， 筛选p_change &gt; 2并且low &gt; 15</span><br>data[(data[<span class="hljs-string">&quot;p_change&quot;</span>] &gt; <span class="hljs-number">2</span>) &amp; (data[<span class="hljs-string">&quot;low&quot;</span>] &gt; <span class="hljs-number">15</span>)].head()<br>data.query(<span class="hljs-string">&quot;p_change &gt; 2 &amp; low &gt; 15&quot;</span>).head()<span class="hljs-comment">###等效于上一行代码</span><br><br><span class="hljs-comment">###判断# 判断&#x27;turnover&#x27;列索引中是否有4.19, 2.39，将返回一列布尔值</span><br>data[<span class="hljs-string">&quot;turnover&quot;</span>].isin([<span class="hljs-number">4.19</span>, <span class="hljs-number">2.39</span>])<span class="hljs-comment">##如下图</span><br></code></pre></td></tr></table></figure><p>利用布尔值索引，即利用一个布尔数组索引出True的数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">###判断# 判断&#x27;turnover&#x27;列索引中是否有4.19, 2.39，将返回一列布尔值</span><br>data[<span class="hljs-string">&quot;turnover&quot;</span>].isin([<span class="hljs-number">4.19</span>, <span class="hljs-number">2.39</span>])<span class="hljs-comment">##如下图</span><br>data[data[<span class="hljs-string">&quot;turnover&quot;</span>].isin([<span class="hljs-number">4.19</span>, <span class="hljs-number">2.39</span>])]<br><span class="hljs-comment">#这块就将返回turnover列布尔值为true的如下图，也就是筛选出turnover中值为4.19和2.39</span><br><br><br><span class="hljs-comment">###布尔值索引是一个很方便的数据筛选操作，比如：</span><br>data[data[<span class="hljs-string">&quot;turnover&quot;</span>]&gt;<span class="hljs-number">0.1</span>]<br><span class="hljs-comment">#也将筛选出turnover列中大于0.1的整体data数据，并不是说只返回turnover相关数据，判断只是返回布尔索引，利用索引的是data数据</span><br></code></pre></td></tr></table></figure><h3 id="4-3-3-统计运算"><a href="#4-3-3-统计运算" class="headerlink" title="4.3.3 统计运算"></a>4.3.3 统计运算</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">data.describe()<br><span class="hljs-comment">#将返回关于列的最值，均值，方差等多种信息</span><br><span class="hljs-comment">##其实这里很多就和numpy相似了</span><br>data.<span class="hljs-built_in">max</span>(axis=<span class="hljs-number">0</span>)<span class="hljs-comment">#返回最值</span><br>data.idxmax(axis=<span class="hljs-number">0</span>) <span class="hljs-comment">#返回最值索引</span><br></code></pre></td></tr></table></figure><p><strong>累计统计函数（累加，累乘等）</strong></p><ul><li>cumsum 计算前1&#x2F;2&#x2F;3&#x2F;…&#x2F;n个数的和</li><li>cummax 计算前1&#x2F;2&#x2F;3&#x2F;…&#x2F;n个数的最大值</li><li>cummin 计算前1&#x2F;2&#x2F;3&#x2F;…&#x2F;n个数的最小值</li><li>cumprod 计算前1&#x2F;2&#x2F;3&#x2F;…&#x2F;n个数的积</li></ul><p><strong>自定义运算</strong></p><p> apply(func, axis&#x3D;0)</p><p> func: 自定义函数</p><p> axis&#x3D;0: 默认按列运算，axis&#x3D;1按行运算</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">data.apply(<span class="hljs-keyword">lambda</span> x: x.<span class="hljs-built_in">max</span>() - x.<span class="hljs-built_in">min</span>())<br><span class="hljs-comment">#这里的lambda x: x.max() - x.min()是lambda表达式，是函数的简单写法也可</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">fx</span>(<span class="hljs-params">data</span>):<br><span class="hljs-keyword">return</span>data.<span class="hljs-built_in">max</span>()-data.<span class="hljs-built_in">min</span>()<br></code></pre></td></tr></table></figure><h2 id="4-4Pandas画图"><a href="#4-4Pandas画图" class="headerlink" title="4.4Pandas画图"></a>4.4Pandas画图</h2><p>pandas.DataFrame.plot<br>DataFrame.plot(x&#x3D;None, y&#x3D;None, kind&#x3D;‘line’)</p><ul><li>x: label or position, default None</li><li>y: label, position or list of label, positions, default None<ul><li>Allows plotting of one column versus another</li><li>kind: str</li><li>‘line’: line plot(default)</li><li>‘bar”: vertical bar plot</li><li>“barh”: horizontal bar plot</li><li>“hist”: histogram</li><li>“pie”: pie plot</li><li>“scatter”: scatter plot</li></ul></li></ul><h2 id="4-5-文件读取与存储"><a href="#4-5-文件读取与存储" class="headerlink" title="4.5 文件读取与存储"></a>4.5 文件读取与存储</h2><h3 id="4-5-1-CSV文件"><a href="#4-5-1-CSV文件" class="headerlink" title="4.5.1 CSV文件"></a>4.5.1 CSV文件</h3><h4 id="4-5-1-1-读取CSV文件-read-csv"><a href="#4-5-1-1-读取CSV文件-read-csv" class="headerlink" title="4.5.1.1 读取CSV文件 read_csv()"></a>4.5.1.1 读取CSV文件 read_csv()</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#pandas.read_csv(filepath_or_buffer=&#x27;&#x27;,usecols=，names=)</span><br><span class="hljs-comment">#filepath_or_buffer : 文件路径</span><br><span class="hljs-comment">#usecols : 指定读取的列名、列表形式</span><br><span class="hljs-comment">#names : 参数</span><br>data = pd.read_csv(<span class="hljs-string">&quot;D:\\python\\study\\day3资料\\02-代码\\stock_day\\stock_day.csv&quot;</span>)<br></code></pre></td></tr></table></figure><h4 id="4-5-1-2-写入CSV文件-to-csv"><a href="#4-5-1-2-写入CSV文件-to-csv" class="headerlink" title="4.5.1.2 写入CSV文件 to_csv()"></a>4.5.1.2 写入CSV文件 to_csv()</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">DataFrame.to_csv(path_or_buf=<span class="hljs-literal">None</span>,sep=<span class="hljs-string">&#x27;,&#x27;</span>columns=<span class="hljs-literal">None</span>,header=<span class="hljs-literal">True</span>,index=<span class="hljs-literal">True</span>,index_label=<span class="hljs-literal">None</span>,mode=<span class="hljs-string">&#x27;w&#x27;</span>,encoding=<span class="hljs-literal">None</span>)<br></code></pre></td></tr></table></figure><ul><li><p>path_or_buf ：string or file handle ， default None</p></li><li><p>sep : character, default ‘,’（分隔符）</p></li><li><p>columns ：sequence,optional</p></li><li><p>mode：’w‘:重写，’a’追加</p></li><li><p>index:是否写入 行索引</p></li><li><p>header:boolean or list of string,default True,是否写进列索引值</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">Series.to_csv (path=<span class="hljs-literal">None</span>,index=<span class="hljs-literal">True</span>,sep=<span class="hljs-string">&#x27;,&#x27;</span>,na_rep=<span class="hljs-string">&#x27;&#x27;</span>,float_format=<span class="hljs-literal">None</span>,header=<span class="hljs-literal">False</span>,index_label=<span class="hljs-literal">None</span>,mode=<span class="hljs-string">&#x27;w&#x27;</span>,encoding=<span class="hljs-literal">None</span>,compression=<span class="hljs-literal">None</span>,date_format=<span class="hljs-literal">None</span>,decimal=<span class="hljs-string">&#x27;.)</span><br></code></pre></td></tr></table></figure></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">pd.read_csv(<span class="hljs-string">&quot;./stock_day/stock_day.csv&quot;</span>, usecols=[<span class="hljs-string">&quot;high&quot;</span>, <span class="hljs-string">&quot;low&quot;</span>, <span class="hljs-string">&quot;open&quot;</span>, <span class="hljs-string">&quot;close&quot;</span>]).head() <span class="hljs-comment"># 读哪些列</span><br><br>data = pd.read_csv(<span class="hljs-string">&quot;stock_day2.csv&quot;</span>, names=[<span class="hljs-string">&quot;open&quot;</span>, <span class="hljs-string">&quot;high&quot;</span>, <span class="hljs-string">&quot;close&quot;</span>, <span class="hljs-string">&quot;low&quot;</span>, <span class="hljs-string">&quot;volume&quot;</span>, <span class="hljs-string">&quot;price_change&quot;</span>, <span class="hljs-string">&quot;p_change&quot;</span>, <span class="hljs-string">&quot;ma5&quot;</span>, <span class="hljs-string">&quot;ma10&quot;</span>, <span class="hljs-string">&quot;ma20&quot;</span>, <span class="hljs-string">&quot;v_ma5&quot;</span>, <span class="hljs-string">&quot;v_ma10&quot;</span>, <span class="hljs-string">&quot;v_ma20&quot;</span>, <span class="hljs-string">&quot;turnover&quot;</span>]) <span class="hljs-comment"># 如果列没有列名，用names传入</span><br><br>data[:<span class="hljs-number">10</span>].to_csv(<span class="hljs-string">&quot;test.csv&quot;</span>, columns=[<span class="hljs-string">&quot;open&quot;</span>]) <span class="hljs-comment"># 保存open列数据</span><br><br>data[:<span class="hljs-number">10</span>].to_csv(<span class="hljs-string">&quot;test.csv&quot;</span>, columns=[<span class="hljs-string">&quot;open&quot;</span>], index=<span class="hljs-literal">False</span>, mode=<span class="hljs-string">&quot;a&quot;</span>, header=<span class="hljs-literal">False</span>) <span class="hljs-comment"># 保存opend列数据，index=False不要行索引，mode=&quot;a&quot;追加模式|mode=&quot;w&quot;重写，header=False不要列索引</span><br></code></pre></td></tr></table></figure><h2 id="4-6Pandas高级处理"><a href="#4-6Pandas高级处理" class="headerlink" title="4.6Pandas高级处理"></a>4.6Pandas高级处理</h2><h3 id="4-6-1-缺失值处理"><a href="#4-6-1-缺失值处理" class="headerlink" title="4.6.1 缺失值处理"></a>4.6.1 缺失值处理</h3><p>如何进行缺失值处理？</p><ul><li>删除含有缺失值的样本</li><li>替换&#x2F;插补数据</li></ul><p><strong>判断NaN是否存在</strong></p><ul><li>pd.isnull(df) 会返回整个dataframe的布尔框架，难以观察(bool为True代表那个位置是缺失值)</li><li>pd.isnull(df).any() 表示只要有一个True就返回True</li><li>pd.notnull(df)会返回整个dataframe的布尔框架，难以观察(bool为False代表那个位置是缺失值)</li><li>pd.notnull(df).all() 表示只要有一个False就返回False</li></ul><p><strong>删除nan数据</strong></p><ul><li>df.dropna(inplace&#x3D;True) 默认按行删除 inplace:True修改原数据，False返回新数据，默认False</li></ul><p><strong>替换nan数据</strong></p><ul><li>df.fillna(value,inplace&#x3D;True)</li><li>value替换的值</li><li>inplace:True修改原数据，False返回新数据，默认False</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python">movie[<span class="hljs-string">&quot;Revenue (Millions)&quot;</span>].fillna(movie[<span class="hljs-string">&quot;Revenue (Millions)&quot;</span>].mean(), inplace=<span class="hljs-literal">True</span>)<br><span class="hljs-comment">###这就是先利用其他代码判断出&quot;Revenue (Millions)&quot;有nan数据，然后利用.fillna函数，令value=movie[&quot;Revenue (Millions)&quot;].mean()列的均值，然后inplace=True修改原数据</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>movie = pd.read_csv(<span class="hljs-string">&quot;./IMDB/IMDB-Movie-Data.csv&quot;</span>)<br><span class="hljs-comment"># 1）判断是否存在NaN类型的缺失值</span><br>np.<span class="hljs-built_in">any</span>(pd.isnull(movie)) <span class="hljs-comment"># 返回True，说明数据中存在缺失值</span><br>np.<span class="hljs-built_in">all</span>(pd.notnull(movie)) <span class="hljs-comment"># 返回False，说明数据中存在缺失值</span><br>pd.isnull(movie).<span class="hljs-built_in">any</span>()<br>pd.notnull(movie).<span class="hljs-built_in">all</span>()<br><br><span class="hljs-comment"># 2）缺失值处理</span><br><span class="hljs-comment"># 方法1：删除含有缺失值的样本</span><br>data1 = movie.dropna()<br>pd.notnull(data1).<span class="hljs-built_in">all</span>()<br><br><span class="hljs-comment"># 方法2：替换</span><br><span class="hljs-comment"># 含有缺失值的字段</span><br><span class="hljs-comment"># Revenue (Millions)    </span><br><span class="hljs-comment"># Metascore</span><br>movie[<span class="hljs-string">&quot;Revenue (Millions)&quot;</span>].fillna(movie[<span class="hljs-string">&quot;Revenue (Millions)&quot;</span>].mean(), inplace=<span class="hljs-literal">True</span>)<br>movie[<span class="hljs-string">&quot;Metascore&quot;</span>].fillna(movie[<span class="hljs-string">&quot;Metascore&quot;</span>].mean(), inplace=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><p><strong>替换非nan的标记数据</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 读取数据</span><br>path = <span class="hljs-string">&quot;wisconsin.data&quot;</span><br>name = [<span class="hljs-string">&quot;Sample code number&quot;</span>,  <span class="hljs-string">&quot;Normal Nucleoli&quot;</span>,<span class="hljs-string">&quot;Mitoses&quot;</span>, <span class="hljs-string">&quot;Class&quot;</span>]<br>data = pd.read_csv(path, names=name)<br><br><span class="hljs-comment">#这里的非nan标记值缺失值就是利用“?”表示的，因此利用参数to_replace,value=np.nan,将默认标记值替换为nan值，然后再利用签署方法处理nan缺失值</span><br><span class="hljs-comment"># 1）替换</span><br>data_new = data.replace(to_replace=<span class="hljs-string">&quot;?&quot;</span>, value=np.nan)<br></code></pre></td></tr></table></figure><h2 id="4-7-数据离散化"><a href="#4-7-数据离散化" class="headerlink" title="4.7 数据离散化"></a>4.7 数据离散化</h2><p><img src="D:\人工智能\深度学习\graph\image-20221031151642094.png" alt="image-20221031151945710"></p><ul><li><p>实现方法：</p><p>1.分组</p><ul><li>自动分组 sr &#x3D; pd.qcut(data,bins)</li><li>自定义分组 sr &#x3D; pd.cut(data,[])</li></ul><p>2.将分组好的结果转换成one-hot编码（哑变量）</p><ul><li>pd.get_dummies(sr, prefix&#x3D;)</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 1）准备数据</span><br>data = pd.Series([<span class="hljs-number">165</span>,<span class="hljs-number">174</span>,<span class="hljs-number">160</span>,<span class="hljs-number">180</span>,<span class="hljs-number">159</span>,<span class="hljs-number">163</span>,<span class="hljs-number">192</span>,<span class="hljs-number">184</span>], index=[<span class="hljs-string">&#x27;No1:165&#x27;</span>, <span class="hljs-string">&#x27;No2:174&#x27;</span>,<span class="hljs-string">&#x27;No3:160&#x27;</span>, <span class="hljs-string">&#x27;No4:180&#x27;</span>, <span class="hljs-string">&#x27;No5:159&#x27;</span>, <span class="hljs-string">&#x27;No6:163&#x27;</span>, <span class="hljs-string">&#x27;No7:192&#x27;</span>, <span class="hljs-string">&#x27;No8:184&#x27;</span>]) <br><span class="hljs-comment"># 2）分组</span><br><span class="hljs-comment"># 自动分组</span><br>sr = pd.qcut(data, <span class="hljs-number">3</span>)<br>sr.value_counts()  <span class="hljs-comment"># 看每一组有几个数据</span><br><span class="hljs-comment"># 3）转换成one-hot编码</span><br>pd.get_dummies(sr, prefix=<span class="hljs-string">&quot;height&quot;</span>)<br><br><span class="hljs-comment"># 自定义分组</span><br>bins = [<span class="hljs-number">150</span>, <span class="hljs-number">165</span>, <span class="hljs-number">180</span>, <span class="hljs-number">195</span>]<span class="hljs-comment">#这就表示有三组[150,165][165,180][180,195]</span><br>sr = pd.cut(data, bins)<br><span class="hljs-comment"># get_dummies</span><br>pd.get_dummies(sr, prefix=<span class="hljs-string">&quot;身高&quot;</span>)<br></code></pre></td></tr></table></figure><h2 id="4-8-合并"><a href="#4-8-合并" class="headerlink" title="4.8 合并"></a>4.8 合并</h2><p>指合并不同dataframe上的内容数据</p><ul><li><p>按方向拼接</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">pd.concat([data1, data2], axis=<span class="hljs-number">1</span>) <br><span class="hljs-comment">#axis：0为列索引；1为行索引</span><br></code></pre></td></tr></table></figure></li><li><p>按索引拼接</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python">left = pd.DataFrame(&#123;<span class="hljs-string">&#x27;key1&#x27;</span>: [<span class="hljs-string">&#x27;K0&#x27;</span>, <span class="hljs-string">&#x27;K0&#x27;</span>, <span class="hljs-string">&#x27;K1&#x27;</span>, <span class="hljs-string">&#x27;K2&#x27;</span>],<br>                        <span class="hljs-string">&#x27;key2&#x27;</span>: [<span class="hljs-string">&#x27;K0&#x27;</span>, <span class="hljs-string">&#x27;K1&#x27;</span>, <span class="hljs-string">&#x27;K0&#x27;</span>, <span class="hljs-string">&#x27;K1&#x27;</span>],<br>                        <span class="hljs-string">&#x27;A&#x27;</span>: [<span class="hljs-string">&#x27;A0&#x27;</span>, <span class="hljs-string">&#x27;A1&#x27;</span>, <span class="hljs-string">&#x27;A2&#x27;</span>, <span class="hljs-string">&#x27;A3&#x27;</span>],<br>                        <span class="hljs-string">&#x27;B&#x27;</span>: [<span class="hljs-string">&#x27;B0&#x27;</span>, <span class="hljs-string">&#x27;B1&#x27;</span>, <span class="hljs-string">&#x27;B2&#x27;</span>, <span class="hljs-string">&#x27;B3&#x27;</span>]&#125;)<br>right = pd.DataFrame(&#123;<span class="hljs-string">&#x27;key1&#x27;</span>: [<span class="hljs-string">&#x27;K0&#x27;</span>, <span class="hljs-string">&#x27;K1&#x27;</span>, <span class="hljs-string">&#x27;K1&#x27;</span>, <span class="hljs-string">&#x27;K2&#x27;</span>],<br>                        <span class="hljs-string">&#x27;key2&#x27;</span>: [<span class="hljs-string">&#x27;K0&#x27;</span>, <span class="hljs-string">&#x27;K0&#x27;</span>, <span class="hljs-string">&#x27;K0&#x27;</span>, <span class="hljs-string">&#x27;K0&#x27;</span>],<br>                        <span class="hljs-string">&#x27;C&#x27;</span>: [<span class="hljs-string">&#x27;C0&#x27;</span>, <span class="hljs-string">&#x27;C1&#x27;</span>, <span class="hljs-string">&#x27;C2&#x27;</span>, <span class="hljs-string">&#x27;C3&#x27;</span>],<br>                        <span class="hljs-string">&#x27;D&#x27;</span>: [<span class="hljs-string">&#x27;D0&#x27;</span>, <span class="hljs-string">&#x27;D1&#x27;</span>, <span class="hljs-string">&#x27;D2&#x27;</span>, <span class="hljs-string">&#x27;D3&#x27;</span>]&#125;)<br>pd.merge(left, right, how=<span class="hljs-string">&quot;inner&quot;</span>, on=[<span class="hljs-string">&quot;key1&quot;</span>, <span class="hljs-string">&quot;key2&quot;</span>])<br>pd.merge(left, right, how=<span class="hljs-string">&quot;left&quot;</span>, on=[<span class="hljs-string">&quot;key1&quot;</span>, <span class="hljs-string">&quot;key2&quot;</span>])<br>pd.merge(left, right, how=<span class="hljs-string">&quot;outer&quot;</span>, on=[<span class="hljs-string">&quot;key1&quot;</span>, <span class="hljs-string">&quot;key2&quot;</span>])<br><span class="hljs-comment">###这里merge参数解释：</span><br><span class="hljs-comment">#left: 需要合并的一个表，合并后在左侧</span><br><span class="hljs-comment">#right:需要合并的一个表，合并后在右侧</span><br><span class="hljs-comment">#how: 合并方式</span><br><span class="hljs-comment">#on: 在哪些索引上进行合并</span><br></code></pre></td></tr></table></figure><h1 id="4-9-交叉表与透视表"><a href="#4-9-交叉表与透视表" class="headerlink" title="4.9 交叉表与透视表"></a>4.9 交叉表与透视表</h1><p>找到、探索两个变量之间的关系0</p></li></ul>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>pytorch框架</title>
    <link href="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/"/>
    <url>/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/</url>
    
    <content type="html"><![CDATA[<h1 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h1><h1 id="Python内置函数"><a href="#Python内置函数" class="headerlink" title="Python内置函数"></a>Python内置函数</h1><h3 id="if-name-“main“"><a href="#if-name-“main“" class="headerlink" title="if _name_ &#x3D;&#x3D; “main“"></a>if _<em>name</em>_ &#x3D;&#x3D; “<strong>main</strong>“</h3><p><code>if __name__ == &quot;__main__&quot;</code> 是 Python 中的一种常见结构，用于判断一个模块是否是直接运行的程序。这个结构在模块被导入时不会执行，而在直接运行时会执行。它的意义在于帮助开发者控制代码的执行方式。</p><p><strong><code>__name__</code> 的含义</strong>:</p><ul><li>当 Python 文件被直接运行时，<code>__name__</code> 的值被设置为 <code>&quot;__main__&quot;</code>。</li><li>当 Python 文件作为模块被导入时，<code>__name__</code> 的值将是该模块的名字（即文件名，不包括扩展名）。</li></ul><p><strong>使用场景</strong>:</p><ul><li><p>这个结构通常用于测试代码或作为脚本的入口点。通过将执行的代码放在这个结构下，可以避免在模块被导入时不必要的代码执行</p><h3 id="示例代码"><a href="#示例代码" class="headerlink" title="示例代码"></a>示例代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs python">python复制代码<span class="hljs-comment"># calculator.py</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">add</span>(<span class="hljs-params">a, b</span>):<br>    <span class="hljs-keyword">return</span> a + b<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">subtract</span>(<span class="hljs-params">a, b</span>):<br>    <span class="hljs-keyword">return</span> a - b<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">multiply</span>(<span class="hljs-params">a, b</span>):<br>    <span class="hljs-keyword">return</span> a * b<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">divide</span>(<span class="hljs-params">a, b</span>):<br>    <span class="hljs-keyword">if</span> b == <span class="hljs-number">0</span>:<br>        <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&quot;Cannot divide by zero.&quot;</span>)<br>    <span class="hljs-keyword">return</span> a / b<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Simple Calculator&quot;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;1. Add&quot;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;2. Subtract&quot;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;3. Multiply&quot;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;4. Divide&quot;</span>)<br><br>    choice = <span class="hljs-built_in">input</span>(<span class="hljs-string">&quot;Choose an operation (1/2/3/4): &quot;</span>)<br><br>    a = <span class="hljs-built_in">float</span>(<span class="hljs-built_in">input</span>(<span class="hljs-string">&quot;Enter first number: &quot;</span>))<br>    b = <span class="hljs-built_in">float</span>(<span class="hljs-built_in">input</span>(<span class="hljs-string">&quot;Enter second number: &quot;</span>))<br><br>    <span class="hljs-keyword">if</span> choice == <span class="hljs-string">&#x27;1&#x27;</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;The result is: <span class="hljs-subst">&#123;add(a, b)&#125;</span>&quot;</span>)<br>    <span class="hljs-keyword">elif</span> choice == <span class="hljs-string">&#x27;2&#x27;</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;The result is: <span class="hljs-subst">&#123;subtract(a, b)&#125;</span>&quot;</span>)<br>    <span class="hljs-keyword">elif</span> choice == <span class="hljs-string">&#x27;3&#x27;</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;The result is: <span class="hljs-subst">&#123;multiply(a, b)&#125;</span>&quot;</span>)<br>    <span class="hljs-keyword">elif</span> choice == <span class="hljs-string">&#x27;4&#x27;</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;The result is: <span class="hljs-subst">&#123;divide(a, b)&#125;</span>&quot;</span>)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Invalid choice!&quot;</span>)<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    main()<br></code></pre></td></tr></table></figure><h3 id="如何使用"><a href="#如何使用" class="headerlink" title="如何使用"></a>如何使用</h3><ol><li><p><strong>直接运行</strong>:</p><ul><li><p>将上述代码保存为 <code>calculator.py</code>。</p></li><li><p>在命令行中运行：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">bash<br><br><br>复制代码<br>python calculator.py<br></code></pre></td></tr></table></figure></li><li><p>程序将提示你选择操作和输入两个数字，然后输出计算结果。</p></li></ul></li><li><p><strong>作为模块导入</strong>:</p><ul><li><p>创建另一个 Python 文件，例如 <code>main.py</code>，并导入 <code>calculator</code> 模块：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">python复制代码<span class="hljs-comment"># main.py</span><br><span class="hljs-keyword">import</span> calculator<br><br><span class="hljs-comment"># 现在你可以使用 calculator 模块中的函数</span><br>result = calculator.add(<span class="hljs-number">10</span>, <span class="hljs-number">5</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;10 + 5 = <span class="hljs-subst">&#123;result&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure></li><li><p>运行 <code>main.py</code>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs Python">bash<br><br><br>复制代码<br>python main.py<br></code></pre></td></tr></table></figure></li><li><p>这将输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs Python">复制代码<br><span class="hljs-number">10</span> + <span class="hljs-number">5</span> = <span class="hljs-number">15</span><br></code></pre></td></tr></table></figure></li></ul></li></ol><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul><li>当你直接运行 <code>calculator.py</code> 时，<code>main()</code> 函数将被调用，程序会执行计算器的功能。</li><li>当你导入 <code>calculator</code> 模块时，<code>main()</code> 函数不会被执行，你可以直接使用其中定义的计算函数。这样可以避免不必要的代码执行，保持模块的灵活性和可重用性。</li></ul></li></ul><h3 id="enumerate-函数"><a href="#enumerate-函数" class="headerlink" title="enumerate()函数"></a>enumerate()函数</h3><p>enumerate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标，一般用在 for 循环当中。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">enumerate</span>(sequence, [start=<span class="hljs-number">0</span>])<br></code></pre></td></tr></table></figure><h3 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h3><ul><li>sequence – 一个序列、迭代器或其他支持迭代对象。</li><li>start – 下标起始位置的值。</li></ul><h3 id="返回值"><a href="#返回值" class="headerlink" title="返回值"></a>返回值</h3><p>返回 enumerate(枚举) 对象。</p><h1 id="Python面向对象"><a href="#Python面向对象" class="headerlink" title="Python面向对象"></a>Python面向对象</h1><h2 id="类-class"><a href="#类-class" class="headerlink" title="类(class):"></a><strong>类(class)</strong>:</h2><p>用来描述具有相同属性和方法的集合。定义了该集合中每个对象所共有的属性和方法。<strong>对象是类的实例。</strong></p><p>###类对象</p><p>类对象支持两种操作：属性引用和实例化。</p><p>属性引用使用和 Python 中所有的属性引用一样的标准语法：<strong>obj.name</strong>。</p><p>类对象创建后，类命名空间中所有的命名都是有效属性名。所以如果类定义是这样:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyClass</span>:<br>    <span class="hljs-string">&quot;&quot;&quot;一个简单的类实例&quot;&quot;&quot;</span><br>    i = <span class="hljs-number">12345</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">f</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;hello world&#x27;</span><br> <br><span class="hljs-comment"># 实例化类</span><br>x = MyClass()<br> <br><span class="hljs-comment"># 访问类的属性和方法</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;MyClass 类的属性 i 为：&quot;</span>, x.i)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;MyClass 类的方法 f 输出为：&quot;</span>, x.f())<br></code></pre></td></tr></table></figure><p>##类属性与方法</p><p><strong>类的私有属性：</strong><strong>__private_attrs</strong>：两个下划线开头，声明该属性为私有，不能在类的外部被使用或直接访问。在类内部的方法中使用时 <strong>self.__private_attrs</strong>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">JustCounter</span>:<br>    __secretCount = <span class="hljs-number">0</span>  <span class="hljs-comment"># 私有变量</span><br>    publicCount = <span class="hljs-number">0</span>    <span class="hljs-comment"># 公开变量</span><br> <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">count</span>(<span class="hljs-params">self</span>):<br>        self.__secretCount += <span class="hljs-number">1</span><br>        self.publicCount += <span class="hljs-number">1</span><br>        <span class="hljs-built_in">print</span> (self.__secretCount)<br> <br>counter = JustCounter()<br>counter.count()<br>counter.count()<br><span class="hljs-built_in">print</span> (counter.publicCount)<br><span class="hljs-built_in">print</span> (counter.__secretCount)  <span class="hljs-comment"># 报错，实例不能访问私有变量</span><br></code></pre></td></tr></table></figure><p>###<strong>类的方法：</strong></p><p>在类的内部，使用 def 关键字来定义一个方法，与一般函数定义不同，类方法必须包含参数 <strong>self</strong>，且为第一个参数，<strong>self</strong> 代表的是类的实例。</p><p><strong>self</strong> 的名字并不是规定死的，也可以使用 <strong>this</strong>，但是最好还是按照约定使用 <strong>self</strong>。</p><h3 id="类的私有方法"><a href="#类的私有方法" class="headerlink" title="类的私有方法"></a>类的私有方法</h3><p><strong>__private_method</strong>：两个下划线开头，声明该方法为私有方法，只能在类的内部调用 ，不能在类的外部调用。<strong>self.__private_methods</strong>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Site</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, name, url</span>):<br>        self.name = name       <span class="hljs-comment"># public</span><br>        self.__url = url   <span class="hljs-comment"># private</span><br> <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">who</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;name  : &#x27;</span>, self.name)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;url : &#x27;</span>, self.__url)<br> <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__foo</span>(<span class="hljs-params">self</span>):          <span class="hljs-comment"># 私有方法</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;这是私有方法&#x27;</span>)<br> <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">foo</span>(<span class="hljs-params">self</span>):            <span class="hljs-comment"># 公共方法</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;这是公共方法&#x27;</span>)<br>        self.__foo()<br> <br>x = Site(<span class="hljs-string">&#x27;菜鸟教程&#x27;</span>, <span class="hljs-string">&#x27;www.runoob.com&#x27;</span>)<br>x.who()        <span class="hljs-comment"># 正常输出</span><br>x.foo()        <span class="hljs-comment"># 正常输出</span><br>x.__foo()      <span class="hljs-comment"># 报错</span><br></code></pre></td></tr></table></figure><p>###类的专有方法</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/%E7%B1%BB%E7%9A%84%E4%B8%93%E6%9C%89%E6%96%B9%E6%B3%95" alt="image-20221206143413965"></p><h2 id="方法："><a href="#方法：" class="headerlink" title="方法："></a><strong>方法</strong>：</h2><p>类中定义的函数。</p><ul><li><p>类有一个名为  __ init __() 的特殊方法（<strong>构造方法</strong>），该方法在类实例化时会自动调用,</p><ul><li><p>_ _ init_ <em>() 方法可以有参数，参数通过 _ <em>init</em></em> _() 传递到类的实例化操作上</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Complex</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, realpart, imagpart</span>):<br>        self.r = realpart<br>        self.i = imagpart<br>x = Complex(<span class="hljs-number">3.0</span>, -<span class="hljs-number">4.5</span>)<br><span class="hljs-built_in">print</span>(x.r, x.i)   <span class="hljs-comment"># 输出结果：3.0-4.5</span><br></code></pre></td></tr></table></figure></li><li><h3 id="self代表类的实例，而非类"><a href="#self代表类的实例，而非类" class="headerlink" title="self代表类的实例，而非类"></a>self代表类的实例，而非类</h3><ul><li>类的方法与普通的函数只有一个特别的区别——它们必须有一个额外的<strong>第一个参数名称</strong>, 按照惯例它的名称是 self.</li><li>self 代表的是类的实例，代表当前对象的地址，而 self.class 则指向类。</li><li>self 不是 python 关键字，我们把他换成 runoob 也是可以正常执行的</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Test</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">prt</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(self)<br>        <span class="hljs-built_in">print</span>(self.__class__)<br> <br>t = Test()<br>t.prt()<br></code></pre></td></tr></table></figure></li></ul></li><li><p>类的方法：在类的内部，使用 <strong>def</strong> 关键字来定义一个方法，与一般函数定义不同，类方法必须包含参数 self, 且为第一个参数，self 代表的是类的实例。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs 1">#类定义<br>class people:<br>    #定义基本属性<br>    name = &#x27;&#x27;<br>    age = 0<br>    #定义私有属性,私有属性在类外部无法直接进行访问<br>    __weight = 0<br>    #定义构造方法<br>    def __init__(self,n,a,w):<br>        self.name = n<br>        self.age = a<br>        self.__weight = w<br>    def speak(self):<br>        print(&quot;%s 说: 我 %d 岁。&quot; %(self.name,self.age))<br> <br># 实例化类<br>p = people(&#x27;runoob&#x27;,10,30)<br>p.speak()<br></code></pre></td></tr></table></figure></li></ul><p>##<strong>类变量：</strong></p><p>类变量在整个实例化的对象中是公用的。类变量定义在类中且在函数体之外。类变量通常不作为实例变量使用。</p><p>##<strong>数据成员：</strong></p><p>类变量或者实例变量用于处理类及其实例对象的相关的数据。</p><p>##<strong>方法重写：</strong></p><p>如果从父类继承的方法不能满足子类的需求，可以对其进行改写，这个过程叫方法的覆盖（override），也称为方法的重写。</p><ul><li><pre><code class="python">class Parent:        # 定义父类   def myMethod(self):      print (&#39;调用父类方法&#39;) class Child(Parent): # 定义子类   def myMethod(self):      print (&#39;调用子类方法&#39;) c = Child()          # 子类实例c.myMethod()         # 子类调用重写方法super(Child,c).myMethod() #用子类对象调用父类已被覆盖的方法<figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs clean"><br>  [super() 函数](https:<span class="hljs-comment">//www.runoob.com/python/python-func-super.html)是用于调用父类(超类)的一个方法。</span><br><br>##**局部变量：**<br><br>定义在方法中的变量，只作用于当前实例的类。<br><br>##**实例变量：**<br><br>在类的声明中，属性是用变量来表示的，这种变量就称为实例变量，实例变量就是一个用 self 修饰的变量。<br><br>##**继承：**<br><br>即一个派生类（derived <span class="hljs-keyword">class</span>）继承基类（base <span class="hljs-keyword">class</span>）的字段和方法。继承也允许把一个派生类的对象作为一个基类对象对待。例如，有这样一个设计：一个Dog类型的对象派生自Animal类，这是模拟<span class="hljs-string">&quot;是一个（is-a）&quot;</span>关系（例图，Dog是一个Animal）。<br><br>- 派生类<br><br>  ```python<br>  <span class="hljs-keyword">class</span> DerivedClassName(BaseClassName):<br>      &lt;statement<span class="hljs-number">-1</span>&gt;<br>      .<br>      .<br>      .<br>      &lt;statement-N&gt;<br></code></pre></td></tr></table></figure>子类（派生类 DerivedClassName）会继承父类（基类 BaseClassName）的属性和方法。BaseClassName（实例中的基类名）必须与派生类定义在一个作用域内。除了类，还可以用表达式，基类定义在另一个模块中时这一点非常有用:<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">DerivedClassName</span>(modname.BaseClassName):<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#类定义</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">people</span>:<br>    <span class="hljs-comment">#定义基本属性</span><br>    name = <span class="hljs-string">&#x27;&#x27;</span><br>    age = <span class="hljs-number">0</span><br>    <span class="hljs-comment">#定义私有属性,私有属性在类外部无法直接进行访问</span><br>    __weight = <span class="hljs-number">0</span><br>    <span class="hljs-comment">#定义构造方法</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,n,a,w</span>):<br>        self.name = n<br>        self.age = a<br>        self.__weight = w<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">speak</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;%s 说: 我 %d 岁。&quot;</span> %(self.name,self.age))<br> <br><span class="hljs-comment">#单继承示例</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">student</span>(<span class="hljs-title class_ inherited__">people</span>):<br>    grade = <span class="hljs-string">&#x27;&#x27;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,n,a,w,g</span>):<br>        <span class="hljs-comment">#调用父类的构函</span><br>        people.__init__(self,n,a,w)<br>        self.grade = g<br>    <span class="hljs-comment">#覆写父类的方法</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">speak</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;%s 说: 我 %d 岁了，我在读 %d 年级&quot;</span>%(self.name,self.age,self.grade))<br> <br> <br> <br>s = student(<span class="hljs-string">&#x27;ken&#x27;</span>,<span class="hljs-number">10</span>,<span class="hljs-number">60</span>,<span class="hljs-number">3</span>)<br>s.speak()<br></code></pre></td></tr></table></figure></code></pre></li><li><p>多继承</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">DerivedClassName</span>(Base1, Base2, Base3):<br>    &lt;statement-<span class="hljs-number">1</span>&gt;<br>    .<br>    .<br>    .<br>    &lt;statement-N&gt;<br></code></pre></td></tr></table></figure><p>需要注意圆括号中父类的顺序，若是父类中有相同的方法名，而在子类使用时未指定，python从左至右搜索 即方法在子类中未找到时，从左到右查找父类中是否包含方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#类定义</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">people</span>:<br>    <span class="hljs-comment">#定义基本属性</span><br>    name = <span class="hljs-string">&#x27;&#x27;</span><br>    age = <span class="hljs-number">0</span><br>    <span class="hljs-comment">#定义私有属性,私有属性在类外部无法直接进行访问</span><br>    __weight = <span class="hljs-number">0</span><br>    <span class="hljs-comment">#定义构造方法</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,n,a,w</span>):<br>        self.name = n<br>        self.age = a<br>        self.__weight = w<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">speak</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;%s 说: 我 %d 岁。&quot;</span> %(self.name,self.age))<br> <br><span class="hljs-comment">#单继承示例</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">student</span>(<span class="hljs-title class_ inherited__">people</span>):<br>    grade = <span class="hljs-string">&#x27;&#x27;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,n,a,w,g</span>):<br>        <span class="hljs-comment">#调用父类的构函</span><br>        people.__init__(self,n,a,w)<br>        self.grade = g<br>    <span class="hljs-comment">#覆写父类的方法</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">speak</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;%s 说: 我 %d 岁了，我在读 %d 年级&quot;</span>%(self.name,self.age,self.grade))<br> <br><span class="hljs-comment">#另一个类，多重继承之前的准备</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">speaker</span>():<br>    topic = <span class="hljs-string">&#x27;&#x27;</span><br>    name = <span class="hljs-string">&#x27;&#x27;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,n,t</span>):<br>        self.name = n<br>        self.topic = t<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">speak</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;我叫 %s，我是一个演说家，我演讲的主题是 %s&quot;</span>%(self.name,self.topic))<br> <br><span class="hljs-comment">#多重继承</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">sample</span>(speaker,student):<br>    a =<span class="hljs-string">&#x27;&#x27;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,n,a,w,g,t</span>):<br>        student.__init__(self,n,a,w,g)<br>        speaker.__init__(self,n,t)<br> <br>test = sample(<span class="hljs-string">&quot;Tim&quot;</span>,<span class="hljs-number">25</span>,<span class="hljs-number">80</span>,<span class="hljs-number">4</span>,<span class="hljs-string">&quot;Python&quot;</span>)<br>test.speak()   <span class="hljs-comment">#方法名同，默认调用的是在括号中参数位置排前父类的方法</span><br><span class="hljs-built_in">super</span>(student, test).speak()<br></code></pre></td></tr></table></figure></li></ul><p>##<strong>实例化：</strong></p><p>创建一个类的实例，类的具体对象。</p><h2 id="对象："><a href="#对象：" class="headerlink" title="对象："></a><strong>对象：</strong></h2><p>通过类定义的数据结构实例。对象包括两个数据成员（类变量和实例变量）和方法。</p><p>#线性模型</p><p>##MSE（平均平方误差 Mean Square Error）</p><p>![image-20221116141550394](D:\人工智能\photo\pytorch md\d2l-en-pytorch.pdf)</p><p>穷举法</p><p>#梯度下降算法实践</p><p>分治：若是凸函数可用，不是话陷入局部最优</p><p> 梯度(Gradient): </p><p>梯度下降法也会陷入到局部最优，后来在神经网络中发现用梯度下降算法很难陷入局部最优点</p><p>非凸函数： 局部最优</p><img src="凸函数" alt="image-20221116142311981" style="zoom:50%;" /><p>鞍点：梯度为0</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/%E9%9E%8D%E7%82%B9.jpj" alt="image-20221116142642619"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D" alt="image-20221116142925931"></p><p>指数加权均值：C<del>i</del>是当前损失，C^&#96;^<del>i</del>是更新后损失</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/%E6%8C%87%E6%95%B0%E5%8A%A0%E6%9D%83%E5%9D%87%E5%80%BC" alt="image-20221116143805313"></p><p>训练发散：训练集正确训练后都是收敛的，对于训练发散常见原因是学习率取得太大 </p><h2 id="随机梯度下降-SGD"><a href="#随机梯度下降-SGD" class="headerlink" title="随机梯度下降(SGD)"></a>随机梯度下降(SGD)</h2><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D.pnj" alt="image-20221116144201757"></p><h2 id="Batch"><a href="#Batch" class="headerlink" title="Batch"></a>Batch</h2><p>在梯度下降算法w计算是可以并行的</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/Batch" alt="image-20221116145124845"></p><p>#Back Propagation 反向传播</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD.pnj" alt="image-20221116150521974"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/fanxiangchuanbo.pnj" alt="image-20221116151255009"></p><h2 id="Chain-Rule-链式法则"><a href="#Chain-Rule-链式法则" class="headerlink" title="Chain Rule 链式法则"></a>Chain Rule 链式法则</h2><p> 前馈</p><p>Backward</p><p>![image-20221116152120646](chain rule.pnj)</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/%E6%B1%82%E6%A2%AF%E5%BA%A6.pnj" alt="image-20221116153023895"></p><h2 id="Pytorch中前馈和反馈计算"><a href="#Pytorch中前馈和反馈计算" class="headerlink" title="Pytorch中前馈和反馈计算"></a>Pytorch中前馈和反馈计算</h2><p>tensor:Pytorch中存储数据数据</p><p>​datagrad</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/tensor.pnj" alt="image-20221116153512231"></p><h1 id="用Pytorch实现线性回归"><a href="#用Pytorch实现线性回归" class="headerlink" title="用Pytorch实现线性回归"></a>用Pytorch实现线性回归</h1><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/pytorch%E5%AE%9E%E7%8E%B0" alt="image-20221117134749098"></p><h2 id="广播机制"><a href="#广播机制" class="headerlink" title="广播机制"></a>广播机制</h2><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/%E5%B9%BF%E6%92%AD%E6%9C%BA%E5%88%B6" alt="image-20221117135124782"></p><h2 id="affine-model-仿射模型"><a href="#affine-model-仿射模型" class="headerlink" title="affine model 仿射模型"></a>affine model 仿射模型</h2><p>线性单元</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/%E4%BB%BF%E5%B0%84%E6%A8%A1%E5%9E%8B.pnj" alt="image-20221117140010765"></p><p>列数为维度，loss为标量</p><p>定义模型时必须继承自nn.Module类构造函数：__ init __() 初始化构造对象使用的函数 和 forward()函数  前馈过程中必须使用的函数 必须定义   backward无是因为Module对象会自动求导</p><p>![image-20221117140403006](definite module..pnj)</p><p>torch.nn.Linear(,)构造对象</p><p>nn: Neural Network</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/nn_linear.pnj" alt="image-20221117143117510"></p><h2 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h2><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B.pnj" alt="image-20221117144717501"></p><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-comment">#1、数据准备</span><br>x_data = torch.Tensor([[<span class="hljs-number">1.0</span>],[<span class="hljs-number">2.0</span>],[<span class="hljs-number">3.0</span>]])<br>y_data = torch.Tensor([[<span class="hljs-number">2.0</span>],[<span class="hljs-number">4.0</span>],[<span class="hljs-number">6.0</span>]])<br><span class="hljs-comment">#2、模型 design model using class</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">LinearModel</span>(torch.nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(LinearModel,self).__init__()<br>        <span class="hljs-comment"># (1,1)是指输入x和输出y的特征维度，这里数据集中的x和y的特征都是1维的</span><br>        <span class="hljs-comment"># 该线性层需要学习的参数是w和b  获取w/b的方式分别是~linear.weight/linear.bias</span><br>        self.linear = torch.nn.Linear(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        y_pred = self.linear(x)<br>        <span class="hljs-keyword">return</span> y_pred<br>    <br>model = LinearModel()<br><span class="hljs-comment">#3、构建损失函数和优化器</span><br>criterion = torch.nn.MSELoss(reduction = <span class="hljs-string">&#x27;sum&#x27;</span>)<br>optimizer = torch.optim.SGD(model.parameters(), lr = <span class="hljs-number">0.01</span>)<br><span class="hljs-comment">#4、训练 training cycle forward, backward, update</span><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100000</span>):<br>    y_pred = model(x_data)<br>    loss = criterion(y_pred,y_data)<br>    <span class="hljs-built_in">print</span>(epoch,loss.item())<br>    <br>    optimizer.zero_grad()<br>    loss.backward()<br>    optimizer.step()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;w = &#x27;</span>, model.linear.weight.item())<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;b = &#x27;</span>, model.linear.bias.item())<br>x_test = torch.tensor([[<span class="hljs-number">4.0</span>]])<br>y_test = model(x_test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;y_pred = &#x27;</span>, y_test.data)<br></code></pre></td></tr></table></figure><h1 id="逻辑斯蒂回归-分类-classification"><a href="#逻辑斯蒂回归-分类-classification" class="headerlink" title="逻辑斯蒂回归   分类(classification)"></a>逻辑斯蒂回归   分类(classification)</h1><p>分类问题中输出的是概率</p><p>二分类：只有两个类别的分类问题</p><h2 id="torchvision"><a href="#torchvision" class="headerlink" title="torchvision"></a>torchvision</h2><p>torchvision中有很多数据集</p><p>参数train表示想要下载的是训练集还是测试集</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/minist" alt="image-20221121142857457"></p><p>##Logistic Function</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/logistic" alt="image-20221121144142954"></p><p>sigmoid functions</p><p>![image-20221121144317732](sigmoid functions)</p><p>##Logistic Regression Model</p><p>![image-20221121144514372](logistic Regression Model)</p><h2 id="Loss-function-for-Binary-Classification"><a href="#Loss-function-for-Binary-Classification" class="headerlink" title="Loss function for Binary Classification"></a>Loss function for Binary Classification</h2><p>此时，我们输出的不在是一个数值而是一个分布</p><p>BCE</p><p>![image-20221121145001408](Loss function classcification)</p><p>两个分布间的差异</p><p>交叉熵</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/BCE" alt="image-20221121150352368"></p><h1 id="处理多维特征的输入"><a href="#处理多维特征的输入" class="headerlink" title="处理多维特征的输入"></a>处理多维特征的输入</h1><p>行——样本(sample)</p><p>列——特征(Feature)</p><p>并行计算</p><p>![image-20221205173832561](mini batch)</p><h2 id="构造多层神经网络"><a href="#构造多层神经网络" class="headerlink" title="构造多层神经网络"></a>构造多层神经网络</h2><p>![image-20221205175024819](Linear Layer)</p><h1 id="加载数据集"><a href="#加载数据集" class="headerlink" title="加载数据集"></a>加载数据集</h1><p>Dataset——数据集 索引</p><p>DataLoader——Mini Batch</p><h2 id="Epoch、Batch-Size、Iterations"><a href="#Epoch、Batch-Size、Iterations" class="headerlink" title="Epoch、Batch-Size、Iterations"></a>Epoch、Batch-Size、Iterations</h2><p>Epoch:所有的训练样本进行了一次前向传播和反向传播是1次Epoch</p><p>Batch Size : 每次训练所用的样本数量</p><p>Iteration:迭代了多少次 </p><p>shuffle&#x3D;True 打乱数据集</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/shuffle" alt="image-20221205204633113"></p><h1 id="多分类问题"><a href="#多分类问题" class="headerlink" title="多分类问题"></a>多分类问题</h1><p>实现输出分类的要求 大于0 和为1</p><p>![image-20221208151950706](D:\人工智能\photo\pytorch md\sigmoid)</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/softmax" alt="image-20221208152435101"></p><p>![image-20221208152553537](softmax example)</p><h2 id="NLLLoss"><a href="#NLLLoss" class="headerlink" title="NLLLoss"></a>NLLLoss</h2><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/NLLLoss" alt="image-20221208153731662"></p><p>![image-20221208153816627](D:\人工智能\photo\pytorch md\torch.crossEntropy)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> transforms<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> datasets<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim<br><br><span class="hljs-comment"># prepare dataset</span><br><br>batch_size = <span class="hljs-number">64</span><br>transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((<span class="hljs-number">0.1307</span>,), (<span class="hljs-number">0.3081</span>,))])  <span class="hljs-comment"># 归一化,均值和方差</span><br><br>train_dataset = datasets.MNIST(root=<span class="hljs-string">&#x27;../dataset/mnist/&#x27;</span>, train=<span class="hljs-literal">True</span>, download=<span class="hljs-literal">True</span>, transform=transform)<br>train_loader = DataLoader(train_dataset, shuffle=<span class="hljs-literal">True</span>, batch_size=batch_size)<br>test_dataset = datasets.MNIST(root=<span class="hljs-string">&#x27;../dataset/mnist/&#x27;</span>, train=<span class="hljs-literal">False</span>, download=<span class="hljs-literal">True</span>, transform=transform)<br>test_loader = DataLoader(test_dataset, shuffle=<span class="hljs-literal">False</span>, batch_size=batch_size)<br><br><br><span class="hljs-comment"># design model using class</span><br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Net</span>(torch.nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(Net, self).__init__()<br>        self.l1 = torch.nn.Linear(<span class="hljs-number">784</span>, <span class="hljs-number">512</span>)<br>        self.l2 = torch.nn.Linear(<span class="hljs-number">512</span>, <span class="hljs-number">256</span>)<br>        self.l3 = torch.nn.Linear(<span class="hljs-number">256</span>, <span class="hljs-number">128</span>)<br>        self.l4 = torch.nn.Linear(<span class="hljs-number">128</span>, <span class="hljs-number">64</span>)<br>        self.l5 = torch.nn.Linear(<span class="hljs-number">64</span>, <span class="hljs-number">10</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = x.view(-<span class="hljs-number">1</span>, <span class="hljs-number">784</span>)  <span class="hljs-comment"># -1其实就是自动获取mini_batch</span><br>        x = F.relu(self.l1(x))<br>        x = F.relu(self.l2(x))<br>        x = F.relu(self.l3(x))<br>        x = F.relu(self.l4(x))<br>        <span class="hljs-keyword">return</span> self.l5(x)  <span class="hljs-comment"># 最后一层不做激活，不进行非线性变换</span><br><br><br>model = Net()<br><br><span class="hljs-comment"># construct loss and optimizer</span><br>criterion = torch.nn.CrossEntropyLoss()<br>optimizer = optim.SGD(model.parameters(), lr=<span class="hljs-number">0.01</span>, momentum=<span class="hljs-number">0.5</span>)<br><br><br><span class="hljs-comment"># training cycle forward, backward, update</span><br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">epoch</span>):<br>    running_loss = <span class="hljs-number">0.0</span><br>    <span class="hljs-keyword">for</span> batch_idx, data <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_loader, <span class="hljs-number">0</span>):<br>        <span class="hljs-comment"># 获得一个批次的数据和标签</span><br>        inputs, target = data<br>        optimizer.zero_grad()<br>        <span class="hljs-comment"># 获得模型预测结果(64, 10)</span><br>        outputs = model(inputs)<br>        <span class="hljs-comment"># 交叉熵代价函数outputs(64,10),target（64）</span><br>        loss = criterion(outputs, target)<br>        loss.backward()<br>        optimizer.step()<br><br>        running_loss += loss.item()<br>        <span class="hljs-keyword">if</span> batch_idx % <span class="hljs-number">300</span> == <span class="hljs-number">299</span>:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;[%d, %5d] loss: %.3f&#x27;</span> % (epoch + <span class="hljs-number">1</span>, batch_idx + <span class="hljs-number">1</span>, running_loss / <span class="hljs-number">300</span>))<br>            running_loss = <span class="hljs-number">0.0</span><br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>():<br>    correct = <span class="hljs-number">0</span><br>    total = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> test_loader:<br>            images, labels = data<br>            outputs = model(images)<br>            _, predicted = torch.<span class="hljs-built_in">max</span>(outputs.data, dim=<span class="hljs-number">1</span>)  <span class="hljs-comment"># dim = 1 列是第0个维度，行是第1个维度</span><br>            total += labels.size(<span class="hljs-number">0</span>)<br>            correct += (predicted == labels).<span class="hljs-built_in">sum</span>().item()  <span class="hljs-comment"># 张量之间的比较运算</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;accuracy on test set: %d %% &#x27;</span> % (<span class="hljs-number">100</span> * correct / total))<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>        train(epoch)<br>        test()<br></code></pre></td></tr></table></figure><h1 id="卷积神经网路-CNN"><a href="#卷积神经网路-CNN" class="headerlink" title="卷积神经网路 CNN"></a>卷积神经网路 CNN</h1><p>图片全连接后 可能会丧失一些原有的图片的空间的特征，比如图片中两点列相邻但是全连接后岔开</p><p>卷积神经网络将图像按原始空间结构进行保存</p><p>输入张量的维度 与 输出张量的维度</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/CNN" alt="image-20221208191834585"></p><p>Feature Extraction 特征提取器 Classification 分类器</p><h2 id="图像是什么？"><a href="#图像是什么？" class="headerlink" title="图像是什么？"></a>图像是什么？</h2><p>RGB——</p><p>栅格图像矢量图像 </p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/Convolution" alt="image-20221208194310511"></p><p>![image-20221208195206388](convolution 你inputchannels)</p><p>![image-20221208195249426](Convolution n input channels and M output Channels)</p><p>![image-20221208202749780](pytorch md\Convolution Layer)</p><h2 id="padding"><a href="#padding" class="headerlink" title="padding"></a>padding</h2><p>![image-20221208203047225](D:\人工智能\photo\pytorch md\padding)</p><h2 id="stride-步长"><a href="#stride-步长" class="headerlink" title="stride 步长"></a>stride 步长</h2><p>每次索引的坐标+</p><p>可有效降低图像的宽度和高度</p><h2 id="Max-Pooling-最大池化层"><a href="#Max-Pooling-最大池化层" class="headerlink" title="Max Pooling  最大池化层"></a>Max Pooling  最大池化层</h2><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/MaxPooling" alt="image-20221208204115830"></p><p>分成n*n组，找每组的最大值</p><p>![image-20221208204503171](Simple Example)</p><p>减少代码冗余：函数&#x2F;类</p><p>Concatenate：拼接 将张量沿着通道连接</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/concatenate" alt="image-20221209100738941"></p><p>What is 1×1 convolution？</p><p>信息融合  改变通道数量</p><p>![image-20221209101316370](1×1 convolution) </p><p>![image-20221209102406979](why  is 1×1)</p><h1 id="循环神经网络-RNN"><a href="#循环神经网络-RNN" class="headerlink" title="循环神经网络 RNN"></a>循环神经网络 RNN</h1><p>DNN：Dense（Deep） 稠密神经网络</p><p>RNN：处理具有序列连接的输入数据（例如：金融股市、天气、自然语言处理）</p><h2 id="RNN-Cell"><a href="#RNN-Cell" class="headerlink" title="RNN Cell"></a>RNN Cell</h2><p>本质：线形层，把某个维度映射到另一个维度的空间。 Linear</p><p>![image-20221214165453611](RNN Cell)</p><p>![image-20221214171337356](RNN Cell2)</p><p>![image-20221214171356832](D:\人工智能\photo\pytorch md\RNN Cell3)</p><p>![image-20221214171723190](RNN Cell in Pytorch)</p><p>![image-20221214174335513](RNN Cell in Pytorch 2)</p><h2 id="How-to-use-RNNCell"><a href="#How-to-use-RNNCell" class="headerlink" title="How to use RNNCell"></a>How to use RNNCell</h2><p>![image-20221214174455158](use RNNCell1)</p><p>![image-20221214174611539](use RNNCell2)</p><p>![image-20221214174814307](use RNNCell3)</p><h2 id="How-to-use-RNN"><a href="#How-to-use-RNN" class="headerlink" title="How to use RNN"></a>How to use RNN</h2><p>![image-20221214174959457](use RNN1)</p><p>![image-20221214180055695](use RNN2)</p><p>![image-20221214180951812](use RNN3)</p><p>![image-20221214181039389](use RNN4)</p><p>![image-20221214181656965](use RNN5)</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/batch_first1" alt="image-20221214181925459"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/batch_first2" alt="image-20221214182021109"></p><h1 id="李宏毅深度学习"><a href="#李宏毅深度学习" class="headerlink" title="李宏毅深度学习"></a>李宏毅深度学习</h1><p>##Pytorch Tutorial</p><p>![image-20230214164320489](pytorch turtorial)</p><p>###Step1 Load Data</p><p>torch.utils.data.Dataset &amp; torch.utils.data.DataLoader</p><ul><li><p>Dataset:stores data samples and expected values  将Python定义class将资料一笔笔读进来打包。                 </p></li><li><p>Dataloader: groups data in batches, enables multiprocessing 将Dataset中一个个的资料合并成一个个batch，平行化处理</p></li><li><p>dataset &#x3D; MyDataset(file)</p></li><li><p>dataloader &#x3D; Dataloader(dataset, batch_size, shuffle &#x3D; True)</p></li></ul><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/Dataset" alt="image-20230214144609312"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/Dataset2" alt="image-20230214144900704"></p><h4 id="Tensors"><a href="#Tensors" class="headerlink" title="Tensors"></a>Tensors</h4><ul><li>High-dimensional matrices (arrays)</li></ul><p><strong>Shape of Tensors</strong></p><p>​Check with .shape() </p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/Tensor" alt="image-20230214145346135"></p><h5 id="Creating-tensors"><a href="#Creating-tensors" class="headerlink" title="Creating tensors"></a>Creating tensors</h5><p>![image-20230214150139489](creat tensors)</p><h5 id="Common-operations"><a href="#Common-operations" class="headerlink" title="Common operations"></a>Common operations</h5><ul><li><p>Addition</p><p>​z &#x3D; x + y</p><p>​z&#x3D;torch.add(x,y)</p></li><li><p>Subtraction</p><p>​z &#x3D; x - y</p><p>​z&#x3D; torch.sub(x,y)</p></li><li><p>Power</p><p>​y &#x3D; x.pow(2)</p></li><li><p>Summation</p><p>​y &#x3D; x.sum()</p></li><li><p>Mean</p><p>​y &#x3D; x.mean()</p></li><li><p>Transpose:transpose two specified dimensions</p><p>​<img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/transpose" alt="image-20230214155039585"></p></li><li><p>Squeeze</p></li></ul><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/squeezw" alt="image-20230214155219945"></p><ul><li>Unsqueeze</li></ul><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/unsqueeze" alt="image-20230214155829437"></p><ul><li>Cat</li></ul><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/cat" alt="image-20230214155853582"></p><ul><li>Device</li></ul><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/device" alt="image-20230214161322544"></p><h5 id="Gradient-Calculation"><a href="#Gradient-Calculation" class="headerlink" title="Gradient Calculation"></a>Gradient Calculation</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">x = torch.tensor([[<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>], [-<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>]], requires_grad=<span class="hljs-literal">True</span>)<br>z= x.<span class="hljs-built_in">pow</span>(<span class="hljs-number">2</span>).<span class="hljs-built_in">sum</span>()<br>z.backward()<br>x.grad<br></code></pre></td></tr></table></figure><p>###Step 2 Define Neural Network</p><p><strong>torch.nn.Module</strong></p><ul><li>Linear Layer(Fully-connected Layer)</li><li>Non-Linear Activation Functions</li></ul><p>####Build your own neural network</p><p>![image-20230214163500685](build network)</p><p>![image-20230214163623783](build network2)</p><h3 id="Step-3-Loss-Function"><a href="#Step-3-Loss-Function" class="headerlink" title="Step 3 Loss Function"></a>Step 3 Loss Function</h3><p>torch.nn.MSELoss<br>torch.nn.CrossEntropyLoss etc.</p><p>![image-20230214163759146](Loss functions)</p><h3 id="Step-4-Optimization-Algorithm"><a href="#Step-4-Optimization-Algorithm" class="headerlink" title="Step 4 Optimization Algorithm"></a>Step 4 Optimization Algorithm</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/optim" alt="image-20230214164200244"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/optim2" alt="image-20230214164218386"></p><h3 id="Step-5-Entire-Procedure"><a href="#Step-5-Entire-Procedure" class="headerlink" title="Step 5 Entire Procedure"></a>Step 5 Entire Procedure</h3><p>![image-20230214164603078](nn training setup)</p><p>![image-20230214164730311](nn training loop)</p><p>![image-20230214165115010](nn Validation loop)</p><p>![image-20230214165337476](nn testing loop)</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/notice" alt="image-20230214170501908"></p><h3 id="Save-Load-Trained-Models"><a href="#Save-Load-Trained-Models" class="headerlink" title="Save&#x2F;Load Trained Models"></a>Save&#x2F;Load Trained Models</h3><p>![image-20230214170609228](save load models)</p><h2 id="Gradient-Decent"><a href="#Gradient-Decent" class="headerlink" title="Gradient Decent"></a>Gradient Decent</h2><h3 id="Backpropagation"><a href="#Backpropagation" class="headerlink" title="Backpropagation"></a>Backpropagation</h3><p>​<strong>Chain Rule</strong></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/chainrule" alt="image-20230215200837078"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/backpropagation" alt="image-20230215200915833"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/Backpropagation2" alt="image-20230215201437884"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/backpropagation3" alt="image-20230215201710167"></p><h2 id="Regression"><a href="#Regression" class="headerlink" title="Regression"></a>Regression</h2><p>[Regression李宏毅]:(<a href="https://github.com/Fafa-DL/Lhy_Machine_Learning/blob/main/%E9%80%89%E4%BF%AE">https://github.com/Fafa-DL/Lhy_Machine_Learning/blob/main/选修</a> To Learn More&#x2F;第一节&#x2F;Regression.pdf)</p><h3 id="Step-1-Model"><a href="#Step-1-Model" class="headerlink" title="Step 1 Model"></a>Step 1 Model</h3><p>![image-20230216104238590](regression model)</p><h3 id="Step2-Goodness-of-Function"><a href="#Step2-Goodness-of-Function" class="headerlink" title="Step2 Goodness of Function"></a>Step2 Goodness of Function</h3><p>![image-20230216104604935](regression goodnessof function)</p><h3 id="Step3-Best-Function"><a href="#Step3-Best-Function" class="headerlink" title="Step3 Best Function"></a>Step3 Best Function</h3><p>![image-20230216104653344](regression best function)</p><p>![image-20230216104725243](gradient descent)</p><p>Local minima Global minima</p><h3 id="Model-Selection"><a href="#Model-Selection" class="headerlink" title="Model Selection"></a>Model Selection</h3><p>![image-20230216104921552](regression model selection)</p><p><strong><strong>Overfitting</strong>:   A  more complex model does not always lead to better performance on testing data.</strong></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220164830103.png" alt="image-20230220164830103"></p><p>[回归 模型选择](<a href="https://github.com/Fafa-DL/Lhy_Machine_Learning/blob/main/%E9%80%89%E4%BF%AE">https://github.com/Fafa-DL/Lhy_Machine_Learning/blob/main/选修</a> To Learn More&#x2F;第一节&#x2F;Regression.pdf)</p><h3 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a><strong>Regularization</strong></h3><p>Redefine Loss function</p><p>![image-20230216105114915](regression regularization)</p><p><strong>Smoother</strong>：meaning is when the input change, the output change smaller(smooth)</p><p>Why we want a smooth function?: If some noises corrupt input x<del>i</del> When testing， a smooth function has less influence.</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220165823191.png" alt="image-20230220165823191"></p><h2 id="Classification"><a href="#Classification" class="headerlink" title="Classification"></a>Classification</h2><h3 id="Gaussian-Distribution"><a href="#Gaussian-Distribution" class="headerlink" title="Gaussian Distribution"></a>Gaussian Distribution</h3><p>![image-20230216142409305](gaussian diutution)</p><p>![image-20230216142609834](probability from class)</p><p>![image-20230216142701986](Maximum Likehood)</p><p>![image-20230216143712066](maximum likehood2)</p><h2 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h2><p>![image-20230216144705245](Logistic regree)</p><p>![image-20230216144840928](logistic regree2)</p><p>![image-20230216150359309](logistic regree3)</p><p>![image-20230216150747837](logistic regress4)</p><p>![image-20230216152128713](logistic regree5)</p><p>![image-20230216153003383](logistic regree6)</p><p>![image-20230216153048539](logistic regree7)</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230216153209267.png" alt="image-20230216153209267"></p><p> <img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230216153429112.png" alt="image-20230216153429112"></p><p>![image-20230216154717652](cross entropy)</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230216155931419.png" alt="image-20230216155931419"></p><p>Generative model 进行了一定的假设</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230216160817270.png" alt="image-20230216160817270"></p><h3 id="Multi-class-Classfication"><a href="#Multi-class-Classfication" class="headerlink" title="Multi-class Classfication"></a>Multi-class Classfication</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230216161736917.png" alt="image-20230216161736917"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230216162028665.png" alt="image-20230216162028665"></p><h3 id="Limitation-of-Logistic-Regression"><a href="#Limitation-of-Logistic-Regression" class="headerlink" title="Limitation of Logistic Regression"></a>Limitation of Logistic Regression</h3><p>Feature Transformation</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230216162441172.png" alt="image-20230216162441172"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230216163421455.png" alt="image-20230216163421455"></p><h2 id="General-Guidance"><a href="#General-Guidance" class="headerlink" title="General Guidance"></a>General Guidance</h2><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217162531424.png" alt="image-20230217162531424"></p><h3 id="Model-Bias"><a href="#Model-Bias" class="headerlink" title="Model Bias"></a>Model Bias</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217163405067.png" alt="image-20230217163405067"></p><h3 id="OPtimization-Issue"><a href="#OPtimization-Issue" class="headerlink" title="OPtimization Issue"></a>OPtimization Issue</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217163545349.png" alt="image-20230217163545349"></p><h3 id="Overfitting"><a href="#Overfitting" class="headerlink" title="Overfitting"></a>Overfitting</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217163840304.png" alt="image-20230217163840304"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217164009238.png" alt="image-20230217164009238"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217164404659.png" alt="image-20230217164404659"></p><p><strong>Data augmentation 要根据资料特性合理设置</strong></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217164553921.png" alt="image-20230217164553921"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217164710202.png" alt="image-20230217164710202"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217164849894.png" alt="image-20230217164849894"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217165040061.png" alt="image-20230217165040061"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217165245444.png" alt="image-20230217165245444"></p><p><strong>模型选择 有可能恰好模型产生随机全正确</strong></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217170146204.png" alt="image-20230217170146204"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217170342996.png" alt="image-20230217170342996"></p><h4 id="used-a-validation-set-but-model-still-overfitted"><a href="#used-a-validation-set-but-model-still-overfitted" class="headerlink" title="used a validation set, but model still overfitted?"></a>used a validation set, but model still overfitted?</h4><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222150042220.png" alt="image-20230222150042220"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222150507570.png" alt="image-20230222150507570"></p><h3 id="Mismatch"><a href="#Mismatch" class="headerlink" title="Mismatch"></a>Mismatch</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217170703851.png" alt="image-20230217170703851"></p><h2 id="ptimization-Fails"><a href="#ptimization-Fails" class="headerlink" title="ptimization Fails"></a>ptimization Fails</h2><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217174738922.png" alt="image-20230217174738922"></p><h3 id="local-minima"><a href="#local-minima" class="headerlink" title="local minima"></a>local minima</h3><h3 id="saddle-point"><a href="#saddle-point" class="headerlink" title="saddle point"></a>saddle point</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217175230940.png" alt="image-20230217175230940"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217175445395.png" alt="image-20230217175445395"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217175935273.png" alt="image-20230217175935273"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217185855119.png" alt="image-20230217185855119"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217190539102.png" alt="image-20230217190539102"></p><h4 id="Don’t-afraid-of-saddle-point"><a href="#Don’t-afraid-of-saddle-point" class="headerlink" title="Don’t afraid of saddle point"></a>Don’t afraid of saddle point</h4><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217190851402.png" alt="image-20230217190851402"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217192854428.png" alt="image-20230217192854428"></p><h2 id="Batch-and-Momentum"><a href="#Batch-and-Momentum" class="headerlink" title="Batch and Momentum"></a>Batch and Momentum</h2><h3 id="Batch-1"><a href="#Batch-1" class="headerlink" title="Batch"></a>Batch</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217194431309.png" alt="image-20230217194431309"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217195204374.png" alt="image-20230217195204374"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217200343404.png" alt="image-20230217200343404"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217200535811.png" alt="image-20230217200535811"></p><p>   <img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217200708347.png" alt="image-20230217200708347"></p><p>·Small batch is better on testing data</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217201131973.png" alt="image-20230217201131973"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217201303403.png" alt="image-20230217201303403"></p><h3 id="Momentum"><a href="#Momentum" class="headerlink" title="Momentum"></a>Momentum</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217201537450.png" alt="image-20230217201537450"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230217202010268.png" alt="image-20230217202010268"></p><h2 id="Adptive-Learning-Rate"><a href="#Adptive-Learning-Rate" class="headerlink" title="Adptive Learning Rate"></a>Adptive Learning Rate</h2><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219103610912.png" alt="image-20230219103610912"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219104510420.png" alt="image-20230219104510420"></p><p><strong>在某一个方向上梯度小希望学习率大一些，在某个方向梯度大一些希望学习率小一些</strong></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219104723217.png" alt="image-20230219104723217"></p><p>###Root Mean Square</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219105222073.png" alt="image-20230219105222073"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219105414500.png" alt="image-20230219105414500"></p><p> <img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219105807737.png" alt="image-20230219105807737"></p><h3 id="RMSProop"><a href="#RMSProop" class="headerlink" title="RMSProop"></a>RMSProop</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219110213837.png" alt="image-20230219110213837"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219110527256.png" alt="image-20230219110527256"></p><h4 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h4><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219110610162.png" alt="image-20230219110610162"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219113320260.png" alt="image-20230219113320260"></p><h3 id="New-Optimizers-for-Deep-Learning"><a href="#New-Optimizers-for-Deep-Learning" class="headerlink" title="New Optimizers for Deep Learning"></a>New Optimizers for Deep Learning</h3><p>[Lhy_Machine_Learning&#x2F;Optimization.pdf at main · Fafa-DL&#x2F;Lhy_Machine_Learning (github.com)](<a href="https://github.com/Fafa-DL/Lhy_Machine_Learning/blob/main/%E9%80%89%E4%BF%AE">https://github.com/Fafa-DL/Lhy_Machine_Learning/blob/main/选修</a> To Learn More&#x2F;第二节&#x2F;Optimization.pdf)</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219173231485.png" alt="image-20230219173231485"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219173402903.png" alt="image-20230219173402903"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219173520988.png" alt="image-20230219173520988"></p><h4 id="SGD"><a href="#SGD" class="headerlink" title="SGD"></a>SGD</h4><h4 id="SGD-with-Momentum-SGDM"><a href="#SGD-with-Momentum-SGDM" class="headerlink" title="SGD with Momentum (SGDM)"></a>SGD with Momentum (SGDM)</h4><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219174817789.png" alt="image-20230219174817789"></p><h4 id="Adagraad"><a href="#Adagraad" class="headerlink" title="Adagraad"></a>Adagraad</h4><h4 id="RMSProp"><a href="#RMSProp" class="headerlink" title="RMSProp"></a>RMSProp</h4><h4 id="Adam-1"><a href="#Adam-1" class="headerlink" title="Adam"></a>Adam</h4><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219175650535.png" alt="image-20230219175650535"></p><img src="image-20230219175745769.png" alt="image-20230219175745769" style="zoom:50%;" /><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219182432823.png" alt="image-20230219182432823"></p><p>尝试解释为什么Adam和SGDM训练不一样：</p><p>​Loss Function比较平坦，训练和测试的的Minimum就会比较接近</p><h5 id="Simply-combine-Adam-with-SGDM？—-SWATS"><a href="#Simply-combine-Adam-with-SGDM？—-SWATS" class="headerlink" title="Simply combine Adam with SGDM？—-SWATS"></a>Simply combine Adam with SGDM？—-SWATS</h5><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219182959481.png" alt="image-20230219182959481"></p><h5 id="Towards-Improving-Adam"><a href="#Towards-Improving-Adam" class="headerlink" title="Towards Improving Adam"></a>Towards Improving Adam</h5><p><a href="https://www.bilibili.com/video/BV1VN4y1P7Zj?t=2352.9&p=26">视频解释 39:00</a></p><p>假设β<del>1</del>&#x3D;0，则未使用m<del>t</del>，focous adaptive learning rate对Adam造成的影响。通过v<del>t</del>表达式可知v<del>t</del>受到梯度的影响会维持1&#x2F;(1-0.999)</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219184733050.png" alt="image-20230219184733050"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219184845319.png" alt="image-20230219184845319"></p><h6 id="AMSGrad"><a href="#AMSGrad" class="headerlink" title="AMSGrad"></a>AMSGrad</h6><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219185255264.png" alt="image-20230219185255264"></p><h5 id="Towards-Improving-SGDM"><a href="#Towards-Improving-SGDM" class="headerlink" title="Towards Improving SGDM"></a>Towards Improving SGDM</h5><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219185732554.png" alt="image-20230219185732554"></p><p><strong>Engineering：learning rate很小或很大精度都不会很好，适中</strong></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219185906756.png" alt="image-20230219185906756"></p><h5 id="Does-Adam-need-warm-up"><a href="#Does-Adam-need-warm-up" class="headerlink" title="Does Adam need warm-up?"></a>Does Adam need warm-up?</h5><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220151750842.png" alt="image-20230220151750842"></p><p>为什么Adam已经Adaptive rate为什么还需要warm up?：上图实际实验说明（横轴为Iteration，纵轴为gradient 的distribution），前几步的估计不准</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220152751776.png" alt="image-20230220152751776"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220153041140.png" alt="image-20230220153041140"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220153440025.png" alt="image-20230220153440025"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220154709135.png" alt="image-20230220154709135"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220154902836.png" alt="image-20230220154902836"></p><h5 id="More-than-momentum"><a href="#More-than-momentum" class="headerlink" title="More than momentum"></a>More than momentum</h5><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220155117699.png" alt="image-20230220155117699"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220160235068.png" alt="image-20230220160235068"></p><p><strong>▽L(θ<del>t-1</del>-λm<del>t-1</del>)表示预测下一点的梯度时如何</strong></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220161633898.png" alt="image-20230220161633898"></p><h5 id="Nadam"><a href="#Nadam" class="headerlink" title="Nadam"></a>Nadam</h5><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220162817076.png" alt="image-20230220162817076"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220163803033.png" alt="image-20230220163803033"></p><h4 id="Something-helps-optimization"><a href="#Something-helps-optimization" class="headerlink" title="Something helps optimization"></a>Something helps optimization</h4><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220163905897.png" alt="image-20230220163905897"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220164300905.png" alt="image-20230220164300905"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230220164324808.png" alt="image-20230220164324808"></p><h2 id="Learning-Rate-Scheduling"><a href="#Learning-Rate-Scheduling" class="headerlink" title="Learning Rate Scheduling"></a>Learning Rate Scheduling</h2><p>将Learning Rate与时间有关</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219113538883.png" alt="image-20230219113538883"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219114058621.png" alt="image-20230219114058621"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219113906542.png" alt="image-20230219113906542"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219114343052.png" alt="image-20230219114343052"></p><h2 id="再探宝可梦、数码宝贝分类器—浅谈机器学习原理"><a href="#再探宝可梦、数码宝贝分类器—浅谈机器学习原理" class="headerlink" title="再探宝可梦、数码宝贝分类器—浅谈机器学习原理"></a>再探宝可梦、数码宝贝分类器—浅谈机器学习原理</h2><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219134611063.png" alt="image-20230219134611063"></p><h4 id="模型复杂度"><a href="#模型复杂度" class="headerlink" title="模型复杂度"></a>模型复杂度</h4><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219140424624.png" alt="image-20230219140424624"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219140828795.png" alt="image-20230219140828795"></p><h4 id="i-i-d"><a href="#i-i-d" class="headerlink" title="i.i.d"></a>i.i.d</h4><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219141400722.png" alt="image-20230219141400722"></p><p>![image-20230219141507996](D:\人工智能\photo\pytorch md\image-20230219141507996.png)</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219142322281.png" alt="image-20230219142322281"></p><h3 id="What-train-sample-do-we-want"><a href="#What-train-sample-do-we-want" class="headerlink" title="What train sample do we want?"></a>What train sample do we want?</h3><p><strong>train得到的模型好坏取决于sample时的资料</strong></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219143624556.png" alt="image-20230219143624556"></p><p>L(h^all^, D<del>all</del> )一定会比L(h^train^, D<del>all</del> )小</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219143741645.png" alt="image-20230219143741645"></p><p>![image-20230219143939593](D:\人工智能\photo\pytorch md\image-20230219143939593.png)</p><h3 id="General"><a href="#General" class="headerlink" title="General"></a>General</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219144104393.png" alt="image-20230219144104393"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219150624632.png" alt="image-20230219150624632"></p><img src="image-20230219150949584.png" alt="image-20230219150949584" style="zoom: 50%;" /><img src="D:\人工智能\photo\pytorch md\image-20230219151206774.png" alt="image-20230219151206774" style="zoom:50%;" /><img src="image-20230219151432675.png" alt="image-20230219151432675" style="zoom:50%;" /><img src="image-20230219151632461.png" alt="image-20230219151632461" style="zoom:50%;" /><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219151824419.png" alt="image-20230219151824419"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219151902001.png" alt="image-20230219151902001"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219151916700.png" alt="image-20230219151916700"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219152147020.png" alt="image-20230219152147020"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219152515395.png" alt="image-20230219152515395"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219152656072.png" alt="image-20230219152656072"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219153140826.png" alt="image-20230219153140826"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230219153347413.png" alt="image-20230219153347413"></p><h3 id="Why-more-parameters-are-easier-to-overfit"><a href="#Why-more-parameters-are-easier-to-overfit" class="headerlink" title="Why more parameters are easier to overfit?"></a>Why more parameters are easier to overfit?</h3><h2 id="鱼与熊掌可以兼得的机器学习"><a href="#鱼与熊掌可以兼得的机器学习" class="headerlink" title="鱼与熊掌可以兼得的机器学习"></a>鱼与熊掌可以兼得的机器学习</h2><h3 id="Review：Why-hidden-layer"><a href="#Review：Why-hidden-layer" class="headerlink" title="Review：Why hidden layer?"></a>Review：Why hidden layer?</h3><p>可以通过一个hidden layer找出所有可能的function</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222151535069.png" alt="image-20230222151535069"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222151614261.png" alt="image-20230222151614261"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222151643870.png" alt="image-20230222151643870"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222152253769.png" alt="image-20230222152253769"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222152423524.png" alt="image-20230222152423524"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222152447853.png" alt="image-20230222152447853"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222153444309.png" alt="image-20230222153444309"></p><p>探讨网络深层的作用</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222154525682.png" alt="image-20230222154525682"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222154753511.png" alt="image-20230222154753511"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222155100307.png" alt="image-20230222155100307"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222155207551.png" alt="image-20230222155207551"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222155229862.png" alt="image-20230222155229862"></p><h2 id="HW2"><a href="#HW2" class="headerlink" title="HW2"></a>HW2</h2><h2 id="Concolutional-Neural-Network-CNN"><a href="#Concolutional-Neural-Network-CNN" class="headerlink" title="Concolutional Neural Network(CNN)"></a>Concolutional Neural Network(CNN)</h2><p><strong>Network Architecture designed for Image</strong></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230221190847727.png" alt="image-20230221190847727"></p><p>对电脑来说一张图片是什么？</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230221191148146.png" alt="image-20230221191148146"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222133926254.png" alt="image-20230222133926254"></p><p>参数过多容易overfitting</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222134324377.png" alt="image-20230222134324377"></p><h3 id="Receptive-field"><a href="#Receptive-field" class="headerlink" title="Receptive field"></a>Receptive field</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222134630110.png" alt="image-20230222134630110"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222135225522.png" alt="image-20230222135225522"></p><p>·</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222135722131.png" alt="image-20230222135722131"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222135846875.png" alt="image-20230222135846875"></p><p>parameter sharing</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222140105874.png" alt="image-20230222140105874"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222140225472.png" alt="image-20230222140225472"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222140412998.png" alt="image-20230222140412998"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222140504306.png" alt="image-20230222140504306"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222140728856.png" alt="image-20230222140728856"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222140813030.png" alt="image-20230222140813030"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222140957944.png" alt="image-20230222140957944"></p><p>若filter大小一直设置3*3，会使network不能看更大的图吗？</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222141306342.png" alt="image-20230222141306342"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222141343778.png" alt="image-20230222141343778"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222141401887.png" alt="image-20230222141401887"></p><p>同样的小目标可以出现在不同地方所以不同区域可以共用参数。</p><h3 id="Pooling-Max-Pooling"><a href="#Pooling-Max-Pooling" class="headerlink" title="Pooling-Max Pooling"></a>Pooling-Max Pooling</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222142228736.png" alt="image-20230222142228736"></p><p>Max Pooling作用：把图片变小</p><p>Pooling主要的作用是减少运算量</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222143015795.png" alt="image-20230222143015795"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222143054258.png" alt="image-20230222143054258"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222143303706.png" alt="image-20230222143303706"> </p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222143421544.png" alt="image-20230222143421544"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222143633013.png" alt="image-20230222143633013"></p><h2 id="Spatial-Transformer-Layer"><a href="#Spatial-Transformer-Layer" class="headerlink" title="Spatial Transformer Layer"></a>Spatial Transformer Layer</h2><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222162327297.png" alt="image-20230222162327297"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222163100727.png" alt="image-20230222163100727"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222163346290.png" alt="image-20230222163346290"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222163816076.png" alt="image-20230222163816076"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222164539375.png" alt="image-20230222164539375"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222164711179.png" alt="image-20230222164711179"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222164815484.png" alt="image-20230222164815484"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222165047469.png" alt="image-20230222165047469"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222170141809.png" alt="image-20230222170141809"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230222170814869.png" alt="image-20230222170814869"></p><h2 id="Self-attention"><a href="#Self-attention" class="headerlink" title="Self-attention"></a>Self-attention</h2><p>解决问题：network input is a set of vectors not a vector</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223161320964.png" alt="image-20230223161320964"></p><p>例子：文字处理，假设处理的是句子每个句子的长度都不一样，将句子每一个词汇都描绘成向量，则句子是一个Vector Set</p><p>如何将词汇表示成向量？—One-hot Encoding，问题假设每个词汇之间没有关系</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223162805885.png" alt="image-20230223162805885"></p><p>例子2：声音讯号</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223163103560.png" alt="image-20230223163103560"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223163644962.png" alt="image-20230223163644962"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223164116773.png" alt="image-20230223164116773"></p><p>![image-20230223164131670](D:\人工智能\photo\pytorch md\image-20230223164131670.png)</p><h3 id="Sequence-Labeling"><a href="#Sequence-Labeling" class="headerlink" title="Sequence Labeling"></a>Sequence Labeling</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223164432190.png" alt="image-20230223164432190"></p><h3 id="Self-attention-1"><a href="#Self-attention-1" class="headerlink" title="Self-attention"></a>Self-attention</h3><p><strong>How working?</strong></p><p>self-attention会接收一整个sequence资料，input 多少vector就输出多少vector，输出vector考虑一整个sequence得到。</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223164858274.png" alt="image-20230223164858274"></p><p>self-attention可以很多次，fully connection network和self-attention可以交替使用，fully connection network处理某一位置资料，self-attention处理整个sequence</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223165123881.png" alt="image-20230223165123881"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223165253237.png" alt="image-20230223165253237"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223165405133.png" alt="image-20230223165405133"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223170452941.png" alt="image-20230223170452941"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223170706124.png" alt="image-20230223170706124"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223170837944.png" alt="image-20230223170837944"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223173855690.png" alt="image-20230223173855690"></p><p>从矩阵乘法解释Self-attention：</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223180959958.png" alt="image-20230223180959958"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230223181544814.png" alt="image-20230223181544814"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230224163731902.png" alt="image-20230224163731902"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230224164123140.png" alt="image-20230224164123140"></p><h4 id="Multi-head-Self-attention"><a href="#Multi-head-Self-attention" class="headerlink" title="Multi-head Self-attention"></a>Multi-head Self-attention</h4><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230224164758954.png" alt="image-20230224164758954"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230224164821859.png" alt="image-20230224164821859"></p><p>Self attention没有位置信息</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230224165938999.png" alt="image-20230224165938999"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230224170054154.png" alt="image-20230224170054154"></p><p>语言辨识：输入向量会很大，只看很小范围。</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230224170251429.png" alt="image-20230224170251429"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230224171004645.png" alt="image-20230224171004645"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230224171217528.png" alt="image-20230224171217528"></p><p>CNN是self-attention的特例</p><p>Self-attention与CNN比较，模型复杂，容易过拟合</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230224171522251.png" alt="image-20230224171522251"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230224174602637.png" alt="image-20230224174602637"></p><h3 id="各式各样的Attention"><a href="#各式各样的Attention" class="headerlink" title="各式各样的Attention"></a>各式各样的Attention</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227155038921.png" alt="image-20230227155038921"></p><p>N×N的计算量特别大</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227155812871.png" alt="image-20230227155812871"></p><p>当Input的N非常大时，以下的处理才会很有效果。</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227161036092.png" alt="image-20230227161036092"></p><p>####Skip Some Calculations</p><p>N×N矩阵中有些位置不需要计算</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227161214393.png" alt="image-20230227161214393"></p><h5 id="Local-Attention-Truncated-Attention"><a href="#Local-Attention-Truncated-Attention" class="headerlink" title="Local Attention&#x2F;Truncated Attention"></a>Local Attention&#x2F;Truncated Attention</h5><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227161430915.png" alt="image-20230227161430915"></p><p>每次attention只能看见小范围，与CNN相似</p><h5 id="Stride-Attention"><a href="#Stride-Attention" class="headerlink" title="Stride Attention"></a>Stride Attention</h5><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227161633916.png" alt="image-20230227161633916"></p><h5 id="Global-Attention"><a href="#Global-Attention" class="headerlink" title="Global Attention"></a>Global Attention</h5><p><a href="https://www.bilibili.com/video/BV1VN4y1P7Zj?t=871.0&p=51">讲解 第14分钟</a></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227162251395.png" alt="image-20230227162251395"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227162444796.png" alt="image-20230227162444796"></p><p><strong>用Multi-head attention</strong></p><p>![image-20230227162554550]image-20230227162554550.png)</p><h3 id="Focous-on-Critical-Pats"><a href="#Focous-on-Critical-Pats" class="headerlink" title="Focous on Critical Pats"></a>Focous on Critical Pats</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227162752928.png" alt="image-20230227162752928"></p><h4 id="Clustering"><a href="#Clustering" class="headerlink" title="Clustering"></a>Clustering</h4><p>相近的vector属于相同的cluster，不相近的属于不同的cluster。</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227163049571.png" alt="image-20230227163049571"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227163128433.png" alt="image-20230227163128433"></p><h3 id="Learnable-Patterns"><a href="#Learnable-Patterns" class="headerlink" title="Learnable Patterns"></a>Learnable Patterns</h3><p>通过Learned计算哪些地方需要计算</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227163638822.png" alt="image-20230227163638822"></p><p>Sinkhorn Sorting Network如何实现加速的？<a href="https://www.bilibili.com/video/BV1VN4y1P7Zj?t=1802.4&p=51">解释 第28分钟</a></p><h3 id="Do-we-need-full-attention-matrix"><a href="#Do-we-need-full-attention-matrix" class="headerlink" title="Do we need full attention matrix?"></a>Do we need full attention matrix?</h3><p><a href="https://www.bilibili.com/video/BV1VN4y1P7Zj?t=1802.4&p=51">定位 第31分钟</a></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227164502837.png" alt="image-20230227164502837"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227164543048.png" alt="image-20230227164543048"></p><p> <img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227164613934.png" alt="image-20230227164613934"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227164942378.png" alt="image-20230227164942378"></p><p>处理query根据问题考虑，若是作业2那种会减少label数量</p><h4 id="Reduce-Nember-of-Keys"><a href="#Reduce-Nember-of-Keys" class="headerlink" title="Reduce Nember of Keys"></a>Reduce Nember of Keys</h4><p>![image-20230227171901971]image-20230227171901971.png)</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227172155132.png" alt="image-20230227172155132"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227172136198.png" alt="image-20230227172136198"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227172326858.png" alt="image-20230227172326858"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227172435027.png" alt="image-20230227172435027"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227172633979.png" alt="image-20230227172633979"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227173058847.png" alt="image-20230227173058847"></p><p>![image-20230227173153780](D:\人工智能\photo\pytorch md\image-20230227173153780.png)</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227173605771.png" alt="image-20230227173605771"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227174638919.png" alt="image-20230227174638919"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227175224594.png" alt="image-20230227175224594"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227175551056.png" alt="image-20230227175551056"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227175834055.png" alt="image-20230227175834055"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227175849100.png" alt="image-20230227175849100"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227180202579.png" alt="image-20230227180202579"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227180222407.png" alt="image-20230227180222407"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227180355433.png" alt="image-20230227180355433"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227180413220.png" alt="image-20230227180413220"></p><h4 id="Synthesizer"><a href="#Synthesizer" class="headerlink" title="Synthesizer"></a>Synthesizer</h4><h2 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h2><p><a href="https://www.youtube.com/watch?v=xCGidAeyS4M">RNN PART1</a></p><p><a href="https://www.youtube.com/watch?v=rTqmWlnwz_0">RNN PART2</a></p><h3 id="Example-Application"><a href="#Example-Application" class="headerlink" title="Example Application"></a>Example Application</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824094358392.png" alt="image-20230824094358392"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824094857191.png" alt="image-20230824094857191"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824094637898.png" alt="image-20230824094637898"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824094806665.png" alt="image-20230824094806665"></p><p>希望神经网络是有记忆的：如输入台北只能输出是目的地而不能分辨此时的台北是出发地还是到达地</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824095157640.png" alt="image-20230824095157640"></p><p>###ElmanNetwork</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824095752464.png" alt="image-20230824095752464"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824100037972.png" alt="image-20230824100037972"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824100110111.png" alt="image-20230824100110111"></p><p> <img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824100146747.png" alt="image-20230824100146747"></p><h3 id="Jordan-Network"><a href="#Jordan-Network" class="headerlink" title="Jordan Network"></a>Jordan Network</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824100319375.png" alt="image-20230824100319375"></p><p>Jordan Network学习效果可能比较好</p><h3 id="Bidirectional-RNN"><a href="#Bidirectional-RNN" class="headerlink" title="Bidirectional RNN"></a>Bidirectional RNN</h3><p>产生输出时看的学习到的范围比较广</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824100517783.png" alt="image-20230824100517783"></p><h3 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h3><p>Long Short-term MEMORY</p><p>Input Gate：只有打开时才能将值写入Memory Cell，打开关闭可以有NN自己学习</p><p>Output Gate：决定外界可不可以将值读出来</p><p>Forget Gate：决定何时将Memory Cell忘掉，打开时代表记住，关闭代表遗忘</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824101358392.png" alt="image-20230824101358392"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824101956681.png" alt="image-20230824101956681"></p><p>激活函数通常旋转sigmoid是因为此值在0-1.可以代表打开程度</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824102122860.png" alt="image-20230824102122860"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824102428705.png" alt="image-20230824102428705"></p><h3 id="Difference-between-RNN-and-LSTM"><a href="#Difference-between-RNN-and-LSTM" class="headerlink" title="Difference between RNN and LSTM"></a>Difference between RNN and LSTM</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824102900519.png" alt="image-20230824102900519"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824102825524.png" alt="image-20230824102825524"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824103223033.png" alt="image-20230824103223033"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824103345925.png" alt="image-20230824103345925"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824103442370.png" alt="image-20230824103442370"></p><h3 id="Multiple-layer-LSTM"><a href="#Multiple-layer-LSTM" class="headerlink" title="Multiple-layer LSTM"></a>Multiple-layer LSTM</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824103522067.png" alt="image-20230824103522067"></p><h3 id="Learning-Target"><a href="#Learning-Target" class="headerlink" title="Learning Target"></a>Learning Target</h3><p>结果的cost:每个RNN的output和reference vector的cross entropy和 去minimize</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824105847788.png" alt="image-20230824105847788"></p><h3 id="BPTT"><a href="#BPTT" class="headerlink" title="BPTT"></a>BPTT</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824110021184.png" alt="image-20230824110021184"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824110158861.png" alt="image-20230824110158861"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824110322220.png" alt="image-20230824110322220"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824110554974.png" alt="image-20230824110554974"></p><p>Clipping： 当gradient大于某个threshold时，就不要超过threshold</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824111209049.png" alt="image-20230824111209049"></p><p>为什么RNN误差会很崎岖：RNN训练问题，源自在时间和时间转换transition时反复使用，从memory接到neuron的一组weight反复被使用，所以ｗ有变化，则会产生如上图gradient会有时很大有时很小</p><p>使用LSTM时候可以避免gradient平坦，因此可以将ｌｅａｒｎｉｎｇ　ｒａｔｅ设的小，如下图</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824112210517.png" alt="image-20230824112210517"></p><p>参数多可能会带来Over fitting的情况</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230824112329435.png" alt="image-20230824112329435"></p><h2 id="GNN"><a href="#GNN" class="headerlink" title="GNN"></a>GNN</h2><p>暂时略过</p><h2 id="Quick-Introduction-of-Batch-Normalization"><a href="#Quick-Introduction-of-Batch-Normalization" class="headerlink" title="Quick Introduction of Batch Normalization"></a>Quick Introduction of Batch Normalization</h2><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226104124832.png" alt="image-20230226104124832"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226104007327.png" alt="image-20230226104007327"></p><p>难训练</p><p>给feature中不同的dimension，有同样的数值范围。</p><h3 id="Feature-Normalization"><a href="#Feature-Normalization" class="headerlink" title="Feature Normalization"></a>Feature Normalization</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226104721560.png" alt="image-20230226104721560"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226104935859.png" alt="image-20230226104935859"></p><p>x正规化后，W作用也可能会使训练困难，feature Normalization可以选择在激活函数之前或之后；选择sigmoid做激活函数推荐对z做feature Normalization。</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226105226151.png" alt="image-20230226105226151"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226105254442.png" alt="image-20230226105254442"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226105619749.png" alt="image-20230226105619749"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226105830567.png" alt="image-20230226105830567"></p><p>β、γ使Z均值不为0，β初始值1，γ初始值0.</p><h3 id="Batch-Normalization-—Testing"><a href="#Batch-Normalization-—Testing" class="headerlink" title="Batch Normalization —Testing"></a>Batch Normalization —Testing</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226110917675.png" alt="image-20230226110917675"></p><h3 id="How-does-Batch-Normalization-Help-Optimization？—–Internal-Covariate-Shift？"><a href="#How-does-Batch-Normalization-Help-Optimization？—–Internal-Covariate-Shift？" class="headerlink" title="How does Batch Normalization Help Optimization？—–Internal Covariate Shift？"></a>How does Batch Normalization Help Optimization？—–Internal Covariate Shift？</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226111349311.png" alt="image-20230226111349311"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226111523076.png" alt="image-20230226111523076"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226111542936.png" alt="image-20230226111542936"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226120807141.png" alt="image-20230226120807141"></p><h1 id="PyTorch数据集归一化-torchvision-transforms-Normalize"><a href="#PyTorch数据集归一化-torchvision-transforms-Normalize" class="headerlink" title="PyTorch数据集归一化- torchvision.transforms.Normalize()"></a><a href="https://so.csdn.net/so/search?q=PyTorch&spm=1001.2101.3001.7020">PyTorch</a>数据集归一化- torchvision.transforms.Normalize()</h1><p>Pytorch数据归一化</p><h3 id="图像处理为什么要归一化？"><a href="#图像处理为什么要归一化？" class="headerlink" title="图像处理为什么要归一化？"></a>图像处理为什么要归一化？</h3><p>对于网络模型训练等，是为了加速神经网络训练收敛，以及保证程序运行时收敛加快。</p><p>数据归一化的概念是一个通用概念，指的是将数据集的原始值转换为新值的行为。新值通常是相对于数据集本身进行编码的，并以某种方式进行缩放。</p><p><strong>特征缩放</strong></p><p>出于这个原因，有时数据归一化的另一个名称是特征缩放。这个术语指的是，在对数据进行归一化时，我们经常会将给定数据集的不同特征转化为相近的范围。</p><p>在这种情况下，我们不仅仅是考虑一个值的数据集，还要<strong>考虑一个具有多个特征的元素的数据集，及每个特征的值</strong>。</p><p>举例来说，假设我们要处理的是一个人的数据集，我们的数据集中有两个相关的特征，年龄和体重。在这种情况下，我们可以观察到，这两个特征集的大小或尺度是不同的，即体重平均大于年龄。</p><p>在使用机器学习算法进行比较或计算时，这种幅度上的差异可能是个问题。因此，这可能是我们希望通过特征缩放将这些特征的值缩放到一些相近尺度的原因之一。<br><strong>规范化示例</strong><br>当我们对数据集进行归一化时，我们通常会对相对于数据集的每个特定值进行某种形式的信息编码，然后重新缩放数据。考虑下面这个例子：</p><p>假设我们有一个正数集合 S 。现在，假设我们从集合s 随机选择一个 x 值并思考：这个 x 值是集合s中最大的数嘛 ？<br>在这种情况下，答案是我们不知道。我们只是没有足够的信息来回答问题。<br>但是，现在假设我们被告知 集合 S 通过将每个值除以集合内的最大值进行归一化。通过此标准化过程，已对值最大的信息进行了编码，并对数据进行了重新缩放。<br>集合中最大的成员是 1，并且数据已按比例缩放到间隔 [0,1]。</p><h2 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h2><p>Seq2Seq</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226114520352.png" alt="image-20230226114520352"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226114631545.png" alt="image-20230226114631545"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226114703556.png" alt="image-20230226114703556"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226115110295.png" alt="image-20230226115110295"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226115738607.png" alt="image-20230226115738607"></p><p>###Seq2seq</p><p>  <img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226115959555.png" alt="image-20230226115959555"></p><h3 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226120051473.png" alt="image-20230226120051473"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226120145462.png" alt="image-20230226120145462"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226121013255.png" alt="image-20230226121013255"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230226121054634.png" alt="image-20230226121054634"></p><h3 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h3><p>Decoder:把Encoder产生的输出都读进去，</p><p>BEGIN（special token）：Decoder开始符号，</p><h4 id="Autoregressive-AT"><a href="#Autoregressive-AT" class="headerlink" title="Autoregressive(AT)"></a>Autoregressive(AT)</h4><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227142225440.png" alt="image-20230227142225440"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227142303877.png" alt="image-20230227142303877"></p><p>Decoder看见的输入其实是前一个时间点自己的输出</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227142315802.png" alt="image-20230227142315802"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227142519206.png" alt="image-20230227142519206"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227142537156.png" alt="image-20230227142537156"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227142630739.png" alt="image-20230227142630739"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227142737083.png" alt="image-20230227142737083"></p><p><strong>Masked</strong>：产生b<del>i</del>时候，不能看比i大的信息</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227142843045.png" alt="image-20230227142843045"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227142906032.png" alt="image-20230227142906032"></p><p><strong>Why masked?</strong> Consider how does decoder work.</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227143253075.png" alt="image-20230227143253075"></p><p><strong>Adding “Stop Token”</strong></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227143441165.png" alt="image-20230227143441165"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227143456890.png" alt="image-20230227143456890"></p><h4 id="NAT-Non-autoregressive"><a href="#NAT-Non-autoregressive" class="headerlink" title="NAT Non-autoregressive"></a>NAT Non-autoregressive</h4><p>一次把整个句子产生出来</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227143706330.png" alt="image-20230227143706330"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227144034589.png" alt="image-20230227144034589"></p><h3 id="Encoder-2-Decoder"><a href="#Encoder-2-Decoder" class="headerlink" title="Encoder 2 Decoder"></a>Encoder 2 Decoder</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227144248632.png" alt="image-20230227144248632"></p><h4 id="Cross-attention"><a href="#Cross-attention" class="headerlink" title="Cross attention"></a>Cross attention</h4><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227144501296.png" alt="image-20230227144501296"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227144542973.png" alt="image-20230227144542973"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227144840761.png" alt="image-20230227144840761"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227145007530.png" alt="image-20230227145007530"></p><h3 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h3><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227145101111.png" alt="image-20230227145101111"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227145328425.png" alt="image-20230227145328425"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227145525543.png" alt="image-20230227145525543"></p><p>Decoder输入的时候，给Decoder输入正确的答案——<strong>Teacher Forcing</strong>：using the ground truth as input.</p><h4 id="Tips"><a href="#Tips" class="headerlink" title="Tips"></a>Tips</h4><p>#####Copy Mechanism</p><p>一些情况下不需要decoder创造输出出来，可能需要从输入中复制一些出来；例如聊天机器人、摘要提取</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227145849416.png" alt="image-20230227145849416"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227145913631.png" alt="image-20230227145913631"></p><p>######<strong>Pointer Network</strong></p><h5 id="Guided-Attention"><a href="#Guided-Attention" class="headerlink" title="Guided Attention"></a>Guided Attention</h5><p>强迫将输入的每个东西都学习</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227150907748.png" alt="image-20230227150907748"></p><h5 id="Beam-Search"><a href="#Beam-Search" class="headerlink" title="Beam Search"></a>Beam Search</h5><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227151307970.png" alt="image-20230227151307970"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227151710565.png" alt="image-20230227151710565"></p><p>Beam search并不是都是结果好的，要根据任务决定，如果任务目的非常明确（语音辨识）Beam search会很有帮助，若需要一些创造（可能会有不止一个答案）随机性可能会更好。</p><p>TTS：语音合成</p><h4 id="Blue-score"><a href="#Blue-score" class="headerlink" title="Blue score"></a>Blue score</h4><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227152337680.png" alt="image-20230227152337680"></p><h4 id="Exposure-bias"><a href="#Exposure-bias" class="headerlink" title="Exposure bias"></a>Exposure bias</h4><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227152453643.png" alt="image-20230227152453643"></p><p>training是Decoder输入是正确的，但是测试时Decoder输入会有错误，为避免在Ground Truth加入一些错误。</p><h5 id="Scheduled-Sampling"><a href="#Scheduled-Sampling" class="headerlink" title="Scheduled Sampling"></a>Scheduled Sampling</h5><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230227152656466.png" alt="image-20230227152656466"></p><h2 id="Generation"><a href="#Generation" class="headerlink" title="Generation"></a>Generation</h2><h2 id="Reinforcement-Learning"><a href="#Reinforcement-Learning" class="headerlink" title="Reinforcement Learning"></a>Reinforcement Learning</h2><h1 id="李沐动手深度学习"><a href="#李沐动手深度学习" class="headerlink" title="李沐动手深度学习"></a>李沐动手深度学习</h1><h2 id="Resnet-残差网络"><a href="#Resnet-残差网络" class="headerlink" title="Resnet 残差网络"></a>Resnet 残差网络</h2><p>为了提到模型预测的精度，想要提高模型的复杂度如下图左所示，但是学习产生模型偏差。Resnet设计每次更复杂的模型使包含上次模型。</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230825155356180.png" alt="image-20230825155356180"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230825155510200.png" alt="image-20230825155510200"></p><p>复杂模型包含小模型。</p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230825155754620.png" alt="image-20230825155754620"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230825155841487.png" alt="image-20230825155841487"></p><p><img src="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/image-20230825160140398.png" alt="image-20230825160140398"></p>]]></content>
    
    
    
    <tags>
      
      <tag>Deep Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>相关学习链接</title>
    <link href="/2023/12/22/%E7%9B%B8%E5%85%B3%E5%AD%A6%E4%B9%A0%E8%BF%9E%E6%8E%A5/"/>
    <url>/2023/12/22/%E7%9B%B8%E5%85%B3%E5%AD%A6%E4%B9%A0%E8%BF%9E%E6%8E%A5/</url>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><h1 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h1><p><a href="https://numpy.org.cn/">Numpy</a></p><h1 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h1><p><a href="https://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling">scikit_learn</a></p><h2 id="Pytorch"><a href="#Pytorch" class="headerlink" title="Pytorch"></a>Pytorch</h2><p><a href="https://pytorch.org/docs/stable/index.html">Pytorch官网手册</a><br><a href="https://speech.ee.ntu.edu.tw/~hylee/ml/2021-spring.php">李宏毅2021 Spring</a><br><a href="https://enzo-miman.github.io/#/README">Enzo 课件</a><br><a href="https://www.cnblogs.com/nickchen121/p/15105048.html">水论文程序猿</a><br><a href="https://blog.csdn.net/qq_33746593/article/details/107202590">位置编码与注意力机制</a></p><p><a href="https://zh-v2.d2l.ai/">《动手学深度学习》 — 动手学深度学习 2.0.0 documentation (d2l.ai)</a></p><p><a href="https://space.bilibili.com/1567748478">跟李沐学AI的个人空间-跟李沐学AI个人主页-哔哩哔哩视频 (bilibili.com)</a></p><p><a href="https://zhuanlan.zhihu.com/p/95368411">pytorch必须掌握的4种边界Padding方法 - 知乎 (zhihu.com)</a></p><p><a href="https://allenwind.github.io/blog/8912/">Embedding层讲解</a></p><h3 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h3><p><a href="https://kazemnejad.com/blog/transformer_architecture_positional_encoding/#proposed-method">T one</a><br><a href="https://nlp.seas.harvard.edu/2018/04/03/attention.html#model-architecture">T 2</a><br><a href="https://zhuanlan.zhihu.com/p/403433120">T 3</a></p><p>[一文教你彻底理解Transformer中Positional Encoding - 知乎 (zhihu.com)](<a href="https://zhuanlan.zhihu.com/p/338592312#%E6%80%8E%E4%B9%88%E6%A0%B7%E5%8E%BB%E5%81%9Apositional">https://zhuanlan.zhihu.com/p/338592312#怎么样去做positional</a> Encoding？)</p><h3 id="强化学习"><a href="#强化学习" class="headerlink" title="强化学习"></a>强化学习</h3><p><a href="https://github.com/xccds/Ten_Minute_RL">xccds&#x2F;Ten_Minute_RL (github.com)</a></p><h2 id="Logging"><a href="#Logging" class="headerlink" title="Logging"></a>Logging</h2><p><a href="https://mp.weixin.qq.com/s/9_gb7Fv8FKvYtjBSOev9Ag">30分钟吃掉wandb模型训练可视化 (qq.com)</a></p><p><a href="https://docs.wandb.ai/guides/sweeps/sweep-config-keys#early_terminate">Sweep configuration options | Weights &amp; Biases Documentation (wandb.ai)</a></p><h1 id="网站博客搭建"><a href="#网站博客搭建" class="headerlink" title="网站博客搭建"></a>网站博客搭建</h1><p><a href="https://zhuanlan.zhihu.com/p/547520780?utm_id=0">Hexo搭建</a></p><p><a href="https://blog.csdn.net/K1052176873/article/details/122879462">Hexo 多机</a></p><p><a href="https://zhuanlan.zhihu.com/p/265077468">hexo博客如何插入图片</a></p><p>Windows命令行进入对应文件路径：</p><p><strong>C:\WINDOWS\system32&gt;D:</strong></p><p><em><strong>D:&gt;cd BBlog</strong></em></p><p><code>hexo clean</code> 删除 public 文件夹，即删除旧的博客文章</p><p><code>hexo g</code> 生成 public 文件夹，即生成新的博客文章相关 html 文件</p><p><code>hexo d</code> 将博客推送到 github</p><p>补充：后续写文章、修改配置后的保存推送操作</p><p>至此，网站部署至master分支，整个网站备份至hexo分支。当网站的配置或文章修改后都要将远程仓库更新。首先，依次执行<br>‘’’git add .<code>git commit -m ChangeFiles（更新信息内容可改)</code>git push （或者git push origin hexo)’’’<br>保证hexo分支版本最新。然后执行<br>‘’’hexo d -g’’’</p><h1 id="控制"><a href="#控制" class="headerlink" title="控制"></a>控制</h1><p><a href="https://www.zhihu.com/question/25347270">(45 封私信 &#x2F; 80 条消息) 想学习自适应控制、滑模控制、模糊控制、鲁棒控制，如何打下基石，该看些什么书？ - 知乎 (zhihu.com)</a></p><h1 id="机器人"><a href="#机器人" class="headerlink" title="机器人"></a>机器人</h1><p><a href="https://www.zhihu.com/question/61879863/answer/3336818984">(33 封私信 &#x2F; 32 条消息) 学习机器人运动学，动力学需要哪些数学基础课程？ - 知乎 (zhihu.com)</a></p><p><a href="https://ww2.mathworks.cn/campaigns/offers/next/getting-started-with-motion-planning-in-matlab-ebook.html?s_v1=55087&elqem=4398968_EM_CN_DIR_24-06_MOE-CG&elqTrackId=6bd354b4164d420abc2a42769ff7130b&elq=bbea92b2272a4984b74afc7fdcb53a20&elqaid=55087&elqat=1&elqCampaignId=20978">使用 MATLAB 进行运动规划 - MATLAB &amp; Simulink (mathworks.cn)</a></p><h2 id="海洋机器人"><a href="#海洋机器人" class="headerlink" title="海洋机器人"></a>海洋机器人</h2><h2 id="资料网站"><a href="#资料网站" class="headerlink" title="资料网站"></a>资料网站</h2><p>(<a href="https://zh.z-library.se/">Z-Library – 世界上最大的电子图书馆。自由访问知识和文化。</a>)</p><p>(<a href="https://www.tboxn.com/#term-80">Tbox导航 | 只收录优质在线工具的导航网站 (tboxn.com)</a>)</p><p><a href="https://zotero-chinese.github.io/zotero-plugins/#/">Zotero 插件商店 - Zotero 中文社区 (zotero-chinese.github.io)</a></p><p><a href="https://www.emojiall.com/zh-hans">Emoji大全 | Emoji表情符号词典 📓 | EmojiAll中文官方网站</a></p><h1 id="期刊会议"><a href="#期刊会议" class="headerlink" title="期刊会议"></a>期刊会议</h1><p><a href="https://zhuanlan.zhihu.com/p/585191008">盘点一下，人工智能顶刊顶会有哪些？ - 知乎 (zhihu.com)</a></p><h2 id="人工智能会议"><a href="#人工智能会议" class="headerlink" title="人工智能会议"></a>人工智能会议</h2><p><a href="https://blog.csdn.net/zffustb/article/details/114916952">部分计算机会议和期刊论文的下载方法_acm论文下载-CSDN博客</a></p><p><a href="https://aaai.org/aaai-publications/aaai-conference-proceedings/">AAAI Conference Proceedings - AAAI</a></p><h2 id="机器人会议"><a href="#机器人会议" class="headerlink" title="机器人会议"></a>机器人会议</h2><p><a href="https://ieeexplore.ieee.org/xpl/conhome/1000393/all-proceedings">IROS</a></p><h2 id="科研网页"><a href="#科研网页" class="headerlink" title="科研网页"></a>科研网页</h2><p><a href="https://www.fossen.biz/publications/">Publication Database (fossen.biz)</a></p><p><a href="https://www.webofscience.com/wos/author/record/652943">彭周华 Web of Science</a></p><p><a href="https://www.webofscience.com/wos/author/record/1877572">古楠 - Web of Science </a></p><p><a href="https://www.webofscience.com/wos/author/record/1821774">王宁 - Web of Science</a></p><p><a href="https://www.webofscience.com/wos/author/record/1017232">向先波 - Web of Science</a></p><p><a href="https://www.webofscience.com/wos/author/record/396948">严新平 - Web of Science</a></p><p><a href="https://www.webofscience.com/wos/author/record/217990">张海涛 - Web of Science</a></p><p><a href="https://www.webofscience.com/wos/author/record/2191269">马勇 - Web of Science</a></p><p><a href="https://www.webofscience.com/wos/author/record/420875">柳晨光 - Web of Science</a></p><p><a href="https://webofscience.clarivate.cn/wos/author/record/54691349">王宏东 - Web of Science)</a></p><h1 id="科研工具"><a href="#科研工具" class="headerlink" title="科研工具"></a>科研工具</h1><h2 id="Origin"><a href="#Origin" class="headerlink" title="Origin"></a>Origin</h2><p>【Origin科研绘图超快速上手指南】<a href="https://www.bilibili.com/video/BV1BA411i7PT?vd_source=2ec9cc7a2d133f3a19434aaf945dabd6">https://www.bilibili.com/video/BV1BA411i7PT?vd_source=2ec9cc7a2d133f3a19434aaf945dabd6</a></p><p><img src="/%E7%9B%B8%E5%85%B3%E5%AD%A6%E4%B9%A0%E8%BF%9E%E6%8E%A5/image-20240229194903383.png" alt="image-20240229194903383"></p><p><a href="https://www.zhihu.com/question/525797309">(46 封私信 &#x2F; 80 条消息) 为什么我的origin图标绘制不显示book数据 ？ - 知乎 (zhihu.com)</a></p><p>[Origin学会粘贴格式，告别重复排版！-王飞的博客嘿嘿 (upcwangfei.com)](<a href="https://www.upcwangfei.com/original-article/2021/04/20/1162/#:~:text=Origin%E5%AD%A6%E4%BC%9A%E7%B2%98%E8%B4%B4%E6%A0%BC%E5%BC%8F%EF%BC%8C%E5%91%8A%E5%88%AB%E9%87%8D%E5%A4%8D%E6%8E%92%E7%89%88%EF%BC%81">https://www.upcwangfei.com/original-article/2021/04/20/1162/#:~:text=Origin学会粘贴格式，告别重复排版！</a> 1 01、在调整好格式的图上方鼠标右键选择[复制格式]-[所有格样式式]。 2 02、在需要调整格式的图上方鼠标右键点击（注意，鼠标左键不要点击）选择[粘贴格式]。 3 03、这样，瞬间就设置好了图的格式，非常快速！ 动图演示,求关注！ 小号防丢 关注一波 公众号的自动回复快到上限了 为了能够发布资源 关注下备用号嘿~~ 原文始发于微信公众号（大飞鸽软件助手）： Origin学会粘贴格式，告别重复排版！)</p><h2 id="Latex"><a href="#Latex" class="headerlink" title="Latex"></a>Latex</h2><p><a href="https://zhuanlan.zhihu.com/p/464237097">【LaTeX应用】常用数学公式和符号 - 知乎 (zhihu.com)</a></p><h1 id="计算机基础"><a href="#计算机基础" class="headerlink" title="计算机基础"></a>计算机基础</h1><p>[U盘启动盘还原的方法_u盘设置u盘启动怎么还原-CSDN博客](<a href="https://blog.csdn.net/weixin_45305215/article/details/126067988#:~:text=U%E7%9B%98%E5%90%AF%E5%8A%A8%E7%9B%98%E8%BF%98%E5%8E%9F%E7%9A%84%E6%96%B9%E6%B3%95">https://blog.csdn.net/weixin_45305215/article/details/126067988#:~:text=U盘启动盘还原的方法</a> 1 1、先将u盘插入到电脑，然后在电脑上按下win%2Br快捷键打开运行菜单，输入”cmd”回车确定打开命令提示符页面。 2 2、 然后在命令提示符输入”diskpart”回车确定。 3 3、,后面输几，比如这里是1。 6 6、选择磁盘1，也就是u盘后，在DISKPART&gt;右侧继续输入命令”clean”回车确认，这样就会清除u盘信息。 7 7、然后可以在磁盘管理界面看见u盘变成了一个未分配的磁盘了。 8 8、鼠标右键单击未分配的磁盘空间，选择新建简单卷。 更多项目)</p><p><a href="https://xujinzh.github.io/page/2/#content-inner">https://xujinzh.github.io/page/2/#content-inner</a></p><p><a href="https://www.bilibili.com/read/cv16202697/">https://www.bilibili.com/read/cv16202697/</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>Learning Link</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
