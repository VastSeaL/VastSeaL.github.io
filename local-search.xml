<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title></title>
    <link href="/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/"/>
    <url>/2024/10/06/pytorch%E6%A1%86%E6%9E%B6/</url>
    
    <content type="html"><![CDATA[<h1 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h1><h1 id="Python内置函数"><a href="#Python内置函数" class="headerlink" title="Python内置函数"></a>Python内置函数</h1><h3 id="enumerate-函数"><a href="#enumerate-函数" class="headerlink" title="enumerate()函数"></a>enumerate()函数</h3><p>enumerate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标，一般用在 for 循环当中。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">enumerate</span>(sequence, [start=<span class="hljs-number">0</span>])<br></code></pre></td></tr></table></figure><h3 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h3><ul><li>sequence – 一个序列、迭代器或其他支持迭代对象。</li><li>start – 下标起始位置的值。</li></ul><h3 id="返回值"><a href="#返回值" class="headerlink" title="返回值"></a>返回值</h3><p>返回 enumerate(枚举) 对象。</p><h1 id="Python面向对象"><a href="#Python面向对象" class="headerlink" title="Python面向对象"></a>Python面向对象</h1><h2 id="类-class"><a href="#类-class" class="headerlink" title="类(class):"></a><strong>类(class)</strong>:</h2><p>用来描述具有相同属性和方法的集合。定义了该集合中每个对象所共有的属性和方法。<strong>对象是类的实例。</strong></p><p>###类对象</p><p>类对象支持两种操作：属性引用和实例化。</p><p>属性引用使用和 Python 中所有的属性引用一样的标准语法：<strong>obj.name</strong>。</p><p>类对象创建后，类命名空间中所有的命名都是有效属性名。所以如果类定义是这样:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyClass</span>:<br>    <span class="hljs-string">&quot;&quot;&quot;一个简单的类实例&quot;&quot;&quot;</span><br>    i = <span class="hljs-number">12345</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">f</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;hello world&#x27;</span><br> <br><span class="hljs-comment"># 实例化类</span><br>x = MyClass()<br> <br><span class="hljs-comment"># 访问类的属性和方法</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;MyClass 类的属性 i 为：&quot;</span>, x.i)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;MyClass 类的方法 f 输出为：&quot;</span>, x.f())<br></code></pre></td></tr></table></figure><p>##类属性与方法</p><p><strong>类的私有属性：</strong><strong>__private_attrs</strong>：两个下划线开头，声明该属性为私有，不能在类的外部被使用或直接访问。在类内部的方法中使用时 <strong>self.__private_attrs</strong>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">JustCounter</span>:<br>    __secretCount = <span class="hljs-number">0</span>  <span class="hljs-comment"># 私有变量</span><br>    publicCount = <span class="hljs-number">0</span>    <span class="hljs-comment"># 公开变量</span><br> <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">count</span>(<span class="hljs-params">self</span>):<br>        self.__secretCount += <span class="hljs-number">1</span><br>        self.publicCount += <span class="hljs-number">1</span><br>        <span class="hljs-built_in">print</span> (self.__secretCount)<br> <br>counter = JustCounter()<br>counter.count()<br>counter.count()<br><span class="hljs-built_in">print</span> (counter.publicCount)<br><span class="hljs-built_in">print</span> (counter.__secretCount)  <span class="hljs-comment"># 报错，实例不能访问私有变量</span><br></code></pre></td></tr></table></figure><p>###<strong>类的方法：</strong></p><p>在类的内部，使用 def 关键字来定义一个方法，与一般函数定义不同，类方法必须包含参数 <strong>self</strong>，且为第一个参数，<strong>self</strong> 代表的是类的实例。</p><p><strong>self</strong> 的名字并不是规定死的，也可以使用 <strong>this</strong>，但是最好还是按照约定使用 <strong>self</strong>。</p><h3 id="类的私有方法"><a href="#类的私有方法" class="headerlink" title="类的私有方法"></a>类的私有方法</h3><p><strong>__private_method</strong>：两个下划线开头，声明该方法为私有方法，只能在类的内部调用 ，不能在类的外部调用。<strong>self.__private_methods</strong>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Site</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, name, url</span>):<br>        self.name = name       <span class="hljs-comment"># public</span><br>        self.__url = url   <span class="hljs-comment"># private</span><br> <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">who</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;name  : &#x27;</span>, self.name)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;url : &#x27;</span>, self.__url)<br> <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__foo</span>(<span class="hljs-params">self</span>):          <span class="hljs-comment"># 私有方法</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;这是私有方法&#x27;</span>)<br> <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">foo</span>(<span class="hljs-params">self</span>):            <span class="hljs-comment"># 公共方法</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;这是公共方法&#x27;</span>)<br>        self.__foo()<br> <br>x = Site(<span class="hljs-string">&#x27;菜鸟教程&#x27;</span>, <span class="hljs-string">&#x27;www.runoob.com&#x27;</span>)<br>x.who()        <span class="hljs-comment"># 正常输出</span><br>x.foo()        <span class="hljs-comment"># 正常输出</span><br>x.__foo()      <span class="hljs-comment"># 报错</span><br></code></pre></td></tr></table></figure><p>###类的专有方法</p><p>![image-20221206143413965](D:\人工智能\photo\pytorch md\类的专有方法)</p><h2 id="方法："><a href="#方法：" class="headerlink" title="方法："></a><strong>方法</strong>：</h2><p>类中定义的函数。</p><ul><li><p>类有一个名为  __ init __() 的特殊方法（<strong>构造方法</strong>），该方法在类实例化时会自动调用,</p><ul><li><p>_ _ init_ <em>() 方法可以有参数，参数通过 _ <em>init</em></em> _() 传递到类的实例化操作上</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Complex</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, realpart, imagpart</span>):<br>        self.r = realpart<br>        self.i = imagpart<br>x = Complex(<span class="hljs-number">3.0</span>, -<span class="hljs-number">4.5</span>)<br><span class="hljs-built_in">print</span>(x.r, x.i)   <span class="hljs-comment"># 输出结果：3.0-4.5</span><br></code></pre></td></tr></table></figure></li><li><h3 id="self代表类的实例，而非类"><a href="#self代表类的实例，而非类" class="headerlink" title="self代表类的实例，而非类"></a>self代表类的实例，而非类</h3><ul><li>类的方法与普通的函数只有一个特别的区别——它们必须有一个额外的<strong>第一个参数名称</strong>, 按照惯例它的名称是 self.</li><li>self 代表的是类的实例，代表当前对象的地址，而 self.class 则指向类。</li><li>self 不是 python 关键字，我们把他换成 runoob 也是可以正常执行的</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Test</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">prt</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(self)<br>        <span class="hljs-built_in">print</span>(self.__class__)<br> <br>t = Test()<br>t.prt()<br></code></pre></td></tr></table></figure></li></ul></li><li><p>类的方法：在类的内部，使用 <strong>def</strong> 关键字来定义一个方法，与一般函数定义不同，类方法必须包含参数 self, 且为第一个参数，self 代表的是类的实例。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs 1">#类定义<br>class people:<br>    #定义基本属性<br>    name = &#x27;&#x27;<br>    age = 0<br>    #定义私有属性,私有属性在类外部无法直接进行访问<br>    __weight = 0<br>    #定义构造方法<br>    def __init__(self,n,a,w):<br>        self.name = n<br>        self.age = a<br>        self.__weight = w<br>    def speak(self):<br>        print(&quot;%s 说: 我 %d 岁。&quot; %(self.name,self.age))<br> <br># 实例化类<br>p = people(&#x27;runoob&#x27;,10,30)<br>p.speak()<br></code></pre></td></tr></table></figure></li></ul><p>##<strong>类变量：</strong></p><p>类变量在整个实例化的对象中是公用的。类变量定义在类中且在函数体之外。类变量通常不作为实例变量使用。</p><p>##<strong>数据成员：</strong></p><p>类变量或者实例变量用于处理类及其实例对象的相关的数据。</p><p>##<strong>方法重写：</strong></p><p>如果从父类继承的方法不能满足子类的需求，可以对其进行改写，这个过程叫方法的覆盖（override），也称为方法的重写。</p><ul><li><pre><code class="python">class Parent:        # 定义父类   def myMethod(self):      print (&#39;调用父类方法&#39;) class Child(Parent): # 定义子类   def myMethod(self):      print (&#39;调用子类方法&#39;) c = Child()          # 子类实例c.myMethod()         # 子类调用重写方法super(Child,c).myMethod() #用子类对象调用父类已被覆盖的方法<figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs clean"><br>  [super() 函数](https:<span class="hljs-comment">//www.runoob.com/python/python-func-super.html)是用于调用父类(超类)的一个方法。</span><br><br>##**局部变量：**<br><br>定义在方法中的变量，只作用于当前实例的类。<br><br>##**实例变量：**<br><br>在类的声明中，属性是用变量来表示的，这种变量就称为实例变量，实例变量就是一个用 self 修饰的变量。<br><br>##**继承：**<br><br>即一个派生类（derived <span class="hljs-keyword">class</span>）继承基类（base <span class="hljs-keyword">class</span>）的字段和方法。继承也允许把一个派生类的对象作为一个基类对象对待。例如，有这样一个设计：一个Dog类型的对象派生自Animal类，这是模拟<span class="hljs-string">&quot;是一个（is-a）&quot;</span>关系（例图，Dog是一个Animal）。<br><br>- 派生类<br><br>  ```python<br>  <span class="hljs-keyword">class</span> DerivedClassName(BaseClassName):<br>      &lt;statement<span class="hljs-number">-1</span>&gt;<br>      .<br>      .<br>      .<br>      &lt;statement-N&gt;<br></code></pre></td></tr></table></figure>子类（派生类 DerivedClassName）会继承父类（基类 BaseClassName）的属性和方法。BaseClassName（实例中的基类名）必须与派生类定义在一个作用域内。除了类，还可以用表达式，基类定义在另一个模块中时这一点非常有用:<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">DerivedClassName</span>(modname.BaseClassName):<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#类定义</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">people</span>:<br>    <span class="hljs-comment">#定义基本属性</span><br>    name = <span class="hljs-string">&#x27;&#x27;</span><br>    age = <span class="hljs-number">0</span><br>    <span class="hljs-comment">#定义私有属性,私有属性在类外部无法直接进行访问</span><br>    __weight = <span class="hljs-number">0</span><br>    <span class="hljs-comment">#定义构造方法</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,n,a,w</span>):<br>        self.name = n<br>        self.age = a<br>        self.__weight = w<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">speak</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;%s 说: 我 %d 岁。&quot;</span> %(self.name,self.age))<br> <br><span class="hljs-comment">#单继承示例</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">student</span>(<span class="hljs-title class_ inherited__">people</span>):<br>    grade = <span class="hljs-string">&#x27;&#x27;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,n,a,w,g</span>):<br>        <span class="hljs-comment">#调用父类的构函</span><br>        people.__init__(self,n,a,w)<br>        self.grade = g<br>    <span class="hljs-comment">#覆写父类的方法</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">speak</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;%s 说: 我 %d 岁了，我在读 %d 年级&quot;</span>%(self.name,self.age,self.grade))<br> <br> <br> <br>s = student(<span class="hljs-string">&#x27;ken&#x27;</span>,<span class="hljs-number">10</span>,<span class="hljs-number">60</span>,<span class="hljs-number">3</span>)<br>s.speak()<br></code></pre></td></tr></table></figure></code></pre></li><li><p>多继承</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">DerivedClassName</span>(Base1, Base2, Base3):<br>    &lt;statement-<span class="hljs-number">1</span>&gt;<br>    .<br>    .<br>    .<br>    &lt;statement-N&gt;<br></code></pre></td></tr></table></figure><p>需要注意圆括号中父类的顺序，若是父类中有相同的方法名，而在子类使用时未指定，python从左至右搜索 即方法在子类中未找到时，从左到右查找父类中是否包含方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#类定义</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">people</span>:<br>    <span class="hljs-comment">#定义基本属性</span><br>    name = <span class="hljs-string">&#x27;&#x27;</span><br>    age = <span class="hljs-number">0</span><br>    <span class="hljs-comment">#定义私有属性,私有属性在类外部无法直接进行访问</span><br>    __weight = <span class="hljs-number">0</span><br>    <span class="hljs-comment">#定义构造方法</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,n,a,w</span>):<br>        self.name = n<br>        self.age = a<br>        self.__weight = w<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">speak</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;%s 说: 我 %d 岁。&quot;</span> %(self.name,self.age))<br> <br><span class="hljs-comment">#单继承示例</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">student</span>(<span class="hljs-title class_ inherited__">people</span>):<br>    grade = <span class="hljs-string">&#x27;&#x27;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,n,a,w,g</span>):<br>        <span class="hljs-comment">#调用父类的构函</span><br>        people.__init__(self,n,a,w)<br>        self.grade = g<br>    <span class="hljs-comment">#覆写父类的方法</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">speak</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;%s 说: 我 %d 岁了，我在读 %d 年级&quot;</span>%(self.name,self.age,self.grade))<br> <br><span class="hljs-comment">#另一个类，多重继承之前的准备</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">speaker</span>():<br>    topic = <span class="hljs-string">&#x27;&#x27;</span><br>    name = <span class="hljs-string">&#x27;&#x27;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,n,t</span>):<br>        self.name = n<br>        self.topic = t<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">speak</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;我叫 %s，我是一个演说家，我演讲的主题是 %s&quot;</span>%(self.name,self.topic))<br> <br><span class="hljs-comment">#多重继承</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">sample</span>(speaker,student):<br>    a =<span class="hljs-string">&#x27;&#x27;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,n,a,w,g,t</span>):<br>        student.__init__(self,n,a,w,g)<br>        speaker.__init__(self,n,t)<br> <br>test = sample(<span class="hljs-string">&quot;Tim&quot;</span>,<span class="hljs-number">25</span>,<span class="hljs-number">80</span>,<span class="hljs-number">4</span>,<span class="hljs-string">&quot;Python&quot;</span>)<br>test.speak()   <span class="hljs-comment">#方法名同，默认调用的是在括号中参数位置排前父类的方法</span><br><span class="hljs-built_in">super</span>(student, test).speak()<br></code></pre></td></tr></table></figure></li></ul><p>##<strong>实例化：</strong></p><p>创建一个类的实例，类的具体对象。</p><h2 id="对象："><a href="#对象：" class="headerlink" title="对象："></a><strong>对象：</strong></h2><p>通过类定义的数据结构实例。对象包括两个数据成员（类变量和实例变量）和方法。</p><p>#线性模型</p><p>##MSE（平均平方误差 Mean Square Error）</p><p>![image-20221116141550394](D:\人工智能\photo\pytorch md\d2l-en-pytorch.pdf)</p><p>穷举法</p><p>#梯度下降算法实践</p><p>分治：若是凸函数可用，不是话陷入局部最优</p><p> 梯度(Gradient): </p><p>梯度下降法也会陷入到局部最优，后来在神经网络中发现用梯度下降算法很难陷入局部最优点</p><p>非凸函数： 局部最优</p><img src="D:\人工智能\photo\pytorch md\凸函数" alt="image-20221116142311981" style="zoom:50%;" /><p>鞍点：梯度为0</p><p>![image-20221116142642619](D:\人工智能\photo\pytorch md\鞍点.jpj)</p><p>![image-20221116142925931](D:\人工智能\photo\pytorch md\梯度下降)</p><p>指数加权均值：C<del>i</del>是当前损失，C^&#96;^<del>i</del>是更新后损失</p><p>![image-20221116143805313](D:\人工智能\photo\pytorch md\指数加权均值)</p><p>训练发散：训练集正确训练后都是收敛的，对于训练发散常见原因是学习率取得太大 </p><h2 id="随机梯度下降-SGD"><a href="#随机梯度下降-SGD" class="headerlink" title="随机梯度下降(SGD)"></a>随机梯度下降(SGD)</h2><p>![image-20221116144201757](D:\人工智能\photo\pytorch md\随机梯度下降.pnj)</p><h2 id="Batch"><a href="#Batch" class="headerlink" title="Batch"></a>Batch</h2><p>在梯度下降算法w计算是可以并行的</p><p>![image-20221116145124845](D:\人工智能\photo\pytorch md\Batch)</p><p>#Back Propagation 反向传播</p><p>![image-20221116150521974](D:\人工智能\photo\pytorch md\反向传播.pnj)</p><p>![image-20221116151255009](D:\人工智能\photo\pytorch md\fanxiangchuanbo.pnj)</p><h2 id="Chain-Rule-链式法则"><a href="#Chain-Rule-链式法则" class="headerlink" title="Chain Rule 链式法则"></a>Chain Rule 链式法则</h2><p> 前馈</p><p>Backward</p><p>![image-20221116152120646](D:\人工智能\photo\pytorch md\chain rule.pnj)</p><p>![image-20221116153023895](D:\人工智能\photo\pytorch md\求梯度.pnj)</p><h2 id="Pytorch中前馈和反馈计算"><a href="#Pytorch中前馈和反馈计算" class="headerlink" title="Pytorch中前馈和反馈计算"></a>Pytorch中前馈和反馈计算</h2><p>tensor:Pytorch中存储数据数据</p><p>​datagrad</p><p>![image-20221116153512231](D:\人工智能\photo\pytorch md\tensor.pnj)</p><h1 id="用Pytorch实现线性回归"><a href="#用Pytorch实现线性回归" class="headerlink" title="用Pytorch实现线性回归"></a>用Pytorch实现线性回归</h1><p>![image-20221117134749098](D:\人工智能\photo\pytorch md\pytorch实现)</p><h2 id="广播机制"><a href="#广播机制" class="headerlink" title="广播机制"></a>广播机制</h2><p>![image-20221117135124782](D:\人工智能\photo\pytorch md\广播机制)</p><h2 id="affine-model-仿射模型"><a href="#affine-model-仿射模型" class="headerlink" title="affine model 仿射模型"></a>affine model 仿射模型</h2><p>线性单元</p><p>![image-20221117140010765](D:\人工智能\photo\pytorch md\仿射模型.pnj)</p><p>列数为维度，loss为标量</p><p>定义模型时必须继承自nn.Module类构造函数：__ init __() 初始化构造对象使用的函数 和 forward()函数  前馈过程中必须使用的函数 必须定义   backward无是因为Module对象会自动求导</p><p>![image-20221117140403006](D:\人工智能\photo\pytorch md\definite module..pnj)</p><p>torch.nn.Linear(,)构造对象</p><p>nn: Neural Network</p><p>![image-20221117143117510](D:\人工智能\photo\pytorch md\nn_linear.pnj)</p><h2 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h2><p>![image-20221117144717501](D:\人工智能\photo\pytorch md\训练过程.pnj)</p><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-comment">#1、数据准备</span><br>x_data = torch.Tensor([[<span class="hljs-number">1.0</span>],[<span class="hljs-number">2.0</span>],[<span class="hljs-number">3.0</span>]])<br>y_data = torch.Tensor([[<span class="hljs-number">2.0</span>],[<span class="hljs-number">4.0</span>],[<span class="hljs-number">6.0</span>]])<br><span class="hljs-comment">#2、模型 design model using class</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">LinearModel</span>(torch.nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(LinearModel,self).__init__()<br>        <span class="hljs-comment"># (1,1)是指输入x和输出y的特征维度，这里数据集中的x和y的特征都是1维的</span><br>        <span class="hljs-comment"># 该线性层需要学习的参数是w和b  获取w/b的方式分别是~linear.weight/linear.bias</span><br>        self.linear = torch.nn.Linear(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        y_pred = self.linear(x)<br>        <span class="hljs-keyword">return</span> y_pred<br>    <br>model = LinearModel()<br><span class="hljs-comment">#3、构建损失函数和优化器</span><br>criterion = torch.nn.MSELoss(reduction = <span class="hljs-string">&#x27;sum&#x27;</span>)<br>optimizer = torch.optim.SGD(model.parameters(), lr = <span class="hljs-number">0.01</span>)<br><span class="hljs-comment">#4、训练 training cycle forward, backward, update</span><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100000</span>):<br>    y_pred = model(x_data)<br>    loss = criterion(y_pred,y_data)<br>    <span class="hljs-built_in">print</span>(epoch,loss.item())<br>    <br>    optimizer.zero_grad()<br>    loss.backward()<br>    optimizer.step()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;w = &#x27;</span>, model.linear.weight.item())<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;b = &#x27;</span>, model.linear.bias.item())<br>x_test = torch.tensor([[<span class="hljs-number">4.0</span>]])<br>y_test = model(x_test)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;y_pred = &#x27;</span>, y_test.data)<br></code></pre></td></tr></table></figure><h1 id="逻辑斯蒂回归-分类-classification"><a href="#逻辑斯蒂回归-分类-classification" class="headerlink" title="逻辑斯蒂回归   分类(classification)"></a>逻辑斯蒂回归   分类(classification)</h1><p>分类问题中输出的是概率</p><p>二分类：只有两个类别的分类问题</p><h2 id="torchvision"><a href="#torchvision" class="headerlink" title="torchvision"></a>torchvision</h2><p>torchvision中有很多数据集</p><p>参数train表示想要下载的是训练集还是测试集</p><p>![image-20221121142857457](D:\人工智能\photo\pytorch md\minist)</p><p>##Logistic Function</p><p>![image-20221121144142954](D:\人工智能\photo\pytorch md\logistic)</p><p>sigmoid functions</p><p>![image-20221121144317732](D:\人工智能\photo\pytorch md\sigmoid functions)</p><p>##Logistic Regression Model</p><p>![image-20221121144514372](D:\人工智能\photo\pytorch md\logistic Regression Model)</p><h2 id="Loss-function-for-Binary-Classification"><a href="#Loss-function-for-Binary-Classification" class="headerlink" title="Loss function for Binary Classification"></a>Loss function for Binary Classification</h2><p>此时，我们输出的不在是一个数值而是一个分布</p><p>BCE</p><p>![image-20221121145001408](D:\人工智能\photo\pytorch md\Loss function classcification)</p><p>两个分布间的差异</p><p>交叉熵</p><p>![image-20221121150352368](D:\人工智能\photo\pytorch md\BCE)</p><h1 id="处理多维特征的输入"><a href="#处理多维特征的输入" class="headerlink" title="处理多维特征的输入"></a>处理多维特征的输入</h1><p>行——样本(sample)</p><p>列——特征(Feature)</p><p>并行计算</p><p>![image-20221205173832561](D:\人工智能\photo\pytorch md\mini batch)</p><h2 id="构造多层神经网络"><a href="#构造多层神经网络" class="headerlink" title="构造多层神经网络"></a>构造多层神经网络</h2><p>![image-20221205175024819](D:\人工智能\photo\pytorch md\Linear Layer)</p><h1 id="加载数据集"><a href="#加载数据集" class="headerlink" title="加载数据集"></a>加载数据集</h1><p>Dataset——数据集 索引</p><p>DataLoader——Mini Batch</p><h2 id="Epoch、Batch-Size、Iterations"><a href="#Epoch、Batch-Size、Iterations" class="headerlink" title="Epoch、Batch-Size、Iterations"></a>Epoch、Batch-Size、Iterations</h2><p>Epoch:所有的训练样本进行了一次前向传播和反向传播是1次Epoch</p><p>Batch Size : 每次训练所用的样本数量</p><p>Iteration:迭代了多少次 </p><p>shuffle&#x3D;True 打乱数据集</p><p>![image-20221205204633113](D:\人工智能\photo\pytorch md\shuffle)</p><h1 id="多分类问题"><a href="#多分类问题" class="headerlink" title="多分类问题"></a>多分类问题</h1><p>实现输出分类的要求 大于0 和为1</p><p>![image-20221208151950706](D:\人工智能\photo\pytorch md\sigmoid)</p><p>![image-20221208152435101](D:\人工智能\photo\pytorch md\softmax)</p><p>![image-20221208152553537](D:\人工智能\photo\pytorch md\softmax example)</p><h2 id="NLLLoss"><a href="#NLLLoss" class="headerlink" title="NLLLoss"></a>NLLLoss</h2><p>![image-20221208153731662](D:\人工智能\photo\pytorch md\NLLLoss)</p><p>![image-20221208153816627](D:\人工智能\photo\pytorch md\torch.crossEntropy)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> transforms<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> datasets<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim<br><br><span class="hljs-comment"># prepare dataset</span><br><br>batch_size = <span class="hljs-number">64</span><br>transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((<span class="hljs-number">0.1307</span>,), (<span class="hljs-number">0.3081</span>,))])  <span class="hljs-comment"># 归一化,均值和方差</span><br><br>train_dataset = datasets.MNIST(root=<span class="hljs-string">&#x27;../dataset/mnist/&#x27;</span>, train=<span class="hljs-literal">True</span>, download=<span class="hljs-literal">True</span>, transform=transform)<br>train_loader = DataLoader(train_dataset, shuffle=<span class="hljs-literal">True</span>, batch_size=batch_size)<br>test_dataset = datasets.MNIST(root=<span class="hljs-string">&#x27;../dataset/mnist/&#x27;</span>, train=<span class="hljs-literal">False</span>, download=<span class="hljs-literal">True</span>, transform=transform)<br>test_loader = DataLoader(test_dataset, shuffle=<span class="hljs-literal">False</span>, batch_size=batch_size)<br><br><br><span class="hljs-comment"># design model using class</span><br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Net</span>(torch.nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(Net, self).__init__()<br>        self.l1 = torch.nn.Linear(<span class="hljs-number">784</span>, <span class="hljs-number">512</span>)<br>        self.l2 = torch.nn.Linear(<span class="hljs-number">512</span>, <span class="hljs-number">256</span>)<br>        self.l3 = torch.nn.Linear(<span class="hljs-number">256</span>, <span class="hljs-number">128</span>)<br>        self.l4 = torch.nn.Linear(<span class="hljs-number">128</span>, <span class="hljs-number">64</span>)<br>        self.l5 = torch.nn.Linear(<span class="hljs-number">64</span>, <span class="hljs-number">10</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = x.view(-<span class="hljs-number">1</span>, <span class="hljs-number">784</span>)  <span class="hljs-comment"># -1其实就是自动获取mini_batch</span><br>        x = F.relu(self.l1(x))<br>        x = F.relu(self.l2(x))<br>        x = F.relu(self.l3(x))<br>        x = F.relu(self.l4(x))<br>        <span class="hljs-keyword">return</span> self.l5(x)  <span class="hljs-comment"># 最后一层不做激活，不进行非线性变换</span><br><br><br>model = Net()<br><br><span class="hljs-comment"># construct loss and optimizer</span><br>criterion = torch.nn.CrossEntropyLoss()<br>optimizer = optim.SGD(model.parameters(), lr=<span class="hljs-number">0.01</span>, momentum=<span class="hljs-number">0.5</span>)<br><br><br><span class="hljs-comment"># training cycle forward, backward, update</span><br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">epoch</span>):<br>    running_loss = <span class="hljs-number">0.0</span><br>    <span class="hljs-keyword">for</span> batch_idx, data <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_loader, <span class="hljs-number">0</span>):<br>        <span class="hljs-comment"># 获得一个批次的数据和标签</span><br>        inputs, target = data<br>        optimizer.zero_grad()<br>        <span class="hljs-comment"># 获得模型预测结果(64, 10)</span><br>        outputs = model(inputs)<br>        <span class="hljs-comment"># 交叉熵代价函数outputs(64,10),target（64）</span><br>        loss = criterion(outputs, target)<br>        loss.backward()<br>        optimizer.step()<br><br>        running_loss += loss.item()<br>        <span class="hljs-keyword">if</span> batch_idx % <span class="hljs-number">300</span> == <span class="hljs-number">299</span>:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;[%d, %5d] loss: %.3f&#x27;</span> % (epoch + <span class="hljs-number">1</span>, batch_idx + <span class="hljs-number">1</span>, running_loss / <span class="hljs-number">300</span>))<br>            running_loss = <span class="hljs-number">0.0</span><br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>():<br>    correct = <span class="hljs-number">0</span><br>    total = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> test_loader:<br>            images, labels = data<br>            outputs = model(images)<br>            _, predicted = torch.<span class="hljs-built_in">max</span>(outputs.data, dim=<span class="hljs-number">1</span>)  <span class="hljs-comment"># dim = 1 列是第0个维度，行是第1个维度</span><br>            total += labels.size(<span class="hljs-number">0</span>)<br>            correct += (predicted == labels).<span class="hljs-built_in">sum</span>().item()  <span class="hljs-comment"># 张量之间的比较运算</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;accuracy on test set: %d %% &#x27;</span> % (<span class="hljs-number">100</span> * correct / total))<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>        train(epoch)<br>        test()<br></code></pre></td></tr></table></figure><h1 id="卷积神经网路-CNN"><a href="#卷积神经网路-CNN" class="headerlink" title="卷积神经网路 CNN"></a>卷积神经网路 CNN</h1><p>图片全连接后 可能会丧失一些原有的图片的空间的特征，比如图片中两点列相邻但是全连接后岔开</p><p>卷积神经网络将图像按原始空间结构进行保存</p><p>输入张量的维度 与 输出张量的维度</p><p>![image-20221208191834585](D:\人工智能\photo\pytorch md\CNN)</p><p>Feature Extraction 特征提取器 Classification 分类器</p><h2 id="图像是什么？"><a href="#图像是什么？" class="headerlink" title="图像是什么？"></a>图像是什么？</h2><p>RGB——</p><p>栅格图像矢量图像 </p><p>![image-20221208194310511](D:\人工智能\photo\pytorch md\Convolution)</p><p>![image-20221208195206388](D:\人工智能\photo\pytorch md\convolution 你inputchannels)</p><p>![image-20221208195249426](D:\人工智能\photo\pytorch md\Convolution n input channels and M output Channels)</p><p>![image-20221208202749780](D:\人工智能\photo\pytorch md\Convolution Layer)</p><h2 id="padding"><a href="#padding" class="headerlink" title="padding"></a>padding</h2><p>![image-20221208203047225](D:\人工智能\photo\pytorch md\padding)</p><h2 id="stride-步长"><a href="#stride-步长" class="headerlink" title="stride 步长"></a>stride 步长</h2><p>每次索引的坐标+</p><p>可有效降低图像的宽度和高度</p><h2 id="Max-Pooling-最大池化层"><a href="#Max-Pooling-最大池化层" class="headerlink" title="Max Pooling  最大池化层"></a>Max Pooling  最大池化层</h2><p>![image-20221208204115830](D:\人工智能\photo\pytorch md\MaxPooling)</p><p>分成n*n组，找每组的最大值</p><p>![image-20221208204503171](D:\人工智能\photo\pytorch md\Simple Example)</p><p>减少代码冗余：函数&#x2F;类</p><p>Concatenate：拼接 将张量沿着通道连接</p><p>![image-20221209100738941](D:\人工智能\photo\pytorch md\concatenate)</p><p>What is 1×1 convolution？</p><p>信息融合  改变通道数量</p><p>![image-20221209101316370](D:\人工智能\photo\pytorch md\1×1 convolution) </p><p>![image-20221209102406979](D:\人工智能\photo\pytorch md\why  is 1×1)</p><h1 id="循环神经网络-RNN"><a href="#循环神经网络-RNN" class="headerlink" title="循环神经网络 RNN"></a>循环神经网络 RNN</h1><p>DNN：Dense（Deep） 稠密神经网络</p><p>RNN：处理具有序列连接的输入数据（例如：金融股市、天气、自然语言处理）</p><h2 id="RNN-Cell"><a href="#RNN-Cell" class="headerlink" title="RNN Cell"></a>RNN Cell</h2><p>本质：线形层，把某个维度映射到另一个维度的空间。 Linear</p><p>![image-20221214165453611](D:\人工智能\photo\pytorch md\RNN Cell)</p><p>![image-20221214171337356](D:\人工智能\photo\pytorch md\RNN Cell2)</p><p>![image-20221214171356832](D:\人工智能\photo\pytorch md\RNN Cell3)</p><p>![image-20221214171723190](D:\人工智能\photo\pytorch md\RNN Cell in Pytorch)</p><p>![image-20221214174335513](D:\人工智能\photo\pytorch md\RNN Cell in Pytorch 2)</p><h2 id="How-to-use-RNNCell"><a href="#How-to-use-RNNCell" class="headerlink" title="How to use RNNCell"></a>How to use RNNCell</h2><p>![image-20221214174455158](D:\人工智能\photo\pytorch md\use RNNCell1)</p><p>![image-20221214174611539](D:\人工智能\photo\pytorch md\use RNNCell2)</p><p>![image-20221214174814307](D:\人工智能\photo\pytorch md\use RNNCell3)</p><h2 id="How-to-use-RNN"><a href="#How-to-use-RNN" class="headerlink" title="How to use RNN"></a>How to use RNN</h2><p>![image-20221214174959457](D:\人工智能\photo\pytorch md\use RNN1)</p><p>![image-20221214180055695](D:\人工智能\photo\pytorch md\use RNN2)</p><p>![image-20221214180951812](D:\人工智能\photo\pytorch md\use RNN3)</p><p>![image-20221214181039389](D:\人工智能\photo\pytorch md\use RNN4)</p><p>![image-20221214181656965](D:\人工智能\photo\pytorch md\use RNN5)</p><p>![image-20221214181925459](D:\人工智能\photo\pytorch md\batch_first1)</p><p>![image-20221214182021109](D:\人工智能\photo\pytorch md\batch_first2)</p><h1 id="李宏毅深度学习"><a href="#李宏毅深度学习" class="headerlink" title="李宏毅深度学习"></a>李宏毅深度学习</h1><p>##Pytorch Tutorial</p><p>![image-20230214164320489](D:\人工智能\photo\pytorch md\pytorch turtorial)</p><p>###Step1 Load Data</p><p>torch.utils.data.Dataset &amp; torch.utils.data.DataLoader</p><ul><li><p>Dataset:stores data samples and expected values  将Python定义class将资料一笔笔读进来打包。                 </p></li><li><p>Dataloader: groups data in batches, enables multiprocessing 将Dataset中一个个的资料合并成一个个batch，平行化处理</p></li><li><p>dataset &#x3D; MyDataset(file)</p></li><li><p>dataloader &#x3D; Dataloader(dataset, batch_size, shuffle &#x3D; True)</p></li></ul><p>![image-20230214144609312](D:\人工智能\photo\pytorch md\Dataset)</p><p>![image-20230214144900704](D:\人工智能\photo\pytorch md\Dataset2)</p><h4 id="Tensors"><a href="#Tensors" class="headerlink" title="Tensors"></a>Tensors</h4><ul><li>High-dimensional matrices (arrays)</li></ul><p><strong>Shape of Tensors</strong></p><p>​Check with .shape() </p><p>![image-20230214145346135](D:\人工智能\photo\pytorch md\Tensor)</p><h5 id="Creating-tensors"><a href="#Creating-tensors" class="headerlink" title="Creating tensors"></a>Creating tensors</h5><p>![image-20230214150139489](D:\人工智能\photo\pytorch md\creat tensors)</p><h5 id="Common-operations"><a href="#Common-operations" class="headerlink" title="Common operations"></a>Common operations</h5><ul><li><p>Addition</p><p>​z &#x3D; x + y</p><p>​z&#x3D;torch.add(x,y)</p></li><li><p>Subtraction</p><p>​z &#x3D; x - y</p><p>​z&#x3D; torch.sub(x,y)</p></li><li><p>Power</p><p>​y &#x3D; x.pow(2)</p></li><li><p>Summation</p><p>​y &#x3D; x.sum()</p></li><li><p>Mean</p><p>​y &#x3D; x.mean()</p></li><li><p>Transpose:transpose two specified dimensions</p><p>​![image-20230214155039585](D:\人工智能\photo\pytorch md\transpose)</p></li><li><p>Squeeze</p></li></ul><p>![image-20230214155219945](D:\人工智能\photo\pytorch md\squeezw)</p><ul><li>Unsqueeze</li></ul><p>![image-20230214155829437](D:\人工智能\photo\pytorch md\unsqueeze)</p><ul><li>Cat</li></ul><p>![image-20230214155853582](D:\人工智能\photo\pytorch md\cat)</p><ul><li>Device</li></ul><p>![image-20230214161322544](D:\人工智能\photo\pytorch md\device)</p><h5 id="Gradient-Calculation"><a href="#Gradient-Calculation" class="headerlink" title="Gradient Calculation"></a>Gradient Calculation</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">x = torch.tensor([[<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>], [-<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>]], requires_grad=<span class="hljs-literal">True</span>)<br>z= x.<span class="hljs-built_in">pow</span>(<span class="hljs-number">2</span>).<span class="hljs-built_in">sum</span>()<br>z.backward()<br>x.grad<br></code></pre></td></tr></table></figure><p>###Step 2 Define Neural Network</p><p><strong>torch.nn.Module</strong></p><ul><li>Linear Layer(Fully-connected Layer)</li><li>Non-Linear Activation Functions</li></ul><p>####Build your own neural network</p><p>![image-20230214163500685](D:\人工智能\photo\pytorch md\build network)</p><p>![image-20230214163623783](D:\人工智能\photo\pytorch md\build network2)</p><h3 id="Step-3-Loss-Function"><a href="#Step-3-Loss-Function" class="headerlink" title="Step 3 Loss Function"></a>Step 3 Loss Function</h3><p>torch.nn.MSELoss<br>torch.nn.CrossEntropyLoss etc.</p><p>![image-20230214163759146](D:\人工智能\photo\pytorch md\Loss functions)</p><h3 id="Step-4-Optimization-Algorithm"><a href="#Step-4-Optimization-Algorithm" class="headerlink" title="Step 4 Optimization Algorithm"></a>Step 4 Optimization Algorithm</h3><p>![image-20230214164200244](D:\人工智能\photo\pytorch md\optim)</p><p>![image-20230214164218386](D:\人工智能\photo\pytorch md\optim2)</p><h3 id="Step-5-Entire-Procedure"><a href="#Step-5-Entire-Procedure" class="headerlink" title="Step 5 Entire Procedure"></a>Step 5 Entire Procedure</h3><p>![image-20230214164603078](D:\人工智能\photo\pytorch md\nn training setup)</p><p>![image-20230214164730311](D:\人工智能\photo\pytorch md\nn training loop)</p><p>![image-20230214165115010](D:\人工智能\photo\pytorch md\nn Validation loop)</p><p>![image-20230214165337476](D:\人工智能\photo\pytorch md\nn testing loop)</p><p>![image-20230214170501908](D:\人工智能\photo\pytorch md\notice)</p><h3 id="Save-Load-Trained-Models"><a href="#Save-Load-Trained-Models" class="headerlink" title="Save&#x2F;Load Trained Models"></a>Save&#x2F;Load Trained Models</h3><p>![image-20230214170609228](D:\人工智能\photo\pytorch md\save load models)</p><h2 id="Gradient-Decent"><a href="#Gradient-Decent" class="headerlink" title="Gradient Decent"></a>Gradient Decent</h2><h3 id="Backpropagation"><a href="#Backpropagation" class="headerlink" title="Backpropagation"></a>Backpropagation</h3><p>​<strong>Chain Rule</strong></p><p>![image-20230215200837078](D:\人工智能\photo\pytorch md\chainrule)</p><p>![image-20230215200915833](D:\人工智能\photo\pytorch md\backpropagation)</p><p>![image-20230215201437884](D:\人工智能\photo\pytorch md\Backpropagation2)</p><p>![image-20230215201710167](D:\人工智能\photo\pytorch md\backpropagation3)</p><h2 id="Regression"><a href="#Regression" class="headerlink" title="Regression"></a>Regression</h2><p>[Regression李宏毅]:(<a href="https://github.com/Fafa-DL/Lhy_Machine_Learning/blob/main/%E9%80%89%E4%BF%AE">https://github.com/Fafa-DL/Lhy_Machine_Learning/blob/main/选修</a> To Learn More&#x2F;第一节&#x2F;Regression.pdf)</p><h3 id="Step-1-Model"><a href="#Step-1-Model" class="headerlink" title="Step 1 Model"></a>Step 1 Model</h3><p>![image-20230216104238590](D:\人工智能\photo\pytorch md\regression model)</p><h3 id="Step2-Goodness-of-Function"><a href="#Step2-Goodness-of-Function" class="headerlink" title="Step2 Goodness of Function"></a>Step2 Goodness of Function</h3><p>![image-20230216104604935](D:\人工智能\photo\pytorch md\regression goodnessof function)</p><h3 id="Step3-Best-Function"><a href="#Step3-Best-Function" class="headerlink" title="Step3 Best Function"></a>Step3 Best Function</h3><p>![image-20230216104653344](D:\人工智能\photo\pytorch md\regression best function)</p><p>![image-20230216104725243](D:\人工智能\photo\pytorch md\gradient descent)</p><p>Local minima Global minima</p><h3 id="Model-Selection"><a href="#Model-Selection" class="headerlink" title="Model Selection"></a>Model Selection</h3><p>![image-20230216104921552](D:\人工智能\photo\pytorch md\regression model selection)</p><p><strong><strong>Overfitting</strong>:   A  more complex model does not always lead to better performance on testing data.</strong></p><p>![image-20230220164830103](D:\人工智能\photo\pytorch md\image-20230220164830103.png)</p><p>[回归 模型选择](<a href="https://github.com/Fafa-DL/Lhy_Machine_Learning/blob/main/%E9%80%89%E4%BF%AE">https://github.com/Fafa-DL/Lhy_Machine_Learning/blob/main/选修</a> To Learn More&#x2F;第一节&#x2F;Regression.pdf)</p><h3 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a><strong>Regularization</strong></h3><p>Redefine Loss function</p><p>![image-20230216105114915](D:\人工智能\photo\pytorch md\regression regularization)</p><p><strong>Smoother</strong>：meaning is when the input change, the output change smaller(smooth)</p><p>Why we want a smooth function?: If some noises corrupt input x<del>i</del> When testing， a smooth function has less influence.</p><p>![image-20230220165823191](D:\人工智能\photo\pytorch md\image-20230220165823191.png)</p><h2 id="Classification"><a href="#Classification" class="headerlink" title="Classification"></a>Classification</h2><h3 id="Gaussian-Distribution"><a href="#Gaussian-Distribution" class="headerlink" title="Gaussian Distribution"></a>Gaussian Distribution</h3><p>![image-20230216142409305](D:\人工智能\photo\pytorch md\gaussian diutution)</p><p>![image-20230216142609834](D:\人工智能\photo\pytorch md\probability from class)</p><p>![image-20230216142701986](D:\人工智能\photo\pytorch md\Maximum Likehood)</p><p>![image-20230216143712066](D:\人工智能\photo\pytorch md\maximum likehood2)</p><h2 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h2><p>![image-20230216144705245](D:\人工智能\photo\pytorch md\Logistic regree)</p><p>![image-20230216144840928](D:\人工智能\photo\pytorch md\logistic regree2)</p><p>![image-20230216150359309](D:\人工智能\photo\pytorch md\logistic regree3)</p><p>![image-20230216150747837](D:\人工智能\photo\pytorch md\logistic regress4)</p><p>![image-20230216152128713](D:\人工智能\photo\pytorch md\logistic regree5)</p><p>![image-20230216153003383](D:\人工智能\photo\pytorch md\logistic regree6)</p><p>![image-20230216153048539](D:\人工智能\photo\pytorch md\logistic regree7)</p><p>![image-20230216153209267](D:\人工智能\photo\pytorch md\image-20230216153209267.png)</p><p> ![image-20230216153429112](D:\人工智能\photo\pytorch md\image-20230216153429112.png)</p><p>![image-20230216154717652](D:\人工智能\photo\pytorch md\cross entropy)</p><p>![image-20230216155931419](D:\人工智能\photo\pytorch md\image-20230216155931419.png)</p><p>Generative model 进行了一定的假设</p><p>![image-20230216160817270](D:\人工智能\photo\pytorch md\image-20230216160817270.png)</p><h3 id="Multi-class-Classfication"><a href="#Multi-class-Classfication" class="headerlink" title="Multi-class Classfication"></a>Multi-class Classfication</h3><p>![image-20230216161736917](D:\人工智能\photo\pytorch md\image-20230216161736917.png)</p><p>![image-20230216162028665](D:\人工智能\photo\pytorch md\image-20230216162028665.png)</p><h3 id="Limitation-of-Logistic-Regression"><a href="#Limitation-of-Logistic-Regression" class="headerlink" title="Limitation of Logistic Regression"></a>Limitation of Logistic Regression</h3><p>Feature Transformation</p><p>![image-20230216162441172](D:\人工智能\photo\pytorch md\image-20230216162441172.png)</p><p>![image-20230216163421455](D:\人工智能\photo\pytorch md\image-20230216163421455.png)</p><h2 id="General-Guidance"><a href="#General-Guidance" class="headerlink" title="General Guidance"></a>General Guidance</h2><p>![image-20230217162531424](D:\人工智能\photo\pytorch md\image-20230217162531424.png)</p><h3 id="Model-Bias"><a href="#Model-Bias" class="headerlink" title="Model Bias"></a>Model Bias</h3><p>![image-20230217163405067](D:\人工智能\photo\pytorch md\image-20230217163405067.png)</p><h3 id="OPtimization-Issue"><a href="#OPtimization-Issue" class="headerlink" title="OPtimization Issue"></a>OPtimization Issue</h3><p>![image-20230217163545349](D:\人工智能\photo\pytorch md\image-20230217163545349.png)</p><h3 id="Overfitting"><a href="#Overfitting" class="headerlink" title="Overfitting"></a>Overfitting</h3><p>![image-20230217163840304](D:\人工智能\photo\pytorch md\image-20230217163840304.png)</p><p>![image-20230217164009238](D:\人工智能\photo\pytorch md\image-20230217164009238.png)</p><p>![image-20230217164404659](D:\人工智能\photo\pytorch md\image-20230217164404659.png)</p><p><strong>Data augmentation 要根据资料特性合理设置</strong></p><p>![image-20230217164553921](D:\人工智能\photo\pytorch md\image-20230217164553921.png)</p><p>![image-20230217164710202](D:\人工智能\photo\pytorch md\image-20230217164710202.png)</p><p>![image-20230217164849894](D:\人工智能\photo\pytorch md\image-20230217164849894.png)</p><p>![image-20230217165040061](D:\人工智能\photo\pytorch md\image-20230217165040061.png)</p><p>![image-20230217165245444](D:\人工智能\photo\pytorch md\image-20230217165245444.png)</p><p><strong>模型选择 有可能恰好模型产生随机全正确</strong></p><p>![image-20230217170146204](D:\人工智能\photo\pytorch md\image-20230217170146204.png)</p><p>![image-20230217170342996](D:\人工智能\photo\pytorch md\image-20230217170342996.png)</p><h4 id="used-a-validation-set-but-model-still-overfitted"><a href="#used-a-validation-set-but-model-still-overfitted" class="headerlink" title="used a validation set, but model still overfitted?"></a>used a validation set, but model still overfitted?</h4><p>![image-20230222150042220](D:\人工智能\photo\pytorch md\image-20230222150042220.png)</p><p>![image-20230222150507570](D:\人工智能\photo\pytorch md\image-20230222150507570.png)</p><h3 id="Mismatch"><a href="#Mismatch" class="headerlink" title="Mismatch"></a>Mismatch</h3><p>![image-20230217170703851](D:\人工智能\photo\pytorch md\image-20230217170703851.png)</p><h2 id="ptimization-Fails"><a href="#ptimization-Fails" class="headerlink" title="ptimization Fails"></a>ptimization Fails</h2><p>![image-20230217174738922](D:\人工智能\photo\pytorch md\image-20230217174738922.png)</p><h3 id="local-minima"><a href="#local-minima" class="headerlink" title="local minima"></a>local minima</h3><h3 id="saddle-point"><a href="#saddle-point" class="headerlink" title="saddle point"></a>saddle point</h3><p>![image-20230217175230940](D:\人工智能\photo\pytorch md\image-20230217175230940.png)</p><p>![image-20230217175445395](D:\人工智能\photo\pytorch md\image-20230217175445395.png)</p><p>![image-20230217175935273](D:\人工智能\photo\pytorch md\image-20230217175935273.png)</p><p>![image-20230217185855119](D:\人工智能\photo\pytorch md\image-20230217185855119.png)</p><p>![image-20230217190539102](D:\人工智能\photo\pytorch md\image-20230217190539102.png)</p><h4 id="Don’t-afraid-of-saddle-point"><a href="#Don’t-afraid-of-saddle-point" class="headerlink" title="Don’t afraid of saddle point"></a>Don’t afraid of saddle point</h4><p>![image-20230217190851402](D:\人工智能\photo\pytorch md\image-20230217190851402.png)</p><p>![image-20230217192854428](D:\人工智能\photo\pytorch md\image-20230217192854428.png)</p><h2 id="Batch-and-Momentum"><a href="#Batch-and-Momentum" class="headerlink" title="Batch and Momentum"></a>Batch and Momentum</h2><h3 id="Batch-1"><a href="#Batch-1" class="headerlink" title="Batch"></a>Batch</h3><p>![image-20230217194431309](D:\人工智能\photo\pytorch md\image-20230217194431309.png)</p><p>![image-20230217195204374](D:\人工智能\photo\pytorch md\image-20230217195204374.png)</p><p>![image-20230217200343404](D:\人工智能\photo\pytorch md\image-20230217200343404.png)</p><p>![image-20230217200535811](D:\人工智能\photo\pytorch md\image-20230217200535811.png)</p><p>   ![image-20230217200708347](D:\人工智能\photo\pytorch md\image-20230217200708347.png)</p><p>·Small batch is better on testing data</p><p>![image-20230217201131973](D:\人工智能\photo\pytorch md\image-20230217201131973.png)</p><p>![image-20230217201303403](D:\人工智能\photo\pytorch md\image-20230217201303403.png)</p><h3 id="Momentum"><a href="#Momentum" class="headerlink" title="Momentum"></a>Momentum</h3><p>![image-20230217201537450](D:\人工智能\photo\pytorch md\image-20230217201537450.png)</p><p>![image-20230217202010268](D:\人工智能\photo\pytorch md\image-20230217202010268.png)</p><h2 id="Adptive-Learning-Rate"><a href="#Adptive-Learning-Rate" class="headerlink" title="Adptive Learning Rate"></a>Adptive Learning Rate</h2><p>![image-20230219103610912](D:\人工智能\photo\pytorch md\image-20230219103610912.png)</p><p>![image-20230219104510420](D:\人工智能\photo\pytorch md\image-20230219104510420.png)</p><p><strong>在某一个方向上梯度小希望学习率大一些，在某个方向梯度大一些希望学习率小一些</strong></p><p>![image-20230219104723217](D:\人工智能\photo\pytorch md\image-20230219104723217.png)</p><p>###Root Mean Square</p><p>![image-20230219105222073](D:\人工智能\photo\pytorch md\image-20230219105222073.png)</p><p>![image-20230219105414500](D:\人工智能\photo\pytorch md\image-20230219105414500.png)</p><p> ![image-20230219105807737](D:\人工智能\photo\pytorch md\image-20230219105807737.png)</p><h3 id="RMSProop"><a href="#RMSProop" class="headerlink" title="RMSProop"></a>RMSProop</h3><p>![image-20230219110213837](D:\人工智能\photo\pytorch md\image-20230219110213837.png)</p><p>![image-20230219110527256](D:\人工智能\photo\pytorch md\image-20230219110527256.png)</p><h4 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h4><p>![image-20230219110610162](D:\人工智能\photo\pytorch md\image-20230219110610162.png)</p><p>![image-20230219113320260](D:\人工智能\photo\pytorch md\image-20230219113320260.png)</p><h3 id="New-Optimizers-for-Deep-Learning"><a href="#New-Optimizers-for-Deep-Learning" class="headerlink" title="New Optimizers for Deep Learning"></a>New Optimizers for Deep Learning</h3><p>[Lhy_Machine_Learning&#x2F;Optimization.pdf at main · Fafa-DL&#x2F;Lhy_Machine_Learning (github.com)](<a href="https://github.com/Fafa-DL/Lhy_Machine_Learning/blob/main/%E9%80%89%E4%BF%AE">https://github.com/Fafa-DL/Lhy_Machine_Learning/blob/main/选修</a> To Learn More&#x2F;第二节&#x2F;Optimization.pdf)</p><p>![image-20230219173231485](D:\人工智能\photo\pytorch md\image-20230219173231485.png)</p><p>![image-20230219173402903](D:\人工智能\photo\pytorch md\image-20230219173402903.png)</p><p>![image-20230219173520988](D:\人工智能\photo\pytorch md\image-20230219173520988.png)</p><h4 id="SGD"><a href="#SGD" class="headerlink" title="SGD"></a>SGD</h4><h4 id="SGD-with-Momentum-SGDM"><a href="#SGD-with-Momentum-SGDM" class="headerlink" title="SGD with Momentum (SGDM)"></a>SGD with Momentum (SGDM)</h4><p>![image-20230219174817789](D:\人工智能\photo\pytorch md\image-20230219174817789.png)</p><h4 id="Adagraad"><a href="#Adagraad" class="headerlink" title="Adagraad"></a>Adagraad</h4><h4 id="RMSProp"><a href="#RMSProp" class="headerlink" title="RMSProp"></a>RMSProp</h4><h4 id="Adam-1"><a href="#Adam-1" class="headerlink" title="Adam"></a>Adam</h4><p>![image-20230219175650535](D:\人工智能\photo\pytorch md\image-20230219175650535.png)</p><img src="D:\人工智能\photo\pytorch md\image-20230219175745769.png" alt="image-20230219175745769" style="zoom:50%;" /><p>![image-20230219182432823](D:\人工智能\photo\pytorch md\image-20230219182432823.png)</p><p>尝试解释为什么Adam和SGDM训练不一样：</p><p>​Loss Function比较平坦，训练和测试的的Minimum就会比较接近</p><h5 id="Simply-combine-Adam-with-SGDM？—-SWATS"><a href="#Simply-combine-Adam-with-SGDM？—-SWATS" class="headerlink" title="Simply combine Adam with SGDM？—-SWATS"></a>Simply combine Adam with SGDM？—-SWATS</h5><p>![image-20230219182959481](D:\人工智能\photo\pytorch md\image-20230219182959481.png)</p><h5 id="Towards-Improving-Adam"><a href="#Towards-Improving-Adam" class="headerlink" title="Towards Improving Adam"></a>Towards Improving Adam</h5><p><a href="https://www.bilibili.com/video/BV1VN4y1P7Zj?t=2352.9&p=26">视频解释 39:00</a></p><p>假设β<del>1</del>&#x3D;0，则未使用m<del>t</del>，focous adaptive learning rate对Adam造成的影响。通过v<del>t</del>表达式可知v<del>t</del>受到梯度的影响会维持1&#x2F;(1-0.999)</p><p>![image-20230219184733050](D:\人工智能\photo\pytorch md\image-20230219184733050.png)</p><p>![image-20230219184845319](D:\人工智能\photo\pytorch md\image-20230219184845319.png)</p><h6 id="AMSGrad"><a href="#AMSGrad" class="headerlink" title="AMSGrad"></a>AMSGrad</h6><p>![image-20230219185255264](D:\人工智能\photo\pytorch md\image-20230219185255264.png)</p><h5 id="Towards-Improving-SGDM"><a href="#Towards-Improving-SGDM" class="headerlink" title="Towards Improving SGDM"></a>Towards Improving SGDM</h5><p>![image-20230219185732554](D:\人工智能\photo\pytorch md\image-20230219185732554.png)</p><p><strong>Engineering：learning rate很小或很大精度都不会很好，适中</strong></p><p>![image-20230219185906756](D:\人工智能\photo\pytorch md\image-20230219185906756.png)</p><h5 id="Does-Adam-need-warm-up"><a href="#Does-Adam-need-warm-up" class="headerlink" title="Does Adam need warm-up?"></a>Does Adam need warm-up?</h5><p>![image-20230220151750842](D:\人工智能\photo\pytorch md\image-20230220151750842.png)</p><p>为什么Adam已经Adaptive rate为什么还需要warm up?：上图实际实验说明（横轴为Iteration，纵轴为gradient 的distribution），前几步的估计不准</p><p>![image-20230220152751776](D:\人工智能\photo\pytorch md\image-20230220152751776.png)</p><p>![image-20230220153041140](D:\人工智能\photo\pytorch md\image-20230220153041140.png)</p><p>![image-20230220153440025](D:\人工智能\photo\pytorch md\image-20230220153440025.png)</p><p>![image-20230220154709135](D:\人工智能\photo\pytorch md\image-20230220154709135.png)</p><p>![image-20230220154902836](D:\人工智能\photo\pytorch md\image-20230220154902836.png)</p><h5 id="More-than-momentum"><a href="#More-than-momentum" class="headerlink" title="More than momentum"></a>More than momentum</h5><p>![image-20230220155117699](D:\人工智能\photo\pytorch md\image-20230220155117699.png)</p><p>![image-20230220160235068](D:\人工智能\photo\pytorch md\image-20230220160235068.png)</p><p><strong>▽L(θ<del>t-1</del>-λm<del>t-1</del>)表示预测下一点的梯度时如何</strong></p><p>![image-20230220161633898](D:\人工智能\photo\pytorch md\image-20230220161633898.png)</p><h5 id="Nadam"><a href="#Nadam" class="headerlink" title="Nadam"></a>Nadam</h5><p>![image-20230220162817076](D:\人工智能\photo\pytorch md\image-20230220162817076.png)</p><p>![image-20230220163803033](D:\人工智能\photo\pytorch md\image-20230220163803033.png)</p><h4 id="Something-helps-optimization"><a href="#Something-helps-optimization" class="headerlink" title="Something helps optimization"></a>Something helps optimization</h4><p>![image-20230220163905897](D:\人工智能\photo\pytorch md\image-20230220163905897.png)</p><p>![image-20230220164300905](D:\人工智能\photo\pytorch md\image-20230220164300905.png)</p><p>![image-20230220164324808](D:\人工智能\photo\pytorch md\image-20230220164324808.png)</p><h2 id="Learning-Rate-Scheduling"><a href="#Learning-Rate-Scheduling" class="headerlink" title="Learning Rate Scheduling"></a>Learning Rate Scheduling</h2><p>将Learning Rate与时间有关</p><p>![image-20230219113538883](D:\人工智能\photo\pytorch md\image-20230219113538883.png)</p><p>![image-20230219114058621](D:\人工智能\photo\pytorch md\image-20230219114058621.png)</p><p>![image-20230219113906542](D:\人工智能\photo\pytorch md\image-20230219113906542.png)</p><p>![image-20230219114343052](D:\人工智能\photo\pytorch md\image-20230219114343052.png)</p><h2 id="再探宝可梦、数码宝贝分类器—浅谈机器学习原理"><a href="#再探宝可梦、数码宝贝分类器—浅谈机器学习原理" class="headerlink" title="再探宝可梦、数码宝贝分类器—浅谈机器学习原理"></a>再探宝可梦、数码宝贝分类器—浅谈机器学习原理</h2><p>![image-20230219134611063](D:\人工智能\photo\pytorch md\image-20230219134611063.png)</p><h4 id="模型复杂度"><a href="#模型复杂度" class="headerlink" title="模型复杂度"></a>模型复杂度</h4><p>![image-20230219140424624](D:\人工智能\photo\pytorch md\image-20230219140424624.png)</p><p>![image-20230219140828795](D:\人工智能\photo\pytorch md\image-20230219140828795.png)</p><h4 id="i-i-d"><a href="#i-i-d" class="headerlink" title="i.i.d"></a>i.i.d</h4><p>![image-20230219141400722](D:\人工智能\photo\pytorch md\image-20230219141400722.png)</p><p>![image-20230219141507996](D:\人工智能\photo\pytorch md\image-20230219141507996.png)</p><p>![image-20230219142322281](D:\人工智能\photo\pytorch md\image-20230219142322281.png)</p><h3 id="What-train-sample-do-we-want"><a href="#What-train-sample-do-we-want" class="headerlink" title="What train sample do we want?"></a>What train sample do we want?</h3><p><strong>train得到的模型好坏取决于sample时的资料</strong></p><p>![image-20230219143624556](D:\人工智能\photo\pytorch md\image-20230219143624556.png)</p><p>L(h^all^, D<del>all</del> )一定会比L(h^train^, D<del>all</del> )小</p><p>![image-20230219143741645](D:\人工智能\photo\pytorch md\image-20230219143741645.png)</p><p>![image-20230219143939593](D:\人工智能\photo\pytorch md\image-20230219143939593.png)</p><h3 id="General"><a href="#General" class="headerlink" title="General"></a>General</h3><p>![image-20230219144104393](D:\人工智能\photo\pytorch md\image-20230219144104393.png)</p><p>![image-20230219150624632](D:\人工智能\photo\pytorch md\image-20230219150624632.png)</p><img src="D:\人工智能\photo\pytorch md\image-20230219150949584.png" alt="image-20230219150949584" style="zoom: 50%;" /><img src="D:\人工智能\photo\pytorch md\image-20230219151206774.png" alt="image-20230219151206774" style="zoom:50%;" /><img src="D:\人工智能\photo\pytorch md\image-20230219151432675.png" alt="image-20230219151432675" style="zoom:50%;" /><img src="D:\人工智能\photo\pytorch md\image-20230219151632461.png" alt="image-20230219151632461" style="zoom:50%;" /><p>![image-20230219151824419](D:\人工智能\photo\pytorch md\image-20230219151824419.png)</p><p>![image-20230219151902001](D:\人工智能\photo\pytorch md\image-20230219151902001.png)</p><p>![image-20230219151916700](D:\人工智能\photo\pytorch md\image-20230219151916700.png)</p><p>![image-20230219152147020](D:\人工智能\photo\pytorch md\image-20230219152147020.png)</p><p>![image-20230219152515395](D:\人工智能\photo\pytorch md\image-20230219152515395.png)</p><p>![image-20230219152656072](D:\人工智能\photo\pytorch md\image-20230219152656072.png)</p><p>![image-20230219153140826](D:\人工智能\photo\pytorch md\image-20230219153140826.png)</p><p>![image-20230219153347413](D:\人工智能\photo\pytorch md\image-20230219153347413.png)</p><h3 id="Why-more-parameters-are-easier-to-overfit"><a href="#Why-more-parameters-are-easier-to-overfit" class="headerlink" title="Why more parameters are easier to overfit?"></a>Why more parameters are easier to overfit?</h3><h2 id="鱼与熊掌可以兼得的机器学习"><a href="#鱼与熊掌可以兼得的机器学习" class="headerlink" title="鱼与熊掌可以兼得的机器学习"></a>鱼与熊掌可以兼得的机器学习</h2><h3 id="Review：Why-hidden-layer"><a href="#Review：Why-hidden-layer" class="headerlink" title="Review：Why hidden layer?"></a>Review：Why hidden layer?</h3><p>可以通过一个hidden layer找出所有可能的function</p><p>![image-20230222151535069](D:\人工智能\photo\pytorch md\image-20230222151535069.png)</p><p>![image-20230222151614261](D:\人工智能\photo\pytorch md\image-20230222151614261.png)</p><p>![image-20230222151643870](D:\人工智能\photo\pytorch md\image-20230222151643870.png)</p><p>![image-20230222152253769](D:\人工智能\photo\pytorch md\image-20230222152253769.png)</p><p>![image-20230222152423524](D:\人工智能\photo\pytorch md\image-20230222152423524.png)</p><p>![image-20230222152447853](D:\人工智能\photo\pytorch md\image-20230222152447853.png)</p><p>![image-20230222153444309](D:\人工智能\photo\pytorch md\image-20230222153444309.png)</p><p>探讨网络深层的作用</p><p>![image-20230222154525682](D:\人工智能\photo\pytorch md\image-20230222154525682.png)</p><p>![image-20230222154753511](D:\人工智能\photo\pytorch md\image-20230222154753511.png)</p><p>![image-20230222155100307](D:\人工智能\photo\pytorch md\image-20230222155100307.png)</p><p>![image-20230222155207551](D:\人工智能\photo\pytorch md\image-20230222155207551.png)</p><p>![image-20230222155229862](D:\人工智能\photo\pytorch md\image-20230222155229862.png)</p><h2 id="HW2"><a href="#HW2" class="headerlink" title="HW2"></a>HW2</h2><h2 id="Concolutional-Neural-Network-CNN"><a href="#Concolutional-Neural-Network-CNN" class="headerlink" title="Concolutional Neural Network(CNN)"></a>Concolutional Neural Network(CNN)</h2><p><strong>Network Architecture designed for Image</strong></p><p>![image-20230221190847727](D:\人工智能\photo\pytorch md\image-20230221190847727.png)</p><p>对电脑来说一张图片是什么？</p><p>![image-20230221191148146](D:\人工智能\photo\pytorch md\image-20230221191148146.png)</p><p>![image-20230222133926254](D:\人工智能\photo\pytorch md\image-20230222133926254.png)</p><p>参数过多容易overfitting</p><p>![image-20230222134324377](D:\人工智能\photo\pytorch md\image-20230222134324377.png)</p><h3 id="Receptive-field"><a href="#Receptive-field" class="headerlink" title="Receptive field"></a>Receptive field</h3><p>![image-20230222134630110](D:\人工智能\photo\pytorch md\image-20230222134630110.png)</p><p>![image-20230222135225522](D:\人工智能\photo\pytorch md\image-20230222135225522.png)</p><p>·</p><p>![image-20230222135722131](D:\人工智能\photo\pytorch md\image-20230222135722131.png)</p><p>![image-20230222135846875](D:\人工智能\photo\pytorch md\image-20230222135846875.png)</p><p>parameter sharing</p><p>![image-20230222140105874](D:\人工智能\photo\pytorch md\image-20230222140105874.png)</p><p>![image-20230222140225472](D:\人工智能\photo\pytorch md\image-20230222140225472.png)</p><p>![image-20230222140412998](D:\人工智能\photo\pytorch md\image-20230222140412998.png)</p><p>![image-20230222140504306](D:\人工智能\photo\pytorch md\image-20230222140504306.png)</p><p>![image-20230222140728856](D:\人工智能\photo\pytorch md\image-20230222140728856.png)</p><p>![image-20230222140813030](D:\人工智能\photo\pytorch md\image-20230222140813030.png)</p><p>![image-20230222140957944](D:\人工智能\photo\pytorch md\image-20230222140957944.png)</p><p>若filter大小一直设置3*3，会使network不能看更大的图吗？</p><p>![image-20230222141306342](D:\人工智能\photo\pytorch md\image-20230222141306342.png)</p><p>![image-20230222141343778](D:\人工智能\photo\pytorch md\image-20230222141343778.png)</p><p>![image-20230222141401887](D:\人工智能\photo\pytorch md\image-20230222141401887.png)</p><p>同样的小目标可以出现在不同地方所以不同区域可以共用参数。</p><h3 id="Pooling-Max-Pooling"><a href="#Pooling-Max-Pooling" class="headerlink" title="Pooling-Max Pooling"></a>Pooling-Max Pooling</h3><p>![image-20230222142228736](D:\人工智能\photo\pytorch md\image-20230222142228736.png)</p><p>Max Pooling作用：把图片变小</p><p>Pooling主要的作用是减少运算量</p><p>![image-20230222143015795](D:\人工智能\photo\pytorch md\image-20230222143015795.png)</p><p>![image-20230222143054258](D:\人工智能\photo\pytorch md\image-20230222143054258.png)</p><p>![image-20230222143303706](D:\人工智能\photo\pytorch md\image-20230222143303706.png) </p><p>![image-20230222143421544](D:\人工智能\photo\pytorch md\image-20230222143421544.png)</p><p>![image-20230222143633013](D:\人工智能\photo\pytorch md\image-20230222143633013.png)</p><h2 id="Spatial-Transformer-Layer"><a href="#Spatial-Transformer-Layer" class="headerlink" title="Spatial Transformer Layer"></a>Spatial Transformer Layer</h2><p>![image-20230222162327297](D:\人工智能\photo\pytorch md\image-20230222162327297.png)</p><p>![image-20230222163100727](D:\人工智能\photo\pytorch md\image-20230222163100727.png)</p><p>![image-20230222163346290](D:\人工智能\photo\pytorch md\image-20230222163346290.png)</p><p>![image-20230222163816076](D:\人工智能\photo\pytorch md\image-20230222163816076.png)</p><p>![image-20230222164539375](D:\人工智能\photo\pytorch md\image-20230222164539375.png)</p><p>![image-20230222164711179](D:\人工智能\photo\pytorch md\image-20230222164711179.png)</p><p>![image-20230222164815484](D:\人工智能\photo\pytorch md\image-20230222164815484.png)</p><p>![image-20230222165047469](D:\人工智能\photo\pytorch md\image-20230222165047469.png)</p><p>![image-20230222170141809](D:\人工智能\photo\pytorch md\image-20230222170141809.png)</p><p>![image-20230222170814869](D:\人工智能\photo\pytorch md\image-20230222170814869.png)</p><h2 id="Self-attention"><a href="#Self-attention" class="headerlink" title="Self-attention"></a>Self-attention</h2><p>解决问题：network input is a set of vectors not a vector</p><p>![image-20230223161320964](D:\人工智能\photo\pytorch md\image-20230223161320964.png)</p><p>例子：文字处理，假设处理的是句子每个句子的长度都不一样，将句子每一个词汇都描绘成向量，则句子是一个Vector Set</p><p>如何将词汇表示成向量？—One-hot Encoding，问题假设每个词汇之间没有关系</p><p>![image-20230223162805885](D:\人工智能\photo\pytorch md\image-20230223162805885.png)</p><p>例子2：声音讯号</p><p>![image-20230223163103560](D:\人工智能\photo\pytorch md\image-20230223163103560.png)</p><p>![image-20230223163644962](D:\人工智能\photo\pytorch md\image-20230223163644962.png)</p><p>![image-20230223164116773](D:\人工智能\photo\pytorch md\image-20230223164116773.png)</p><p>![image-20230223164131670](D:\人工智能\photo\pytorch md\image-20230223164131670.png)</p><h3 id="Sequence-Labeling"><a href="#Sequence-Labeling" class="headerlink" title="Sequence Labeling"></a>Sequence Labeling</h3><p>![image-20230223164432190](D:\人工智能\photo\pytorch md\image-20230223164432190.png)</p><h3 id="Self-attention-1"><a href="#Self-attention-1" class="headerlink" title="Self-attention"></a>Self-attention</h3><p><strong>How working?</strong></p><p>self-attention会接收一整个sequence资料，input 多少vector就输出多少vector，输出vector考虑一整个sequence得到。</p><p>![image-20230223164858274](D:\人工智能\photo\pytorch md\image-20230223164858274.png)</p><p>self-attention可以很多次，fully connection network和self-attention可以交替使用，fully connection network处理某一位置资料，self-attention处理整个sequence</p><p>![image-20230223165123881](D:\人工智能\photo\pytorch md\image-20230223165123881.png)</p><p>![image-20230223165253237](D:\人工智能\photo\pytorch md\image-20230223165253237.png)</p><p>![image-20230223165405133](D:\人工智能\photo\pytorch md\image-20230223165405133.png)</p><p>![image-20230223170452941](D:\人工智能\photo\pytorch md\image-20230223170452941.png)</p><p>![image-20230223170706124](D:\人工智能\photo\pytorch md\image-20230223170706124.png)</p><p>![image-20230223170837944](D:\人工智能\photo\pytorch md\image-20230223170837944.png)</p><p>![image-20230223173855690](D:\人工智能\photo\pytorch md\image-20230223173855690.png)</p><p>从矩阵乘法解释Self-attention：</p><p>![image-20230223180959958](D:\人工智能\photo\pytorch md\image-20230223180959958.png)</p><p>![image-20230223181544814](D:\人工智能\photo\pytorch md\image-20230223181544814.png)</p><p>![image-20230224163731902](D:\人工智能\photo\pytorch md\image-20230224163731902.png)</p><p>![image-20230224164123140](D:\人工智能\photo\pytorch md\image-20230224164123140.png)</p><h4 id="Multi-head-Self-attention"><a href="#Multi-head-Self-attention" class="headerlink" title="Multi-head Self-attention"></a>Multi-head Self-attention</h4><p>![image-20230224164758954](D:\人工智能\photo\pytorch md\image-20230224164758954.png)</p><p>![image-20230224164821859](D:\人工智能\photo\pytorch md\image-20230224164821859.png)</p><p>Self attention没有位置信息</p><p>![image-20230224165938999](D:\人工智能\photo\pytorch md\image-20230224165938999.png)</p><p>![image-20230224170054154](D:\人工智能\photo\pytorch md\image-20230224170054154.png)</p><p>语言辨识：输入向量会很大，只看很小范围。</p><p>![image-20230224170251429](D:\人工智能\photo\pytorch md\image-20230224170251429.png)</p><p>![image-20230224171004645](D:\人工智能\photo\pytorch md\image-20230224171004645.png)</p><p>![image-20230224171217528](D:\人工智能\photo\pytorch md\image-20230224171217528.png)</p><p>CNN是self-attention的特例</p><p>Self-attention与CNN比较，模型复杂，容易过拟合</p><p>![image-20230224171522251](D:\人工智能\photo\pytorch md\image-20230224171522251.png)</p><p>![image-20230224174602637](D:\人工智能\photo\pytorch md\image-20230224174602637.png)</p><h3 id="各式各样的Attention"><a href="#各式各样的Attention" class="headerlink" title="各式各样的Attention"></a>各式各样的Attention</h3><p>![image-20230227155038921](D:\人工智能\photo\pytorch md\image-20230227155038921.png)</p><p>N×N的计算量特别大</p><p>![image-20230227155812871](D:\人工智能\photo\pytorch md\image-20230227155812871.png)</p><p>当Input的N非常大时，以下的处理才会很有效果。</p><p>![image-20230227161036092](D:\人工智能\photo\pytorch md\image-20230227161036092.png)</p><p>####Skip Some Calculations</p><p>N×N矩阵中有些位置不需要计算</p><p>![image-20230227161214393](D:\人工智能\photo\pytorch md\image-20230227161214393.png)</p><h5 id="Local-Attention-Truncated-Attention"><a href="#Local-Attention-Truncated-Attention" class="headerlink" title="Local Attention&#x2F;Truncated Attention"></a>Local Attention&#x2F;Truncated Attention</h5><p>![image-20230227161430915](D:\人工智能\photo\pytorch md\image-20230227161430915.png)</p><p>每次attention只能看见小范围，与CNN相似</p><h5 id="Stride-Attention"><a href="#Stride-Attention" class="headerlink" title="Stride Attention"></a>Stride Attention</h5><p>![image-20230227161633916](D:\人工智能\photo\pytorch md\image-20230227161633916.png)</p><h5 id="Global-Attention"><a href="#Global-Attention" class="headerlink" title="Global Attention"></a>Global Attention</h5><p><a href="https://www.bilibili.com/video/BV1VN4y1P7Zj?t=871.0&p=51">讲解 第14分钟</a></p><p>![image-20230227162251395](D:\人工智能\photo\pytorch md\image-20230227162251395.png)</p><p>![image-20230227162444796](D:\人工智能\photo\pytorch md\image-20230227162444796.png)</p><p><strong>用Multi-head attention</strong></p><p>![image-20230227162554550](D:\人工智能\photo\pytorch md\image-20230227162554550.png)</p><h3 id="Focous-on-Critical-Pats"><a href="#Focous-on-Critical-Pats" class="headerlink" title="Focous on Critical Pats"></a>Focous on Critical Pats</h3><p>![image-20230227162752928](D:\人工智能\photo\pytorch md\image-20230227162752928.png)</p><h4 id="Clustering"><a href="#Clustering" class="headerlink" title="Clustering"></a>Clustering</h4><p>相近的vector属于相同的cluster，不相近的属于不同的cluster。</p><p>![image-20230227163049571](D:\人工智能\photo\pytorch md\image-20230227163049571.png)</p><p>![image-20230227163128433](D:\人工智能\photo\pytorch md\image-20230227163128433.png)</p><h3 id="Learnable-Patterns"><a href="#Learnable-Patterns" class="headerlink" title="Learnable Patterns"></a>Learnable Patterns</h3><p>通过Learned计算哪些地方需要计算</p><p>![image-20230227163638822](D:\人工智能\photo\pytorch md\image-20230227163638822.png)</p><p>Sinkhorn Sorting Network如何实现加速的？<a href="https://www.bilibili.com/video/BV1VN4y1P7Zj?t=1802.4&p=51">解释 第28分钟</a></p><h3 id="Do-we-need-full-attention-matrix"><a href="#Do-we-need-full-attention-matrix" class="headerlink" title="Do we need full attention matrix?"></a>Do we need full attention matrix?</h3><p><a href="https://www.bilibili.com/video/BV1VN4y1P7Zj?t=1802.4&p=51">定位 第31分钟</a></p><p>![image-20230227164502837](D:\人工智能\photo\pytorch md\image-20230227164502837.png)</p><p>![image-20230227164543048](D:\人工智能\photo\pytorch md\image-20230227164543048.png)</p><p> ![image-20230227164613934](D:\人工智能\photo\pytorch md\image-20230227164613934.png)</p><p>![image-20230227164942378](D:\人工智能\photo\pytorch md\image-20230227164942378.png)</p><p>处理query根据问题考虑，若是作业2那种会减少label数量</p><h4 id="Reduce-Nember-of-Keys"><a href="#Reduce-Nember-of-Keys" class="headerlink" title="Reduce Nember of Keys"></a>Reduce Nember of Keys</h4><p>![image-20230227171901971](D:\人工智能\photo\pytorch md\image-20230227171901971.png)</p><p>![image-20230227172155132](D:\人工智能\photo\pytorch md\image-20230227172155132.png)</p><p>![image-20230227172136198](D:\人工智能\photo\pytorch md\image-20230227172136198.png)</p><p>![image-20230227172326858](D:\人工智能\photo\pytorch md\image-20230227172326858.png)</p><p>![image-20230227172435027](D:\人工智能\photo\pytorch md\image-20230227172435027.png)</p><p>![image-20230227172633979](D:\人工智能\photo\pytorch md\image-20230227172633979.png)</p><p>![image-20230227173058847](D:\人工智能\photo\pytorch md\image-20230227173058847.png)</p><p>![image-20230227173153780](D:\人工智能\photo\pytorch md\image-20230227173153780.png)</p><p>![image-20230227173605771](D:\人工智能\photo\pytorch md\image-20230227173605771.png)</p><p>![image-20230227174638919](D:\人工智能\photo\pytorch md\image-20230227174638919.png)</p><p>![image-20230227175224594](D:\人工智能\photo\pytorch md\image-20230227175224594.png)</p><p>![image-20230227175551056](D:\人工智能\photo\pytorch md\image-20230227175551056.png)</p><p>![image-20230227175834055](D:\人工智能\photo\pytorch md\image-20230227175834055.png)</p><p>![image-20230227175849100](D:\人工智能\photo\pytorch md\image-20230227175849100.png)</p><p>![image-20230227180202579](D:\人工智能\photo\pytorch md\image-20230227180202579.png)</p><p>![image-20230227180222407](D:\人工智能\photo\pytorch md\image-20230227180222407.png)</p><p>![image-20230227180355433](D:\人工智能\photo\pytorch md\image-20230227180355433.png)</p><p>![image-20230227180413220](D:\人工智能\photo\pytorch md\image-20230227180413220.png)</p><h4 id="Synthesizer"><a href="#Synthesizer" class="headerlink" title="Synthesizer"></a>Synthesizer</h4><h2 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h2><p><a href="https://www.youtube.com/watch?v=xCGidAeyS4M">RNN PART1</a></p><p><a href="https://www.youtube.com/watch?v=rTqmWlnwz_0">RNN PART2</a></p><h3 id="Example-Application"><a href="#Example-Application" class="headerlink" title="Example Application"></a>Example Application</h3><p><img src="D:\人工智能\image-20230824094358392.png" alt="image-20230824094358392"></p><p><img src="D:\人工智能\image-20230824094857191.png" alt="image-20230824094857191"></p><p><img src="D:\人工智能\image-20230824094637898.png" alt="image-20230824094637898"></p><p><img src="D:\人工智能\image-20230824094806665.png" alt="image-20230824094806665"></p><p>希望神经网络是有记忆的：如输入台北只能输出是目的地而不能分辨此时的台北是出发地还是到达地</p><p><img src="D:\人工智能\image-20230824095157640.png" alt="image-20230824095157640"></p><p>###ElmanNetwork</p><p><img src="D:\人工智能\image-20230824095752464.png" alt="image-20230824095752464"></p><p><img src="D:\人工智能\image-20230824100037972.png" alt="image-20230824100037972"></p><p><img src="D:\人工智能\image-20230824100110111.png" alt="image-20230824100110111"></p><p> <img src="D:\人工智能\image-20230824100146747.png" alt="image-20230824100146747"></p><h3 id="Jordan-Network"><a href="#Jordan-Network" class="headerlink" title="Jordan Network"></a>Jordan Network</h3><p><img src="D:\人工智能\image-20230824100319375.png" alt="image-20230824100319375"></p><p>Jordan Network学习效果可能比较好</p><h3 id="Bidirectional-RNN"><a href="#Bidirectional-RNN" class="headerlink" title="Bidirectional RNN"></a>Bidirectional RNN</h3><p>产生输出时看的学习到的范围比较广</p><p><img src="D:\人工智能\image-20230824100517783.png" alt="image-20230824100517783"></p><h3 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h3><p>Long Short-term MEMORY</p><p>Input Gate：只有打开时才能将值写入Memory Cell，打开关闭可以有NN自己学习</p><p>Output Gate：决定外界可不可以将值读出来</p><p>Forget Gate：决定何时将Memory Cell忘掉，打开时代表记住，关闭代表遗忘</p><p><img src="D:\人工智能\image-20230824101358392.png" alt="image-20230824101358392"></p><p><img src="D:\人工智能\image-20230824101956681.png" alt="image-20230824101956681"></p><p>激活函数通常旋转sigmoid是因为此值在0-1.可以代表打开程度</p><p><img src="D:\人工智能\image-20230824102122860.png" alt="image-20230824102122860"></p><p><img src="D:\人工智能\image-20230824102428705.png" alt="image-20230824102428705"></p><h3 id="Difference-between-RNN-and-LSTM"><a href="#Difference-between-RNN-and-LSTM" class="headerlink" title="Difference between RNN and LSTM"></a>Difference between RNN and LSTM</h3><p><img src="D:\人工智能\image-20230824102900519.png" alt="image-20230824102900519"></p><p><img src="D:\人工智能\image-20230824102825524.png" alt="image-20230824102825524"></p><p><img src="D:\人工智能\image-20230824103223033.png" alt="image-20230824103223033"></p><p><img src="D:\人工智能\image-20230824103345925.png" alt="image-20230824103345925"></p><p><img src="D:\人工智能\image-20230824103442370.png" alt="image-20230824103442370"></p><h3 id="Multiple-layer-LSTM"><a href="#Multiple-layer-LSTM" class="headerlink" title="Multiple-layer LSTM"></a>Multiple-layer LSTM</h3><p><img src="D:\人工智能\image-20230824103522067.png" alt="image-20230824103522067"></p><h3 id="Learning-Target"><a href="#Learning-Target" class="headerlink" title="Learning Target"></a>Learning Target</h3><p>结果的cost:每个RNN的output和reference vector的cross entropy和 去minimize</p><p><img src="D:\人工智能\image-20230824105847788.png" alt="image-20230824105847788"></p><h3 id="BPTT"><a href="#BPTT" class="headerlink" title="BPTT"></a>BPTT</h3><p><img src="D:\人工智能\image-20230824110021184.png" alt="image-20230824110021184"></p><p><img src="D:\人工智能\image-20230824110158861.png" alt="image-20230824110158861"></p><p><img src="D:\人工智能\image-20230824110322220.png" alt="image-20230824110322220"></p><p><img src="D:\人工智能\image-20230824110554974.png" alt="image-20230824110554974"></p><p>Clipping： 当gradient大于某个threshold时，就不要超过threshold</p><p><img src="D:\人工智能\image-20230824111209049.png" alt="image-20230824111209049"></p><p>为什么RNN误差会很崎岖：RNN训练问题，源自在时间和时间转换transition时反复使用，从memory接到neuron的一组weight反复被使用，所以ｗ有变化，则会产生如上图gradient会有时很大有时很小</p><p>使用LSTM时候可以避免gradient平坦，因此可以将ｌｅａｒｎｉｎｇ　ｒａｔｅ设的小，如下图</p><p><img src="D:\人工智能\image-20230824112210517.png" alt="image-20230824112210517"></p><p>参数多可能会带来Over fitting的情况</p><p><img src="D:\人工智能\image-20230824112329435.png" alt="image-20230824112329435"></p><h2 id="GNN"><a href="#GNN" class="headerlink" title="GNN"></a>GNN</h2><p>暂时略过</p><h2 id="Quick-Introduction-of-Batch-Normalization"><a href="#Quick-Introduction-of-Batch-Normalization" class="headerlink" title="Quick Introduction of Batch Normalization"></a>Quick Introduction of Batch Normalization</h2><p>![image-20230226104124832](D:\人工智能\photo\pytorch md\image-20230226104124832.png)</p><p>![image-20230226104007327](D:\人工智能\photo\pytorch md\image-20230226104007327.png)</p><p>难训练</p><p>给feature中不同的dimension，有同样的数值范围。</p><h3 id="Feature-Normalization"><a href="#Feature-Normalization" class="headerlink" title="Feature Normalization"></a>Feature Normalization</h3><p>![image-20230226104721560](D:\人工智能\photo\pytorch md\image-20230226104721560.png)</p><p>![image-20230226104935859](D:\人工智能\photo\pytorch md\image-20230226104935859.png)</p><p>x正规化后，W作用也可能会使训练困难，feature Normalization可以选择在激活函数之前或之后；选择sigmoid做激活函数推荐对z做feature Normalization。</p><p>![image-20230226105226151](D:\人工智能\photo\pytorch md\image-20230226105226151.png)</p><p>![image-20230226105254442](D:\人工智能\photo\pytorch md\image-20230226105254442.png)</p><p>![image-20230226105619749](D:\人工智能\photo\pytorch md\image-20230226105619749.png)</p><p>![image-20230226105830567](D:\人工智能\photo\pytorch md\image-20230226105830567.png)</p><p>β、γ使Z均值不为0，β初始值1，γ初始值0.</p><h3 id="Batch-Normalization-—Testing"><a href="#Batch-Normalization-—Testing" class="headerlink" title="Batch Normalization —Testing"></a>Batch Normalization —Testing</h3><p>![image-20230226110917675](D:\人工智能\photo\pytorch md\image-20230226110917675.png)</p><h3 id="How-does-Batch-Normalization-Help-Optimization？—–Internal-Covariate-Shift？"><a href="#How-does-Batch-Normalization-Help-Optimization？—–Internal-Covariate-Shift？" class="headerlink" title="How does Batch Normalization Help Optimization？—–Internal Covariate Shift？"></a>How does Batch Normalization Help Optimization？—–Internal Covariate Shift？</h3><p>![image-20230226111349311](D:\人工智能\photo\pytorch md\image-20230226111349311.png)</p><p>![image-20230226111523076](D:\人工智能\photo\pytorch md\image-20230226111523076.png)</p><p>![image-20230226111542936](D:\人工智能\photo\pytorch md\image-20230226111542936.png)</p><p>![image-20230226120807141](D:\人工智能\photo\pytorch md\image-20230226120807141.png)</p><h1 id="PyTorch数据集归一化-torchvision-transforms-Normalize"><a href="#PyTorch数据集归一化-torchvision-transforms-Normalize" class="headerlink" title="PyTorch数据集归一化- torchvision.transforms.Normalize()"></a><a href="https://so.csdn.net/so/search?q=PyTorch&spm=1001.2101.3001.7020">PyTorch</a>数据集归一化- torchvision.transforms.Normalize()</h1><p>Pytorch数据归一化</p><h3 id="图像处理为什么要归一化？"><a href="#图像处理为什么要归一化？" class="headerlink" title="图像处理为什么要归一化？"></a>图像处理为什么要归一化？</h3><p>对于网络模型训练等，是为了加速神经网络训练收敛，以及保证程序运行时收敛加快。</p><p>数据归一化的概念是一个通用概念，指的是将数据集的原始值转换为新值的行为。新值通常是相对于数据集本身进行编码的，并以某种方式进行缩放。</p><p><strong>特征缩放</strong></p><p>出于这个原因，有时数据归一化的另一个名称是特征缩放。这个术语指的是，在对数据进行归一化时，我们经常会将给定数据集的不同特征转化为相近的范围。</p><p>在这种情况下，我们不仅仅是考虑一个值的数据集，还要<strong>考虑一个具有多个特征的元素的数据集，及每个特征的值</strong>。</p><p>举例来说，假设我们要处理的是一个人的数据集，我们的数据集中有两个相关的特征，年龄和体重。在这种情况下，我们可以观察到，这两个特征集的大小或尺度是不同的，即体重平均大于年龄。</p><p>在使用机器学习算法进行比较或计算时，这种幅度上的差异可能是个问题。因此，这可能是我们希望通过特征缩放将这些特征的值缩放到一些相近尺度的原因之一。<br><strong>规范化示例</strong><br>当我们对数据集进行归一化时，我们通常会对相对于数据集的每个特定值进行某种形式的信息编码，然后重新缩放数据。考虑下面这个例子：</p><p>假设我们有一个正数集合 S 。现在，假设我们从集合s 随机选择一个 x 值并思考：这个 x 值是集合s中最大的数嘛 ？<br>在这种情况下，答案是我们不知道。我们只是没有足够的信息来回答问题。<br>但是，现在假设我们被告知 集合 S 通过将每个值除以集合内的最大值进行归一化。通过此标准化过程，已对值最大的信息进行了编码，并对数据进行了重新缩放。<br>集合中最大的成员是 1，并且数据已按比例缩放到间隔 [0,1]。</p><h2 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h2><p>Seq2Seq</p><p>![image-20230226114520352](D:\人工智能\photo\pytorch md\image-20230226114520352.png)</p><p>![image-20230226114631545](D:\人工智能\photo\pytorch md\image-20230226114631545.png)</p><p>![image-20230226114703556](D:\人工智能\photo\pytorch md\image-20230226114703556.png)</p><p>![image-20230226115110295](D:\人工智能\photo\pytorch md\image-20230226115110295.png)</p><p>![image-20230226115738607](D:\人工智能\photo\pytorch md\image-20230226115738607.png)</p><p>###Seq2seq</p><p>  ![image-20230226115959555](D:\人工智能\photo\pytorch md\image-20230226115959555.png)</p><h3 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h3><p>![image-20230226120051473](D:\人工智能\photo\pytorch md\image-20230226120051473.png)</p><p>![image-20230226120145462](D:\人工智能\photo\pytorch md\image-20230226120145462.png)</p><p>![image-20230226121013255](D:\人工智能\photo\pytorch md\image-20230226121013255.png)</p><p>![image-20230226121054634](D:\人工智能\photo\pytorch md\image-20230226121054634.png)</p><h3 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h3><p>Decoder:把Encoder产生的输出都读进去，</p><p>BEGIN（special token）：Decoder开始符号，</p><h4 id="Autoregressive-AT"><a href="#Autoregressive-AT" class="headerlink" title="Autoregressive(AT)"></a>Autoregressive(AT)</h4><p>![image-20230227142225440](D:\人工智能\photo\pytorch md\image-20230227142225440.png)</p><p>![image-20230227142303877](D:\人工智能\photo\pytorch md\image-20230227142303877.png)</p><p>Decoder看见的输入其实是前一个时间点自己的输出</p><p>![image-20230227142315802](D:\人工智能\photo\pytorch md\image-20230227142315802.png)</p><p>![image-20230227142519206](D:\人工智能\photo\pytorch md\image-20230227142519206.png)</p><p>![image-20230227142537156](D:\人工智能\photo\pytorch md\image-20230227142537156.png)</p><p>![image-20230227142630739](D:\人工智能\photo\pytorch md\image-20230227142630739.png)</p><p>![image-20230227142737083](D:\人工智能\photo\pytorch md\image-20230227142737083.png)</p><p><strong>Masked</strong>：产生b<del>i</del>时候，不能看比i大的信息</p><p>![image-20230227142843045](D:\人工智能\photo\pytorch md\image-20230227142843045.png)</p><p>![image-20230227142906032](D:\人工智能\photo\pytorch md\image-20230227142906032.png)</p><p><strong>Why masked?</strong> Consider how does decoder work.</p><p>![image-20230227143253075](D:\人工智能\photo\pytorch md\image-20230227143253075.png)</p><p><strong>Adding “Stop Token”</strong></p><p>![image-20230227143441165](D:\人工智能\photo\pytorch md\image-20230227143441165.png)</p><p>![image-20230227143456890](D:\人工智能\photo\pytorch md\image-20230227143456890.png)</p><h4 id="NAT-Non-autoregressive"><a href="#NAT-Non-autoregressive" class="headerlink" title="NAT Non-autoregressive"></a>NAT Non-autoregressive</h4><p>一次把整个句子产生出来</p><p>![image-20230227143706330](D:\人工智能\photo\pytorch md\image-20230227143706330.png)</p><p>![image-20230227144034589](D:\人工智能\photo\pytorch md\image-20230227144034589.png)</p><h3 id="Encoder-2-Decoder"><a href="#Encoder-2-Decoder" class="headerlink" title="Encoder 2 Decoder"></a>Encoder 2 Decoder</h3><p>![image-20230227144248632](D:\人工智能\photo\pytorch md\image-20230227144248632.png)</p><h4 id="Cross-attention"><a href="#Cross-attention" class="headerlink" title="Cross attention"></a>Cross attention</h4><p>![image-20230227144501296](D:\人工智能\photo\pytorch md\image-20230227144501296.png)</p><p>![image-20230227144542973](D:\人工智能\photo\pytorch md\image-20230227144542973.png)</p><p>![image-20230227144840761](D:\人工智能\photo\pytorch md\image-20230227144840761.png)</p><p>![image-20230227145007530](D:\人工智能\photo\pytorch md\image-20230227145007530.png)</p><h3 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h3><p>![image-20230227145101111](D:\人工智能\photo\pytorch md\image-20230227145101111.png)</p><p>![image-20230227145328425](D:\人工智能\photo\pytorch md\image-20230227145328425.png)</p><p>![image-20230227145525543](D:\人工智能\photo\pytorch md\image-20230227145525543.png)</p><p>Decoder输入的时候，给Decoder输入正确的答案——<strong>Teacher Forcing</strong>：using the ground truth as input.</p><h4 id="Tips"><a href="#Tips" class="headerlink" title="Tips"></a>Tips</h4><p>#####Copy Mechanism</p><p>一些情况下不需要decoder创造输出出来，可能需要从输入中复制一些出来；例如聊天机器人、摘要提取</p><p>![image-20230227145849416](D:\人工智能\photo\pytorch md\image-20230227145849416.png)</p><p>![image-20230227145913631](D:\人工智能\photo\pytorch md\image-20230227145913631.png)</p><p>######<strong>Pointer Network</strong></p><h5 id="Guided-Attention"><a href="#Guided-Attention" class="headerlink" title="Guided Attention"></a>Guided Attention</h5><p>强迫将输入的每个东西都学习</p><p>![image-20230227150907748](D:\人工智能\photo\pytorch md\image-20230227150907748.png)</p><h5 id="Beam-Search"><a href="#Beam-Search" class="headerlink" title="Beam Search"></a>Beam Search</h5><p>![image-20230227151307970](D:\人工智能\photo\pytorch md\image-20230227151307970.png)</p><p>![image-20230227151710565](D:\人工智能\photo\pytorch md\image-20230227151710565.png)</p><p>Beam search并不是都是结果好的，要根据任务决定，如果任务目的非常明确（语音辨识）Beam search会很有帮助，若需要一些创造（可能会有不止一个答案）随机性可能会更好。</p><p>TTS：语音合成</p><h4 id="Blue-score"><a href="#Blue-score" class="headerlink" title="Blue score"></a>Blue score</h4><p>![image-20230227152337680](D:\人工智能\photo\pytorch md\image-20230227152337680.png)</p><h4 id="Exposure-bias"><a href="#Exposure-bias" class="headerlink" title="Exposure bias"></a>Exposure bias</h4><p>![image-20230227152453643](D:\人工智能\photo\pytorch md\image-20230227152453643.png)</p><p>training是Decoder输入是正确的，但是测试时Decoder输入会有错误，为避免在Ground Truth加入一些错误。</p><h5 id="Scheduled-Sampling"><a href="#Scheduled-Sampling" class="headerlink" title="Scheduled Sampling"></a>Scheduled Sampling</h5><p>![image-20230227152656466](D:\人工智能\photo\pytorch md\image-20230227152656466.png)</p><h2 id="Generation"><a href="#Generation" class="headerlink" title="Generation"></a>Generation</h2><h2 id="Reinforcement-Learning"><a href="#Reinforcement-Learning" class="headerlink" title="Reinforcement Learning"></a>Reinforcement Learning</h2><h1 id="李沐动手深度学习"><a href="#李沐动手深度学习" class="headerlink" title="李沐动手深度学习"></a>李沐动手深度学习</h1><h2 id="Resnet-残差网络"><a href="#Resnet-残差网络" class="headerlink" title="Resnet 残差网络"></a>Resnet 残差网络</h2><p>为了提到模型预测的精度，想要提高模型的复杂度如下图左所示，但是学习产生模型偏差。Resnet设计每次更复杂的模型使包含上次模型。</p><p><img src="D:\人工智能\image-20230825155356180.png" alt="image-20230825155356180"></p><p><img src="D:\人工智能\image-20230825155510200.png" alt="image-20230825155510200"></p><p>复杂模型包含小模型。</p><p><img src="D:\人工智能\image-20230825155754620.png" alt="image-20230825155754620"></p><p><img src="D:\人工智能\image-20230825155841487.png" alt="image-20230825155841487"></p><p><img src="D:\人工智能\image-20230825160140398.png" alt="image-20230825160140398"></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2024/01/19/%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C%E7%94%A8%E8%AF%8D/"/>
    <url>/2024/01/19/%E8%AE%BA%E6%96%87%E5%86%99%E4%BD%9C%E7%94%A8%E8%AF%8D/</url>
    
    <content type="html"><![CDATA[<h1 id="论文写作用词"><a href="#论文写作用词" class="headerlink" title="论文写作用词"></a>论文写作用词</h1><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>As stated above,</p><h2 id="影响"><a href="#影响" class="headerlink" title="影响"></a>影响</h2><p><strong>has a great impact on</strong>：However, non-stationary time series has a great impact on the prediction accuracy of this method.</p><h2 id="提出"><a href="#提出" class="headerlink" title="提出"></a>提出</h2><p><strong>puts forward</strong></p><p><strong>provides a potential way for****：</strong>The Long-Short Term Memory (LSTM) deep learning model provides a potential way for nonlinear ship motions prediction due to its capability in nonlinearity processing.</p><h3 id="形容提出的方法"><a href="#形容提出的方法" class="headerlink" title="形容提出的方法"></a>形容提出的方法</h3><p><strong>Innovatively</strong>：is innovatively developed by elaborately creating</p><h3 id="设计"><a href="#设计" class="headerlink" title="设计"></a>设计</h3><p><strong>is devised to****：</strong>the Conv-1D is devised to convert 5-dimensional-input samples consisting of course angle, yaw rate, roll angle, total speed and rudder angle</p><h2 id="提出观点、sb认为"><a href="#提出观点、sb认为" class="headerlink" title="提出观点、sb认为"></a>提出观点、sb认为</h2><p>XXX argued that，</p><p>The present study proposes,</p><p>we present a data-driven approach called</p><p>More specifically,</p><p><strong>in view of</strong>：Therefore, in view of the low accuracyof ship motionprediction with the characteristics of nonstationarity, nonlinearity and randomness, this paper proposes an improved whale optimization algorithm</p><p><strong>传统的</strong></p><p>Traditional，</p><p>Conventional</p><h2 id="提出需求："><a href="#提出需求：" class="headerlink" title="提出需求："></a>提出需求：</h2><p>Design and Implementation of 设计和实现</p><p>puts forward demanding requirements for  </p><p>In order to solve the problem of 为了解决问题</p><p>n consideration of the circumstance in…environment。</p><p>for the cases in which 对于其中的情景</p><p>The strong demands from commercial, scientific and environmental communities accelerate the development of USV application</p><p>To that end，为此目的 ：To that end, Neural-Fly uses a proposed learning algorithm, </p><p>In response to this problem,</p><p>which may lead to：TCN network extracts original features without any bias, which may lead to insufficient learning for some important features;</p><h2 id="提出对比"><a href="#提出对比" class="headerlink" title="提出对比"></a>提出对比</h2><p>For a comparison,，</p><p>benchmark models 基准模型</p><p>Compared with the suboptimal model,</p><h2 id="强调重要-受到广泛研究："><a href="#强调重要-受到广泛研究：" class="headerlink" title="强调重要 受到广泛研究："></a>强调重要 受到广泛研究：</h2><p>It is inevitable to repeatedly do s.t</p><p>Play a more and more important role in..</p><p>Become a feasible solution for、</p><p>becoming more and more important in</p><p>attracted lots of attentions from worldwide researchers</p><p>attracted wide attentions of researchers from all over the world</p><p>it attracts ever increasing interest and results in a series of</p><p>which have attracted the interest of many researchers over the years.。</p><p>is a critical component in</p><p>This is crucial in</p><p>are critical to</p><p>is the essential part of marine operations for</p><p>have gained increasing prominence driven by their ability to perform</p><p>has attracted <strong>considerable</strong> research attention.</p><p>has achieved impressive results by </p><p>nontrivial：Hence, convergence to a curved path under the influence of an unknown drift force is nontrivial.</p><p><strong>It is noteworthy that:</strong></p><p><strong>… is a fundamental issue in …:</strong> Disturbance estimation is a fundamental issue in MV motion control,</p><p><strong>play a vital role as an essential means fo</strong>r</p><p><strong>is significant for</strong> operability, safety, and survivability.</p><h2 id="受到广泛研究"><a href="#受到广泛研究" class="headerlink" title="受到广泛研究"></a>受到广泛研究</h2><p>it is extensively studied in various subjects such as</p><p>has been being a long-standing hot topic</p><h3 id="新技术方法"><a href="#新技术方法" class="headerlink" title="新技术方法"></a>新技术方法</h3><p><strong>emerging</strong> intelligent control techniques</p><h2 id="目标是："><a href="#目标是：" class="headerlink" title="目标是："></a>目标是：</h2><p>this study aims to do s.t</p><p>The objective of</p><h2 id="考虑到："><a href="#考虑到：" class="headerlink" title="考虑到："></a>考虑到：</h2><p>Considering the high cost of</p><p>The model takes into account that</p><h2 id="表示普遍性"><a href="#表示普遍性" class="headerlink" title="表示普遍性"></a>表示普遍性</h2><p>Typically:</p><p>​       the ship to this reference trajectory will typically include changes in the magnitude of the forward speed.</p><p>The main rationale of</p><h3 id="强调一个模型的通用"><a href="#强调一个模型的通用" class="headerlink" title="强调一个模型的通用"></a>强调一个模型的通用</h3><p><strong>one of the most explored</strong>：The auto-regressive (AR) model is one of the most explored (Huang et al., 2014) due to its simplicity and practicability.</p><h2 id="表示稀缺性"><a href="#表示稀缺性" class="headerlink" title="表示稀缺性"></a>表示稀缺性</h2><p>has rarely been exploited by existing</p><h2 id="用。。。方式："><a href="#用。。。方式：" class="headerlink" title="用。。。方式："></a>用。。。方式：</h2><p>in the manner of</p><p>describe the state-of-the-art methods of 最新方法</p><p>The mechanism of 。。。。的机制</p><p>the most applied methods 最常用的方法</p><p>illustrate the mechanism of 阐述了…的机理</p><p>opened up a new way to solve the problem of</p><p>be adopted in 采用</p><p>resort ：Then the controller is extended to cope with the MSV yaw tracking and velocity control by resorting to the augmented backstepping technique.</p><p>A frequently used solution of the</p><p><strong>to the best of our knowledge</strong>：Unfortunately, to the best of our knowledge, practically industrial dynamics have rarely been addressed in the aforementioned works.</p><p><strong>利用</strong> <strong>leverage</strong></p><p>One solution could be to leverage self-rotation in UAVs to extend the sensor FoV without consuming extra power.</p><h2 id="做事情"><a href="#做事情" class="headerlink" title="做事情"></a>做事情</h2><p>We will dedicate effort to</p><h2 id="提出了。。。："><a href="#提出了。。。：" class="headerlink" title="提出了。。。："></a>提出了。。。：</h2><p>adopt the strategy of 采取了。。。策略</p><p>they further proposed a … approach.</p><p>It is verified that 证明了</p><p>Some representative algorithms</p><p>There are mainly three guidance methods, namely, …, …,and …</p><p>really isn’t much more than 实际上只不过是 e.g.: A node really isn’t much more than an executable file within a ROS package. </p><p>This paper investigates the problem of。。。 这篇文章探讨了。。问题</p><p><strong>解决方法</strong></p><p>solves this problem by introducing：TCN solves this problem by introducing expansion convolution to achieve exponential expansion of receptive field.</p><h2 id="因此："><a href="#因此：" class="headerlink" title="因此："></a>因此：</h2><p>Therefore</p><p>Consequently,</p><p>As such,</p><p>Thereby：For example, the value of ε in Noise Level 3 is adjusted to be nearly 10 times the value of ε in Noise Level 1, <strong>thereby</strong> ensuring the stability of the numberof SVs.</p><p>Admittedly,</p><h2 id="记住"><a href="#记住" class="headerlink" title="记住"></a>记住</h2><p>Bear in mind to … </p><h2 id="关联词："><a href="#关联词：" class="headerlink" title="关联词："></a>关联词：</h2><p>Concretely, 具体地</p><p>Subsequently</p><p>Recently,</p><p>Previously</p><p>Moreover, 此外</p><p>In addition to， 除了</p><p>Despite, 尽管</p><p>In addition,， 另外</p><p>Specifically, 特别地</p><p>In particular,</p><p>On the one hand,…., On the other hand,…</p><p>To be specific 具体而言</p><p>With regard to 至于 关于</p><p>Meanwhile, 同时，</p><p>In parallel, 同时</p><p>Nevertheless，然而</p><p>Contemporary， 当代的</p><p>Leverage. 借用</p><p>And vice versa. 反之亦然</p><p>Alternatively, 要不，或者，</p><p>i.e. 即，也就是</p><p>In other words, 换句话说，</p><p>Equivalently,   相等的</p><p>Show the flowchart of … 展示、、、流程图</p><p>Conversely, 相反地</p><p>Whereas *conj.*（表示对比）但是，然而；鉴于（用于文件的开头）：The prediction of NAF in 3-DOF motion state changes slightly as the USV moves, whereas NTF makes a prediction that the motion state of USV changes periodically.</p><p><strong>Ideally</strong>,：理想上地</p><p>First, Next , Then, Finally</p><h3 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h3><p>Lastly, 最后</p><p>Eventually,</p><h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><p>Overall，</p><p>The results demonstrate that：</p><h3 id="转折"><a href="#转折" class="headerlink" title="转折"></a>转折</h3><p>**and, on the other hand,**：it is sufficiently simple and transparent for analysis and, on the other hand, identification of its parameters is definitely a nontrivial task.</p><p><strong>It must be noticed, however, that</strong>：It must be noticed, however, that the resulting model should not be regarded as that of a Mariner type ship but rather of some realistic generic vessel.</p><h3 id="用于解释，递进"><a href="#用于解释，递进" class="headerlink" title="用于解释，递进"></a>用于解释，递进</h3><p><strong>That is to say,</strong>: 也就是说That is to say, the first 60s of datain ship movement is used as training data, and the last 20s is used as test data set.</p><p>**As the name implies,**：顾名思义，</p><p><strong>Based on … the model</strong>: Based on the TCN model, this paper puts forward the mechanism of increasing attention.</p><p><strong>In essence,</strong> </p><h4 id="逐渐、渐渐地"><a href="#逐渐、渐渐地" class="headerlink" title="逐渐、渐渐地"></a>逐渐、渐渐地</h4><p>**bit by bit,**<strong>：</strong>The Multiply layer multiplies the output of Attention and the output of the TCN network layer bit by bit, thus</p><h3 id="分别"><a href="#分别" class="headerlink" title="分别"></a>分别</h3><p>Respectively</p><p><strong>are distinguished in:</strong> In this paper, definitions of short term, middle term and long term prediction of ship mo tions are distinguished in Section 2 while Section 3 gives the various classifications of shortterm prediction techniques for ship motions.</p><h2 id="提高、提升"><a href="#提高、提升" class="headerlink" title="提高、提升"></a>提高、提升</h2><p><strong>Promote</strong>：which promote the sensitivity of the whole system by paying more attention to significant information。</p><h2 id="减少、抑制"><a href="#减少、抑制" class="headerlink" title="减少、抑制"></a>减少、抑制</h2><p><strong>Suppress</strong>：suppress the interference of noise signals.</p><h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><p>The above surveyed … all have their own advantages and disadvantages in specific application scenarios.</p><p>Optimal 最佳的</p><p>are beneficial for</p><p>advances have been achieved through</p><p>trade-off between… </p><p>a good level of ：retaina good level of agility</p><p>The benefit of this design is that</p><p>The main merits of</p><p><strong>is significant for</strong> operability, safety, and survivability.</p><h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><p>The drawback is</p><p>To adequately demonstrate the effectiveness and superiority of</p><h2 id="很多"><a href="#很多" class="headerlink" title="很多"></a>很多</h2><p>Versatile: adj. 多才多艺的，有多种技能的；多用途的，多功能的</p><p>​    <strong>are versatile means to</strong></p><p>tremendous,</p><p>a variety of</p><p>substantial</p><p><strong>extensive</strong>：extensive research</p><p>are rich in the literature and are to be reviewed in-depth in this section.</p><p>a paucity of 缺乏</p><p>in the magnitude of … 。。。的大小</p><p>substantially 大体上</p><h2 id="随着。。。发展："><a href="#随着。。。发展：" class="headerlink" title="随着。。。发展："></a>随着。。。发展：</h2><p>With the booming development of</p><p>determine the application prospect of</p><p>With recent advances in technology, …</p><p>based on the development in</p><p>With the continuous innovation of </p><p>可靠性the reliability of</p><p>下位机 its lower machine</p><p>上升和下降 ascending and descending</p><p>Endeavors 努力奋力</p><p>Since most of the time， 大多时候</p><p>Representative 典型的</p><p>the kinematic and dynamic model 运动和动力学的模型</p><p>the optimal solution 最优解</p><p>障碍物：</p><p>terrain obstacles 地形障碍物</p><p>floating obstacles    漂浮障碍物</p><p>interacts with   相互作用、与</p><p>holonomic 完全的</p><p>hierarchical 分等级的</p><h2 id="被证实"><a href="#被证实" class="headerlink" title="被证实"></a>被证实</h2><p>Is verified to …</p><p>prove to</p><h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><p>Be widely used in </p><p>Be used interchangeably 可交换使用</p><p> have great value with their ability to execute </p><h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><p><strong>dwell on</strong>：The data-driven part dwells on prediction residuals which are approximated by a least square-support vector machine.</p><h2 id="兼容的-相同的"><a href="#兼容的-相同的" class="headerlink" title="兼容的 相同的"></a>兼容的 相同的</h2><p>is fully compatible with</p><p>is identical to：The basic structure of the decoder is identical to that of the encoder.</p><p><strong>包含、包括</strong></p><p>comprises</p><h2 id="不同"><a href="#不同" class="headerlink" title="不同"></a>不同</h2><p>The difference lies in</p><p>In contrast with，相比之下</p><p>As opposed to</p><p>and vice versa 反之亦然</p><h2 id="修改"><a href="#修改" class="headerlink" title="修改"></a>修改</h2><p>Touch up</p><h2 id="危险的"><a href="#危险的" class="headerlink" title="危险的"></a>危险的</h2><p> hazardous </p><h2 id="计算"><a href="#计算" class="headerlink" title="计算"></a>计算</h2><p>Taking the time derivative of (2) along (1) yields 对(2)沿(1)求导得到的结果</p><h2 id="减少"><a href="#减少" class="headerlink" title="减少"></a>减少</h2><p>a diminished oscillatory behavior</p><p>aggravate 使加重，使恶化</p><p>degrade the performance of</p><h2 id="不可能"><a href="#不可能" class="headerlink" title="不可能"></a>不可能</h2><p>it is impractical to</p><h2 id="同样的"><a href="#同样的" class="headerlink" title="同样的"></a>同样的</h2><p>In a similarly simple way,</p><h2 id="方便的"><a href="#方便的" class="headerlink" title="方便的"></a>方便的</h2><p>Intuitive</p><p>It is trivial to 是微不足道的</p><h2 id="简单的"><a href="#简单的" class="headerlink" title="简单的"></a>简单的</h2><p>it is straightforward to</p><h2 id="最先进的"><a href="#最先进的" class="headerlink" title="最先进的"></a>最先进的</h2><p>State-of-the-art</p><p>were widely considered to represent the state of the art in 。。。</p><h1 id="英文论文写作"><a href="#英文论文写作" class="headerlink" title="英文论文写作"></a>英文论文写作</h1><p><strong>在本文</strong></p><p><strong>In the present work****，</strong>：In the present work, an input vector space optimization method is proposed based on the dependence hidden in ship motion records of a sequence.</p><h2 id="本文提及另一篇文章的方法"><a href="#本文提及另一篇文章的方法" class="headerlink" title="本文提及另一篇文章的方法"></a>本文提及另一篇文章的方法</h2><p>More details about the length optimisation and difference method can be found in (Wang and Zou, 2018). </p><p>and more details can be found in the literature (Strom-Tejsen, 1965).</p><p>The method of noise generationrefers to the literature(Sutulo and Guedes Soares, 2014), using the formula as:</p><h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p>Related work for</p><p>总结了。。。。等方向的代表性工作。</p><h2 id="介绍相关研究"><a href="#介绍相关研究" class="headerlink" title="介绍相关研究"></a>介绍相关研究</h2><p>Numerical simulations are carried out for vilification and comparison purpose.</p><p><strong>A variety of models have been attempted to****：</strong>A variety of models have been attempted to achieve real-time prediction of vessel motions.</p><p><strong>were developed based on****：</strong> Early studies on the real-time ship motions prediction were developed based on the linear ship hydrodynamic equations.</p><p>it is extensively studied in various subjects such as</p><h2 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h2><p><strong>the effect of:</strong> results and discussion are presented, the effect of the ACF function in input vector space optimization is analyzed.</p><p><strong>The detailed prediction results are analyzed as follows.</strong></p><p><strong>To adequately demonstrate the effectiveness and superiority of</strong></p><p><strong>show excellent prediction</strong></p><h3 id="想法"><a href="#想法" class="headerlink" title="想法"></a>想法</h3><p><strong>the idea of</strong>:Convolutional neural networks use the idea of weight sharing and local correlation to solve the problem of large amount of model parameters and difficult training.</p><p><strong>The motivation</strong>:The motivation is to extract the nonlinear dynamic characteristics and the hydrodynamic memory information through the advantage of CNN and LSTM, respectively.</p><h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p><strong>It can be clearly confirmed that：</strong>It can be clearly confirmed that without the memory vector, the forecasting results are remarkably different from the exact values (the hydrodynamic model-based simulation results), especially at the beginning of a time series, which indicates that the system cannot capture the physical correlations between the input and output time series (motion records and future ship motions).</p><p><strong>the prediction errors were significant, particularly for pitch motions.</strong></p><p><strong>For a more quantitative investigation</strong>,：For a more quantitative investigation, the root mean squared errors at several specific time instants are evaluated for the entire test dataset (in this test, 500 data),</p><p><strong>In the cases of</strong>：</p><h2 id="影响-1"><a href="#影响-1" class="headerlink" title="影响"></a>影响</h2><p><strong>are consequences of</strong>：The memory effects are consequences of the radiatedwaves result from the ship motions and their scattering of incident waves.</p><h2 id="每一章介绍怎么写"><a href="#每一章介绍怎么写" class="headerlink" title="每一章介绍怎么写"></a>每一章介绍怎么写</h2><h2 id="图表阐述"><a href="#图表阐述" class="headerlink" title="图表阐述"></a>图表阐述</h2><p><strong>Aesthetically</strong> 美观地</p><p><strong>Logarithmic</strong> 对数地：In order to display the data more aesthetically, the logarithmic coordinate axis is used in Fig. 11.</p><p><strong>Intuitively****：</strong>直觉地、易懂地：The prediction effect of the three models can be more intuitively displayed by comparing the RMSE of ship motion response in Fig. 13.</p><p><strong>generally</strong>:It can be seen from Table 3 that the performance of the hybrid network is generally better than that of the GRU neural network model and the traditional model.</p><p><strong>In order to conveniently show the difference between different models and Model A,</strong></p><p>s<strong>hows the absolute value of the deviation between</strong> the predicted ship roll value and the real ship roll value of the six modelsat each sampling time, denoted by Error &#x3D; |yreal-ypre|.</p><p><strong>the overall similarity</strong>:the Error curve of LSTM is mainly in the range of (0,0.2), which shows the overall similarity compared with the Error curve of ARIMA model.</p><h2 id="进行实验"><a href="#进行实验" class="headerlink" title="进行实验"></a>进行实验</h2><p>Numerical simulations are carried out for vilification and comparison purpose.</p><p>In order to verify our conclusion, </p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p><strong>The results show that</strong> : The results show that the method of online modeling and prediction of MASS under ocean waves proposed in this paper is effective</p><p><strong>The results demonstrate that</strong>：The results demonstrate that the identified model has good generalisation, verifying the robustness and efficiency of the algorithm.</p><p><strong>The simulation experiment shows that</strong>：The simulation experiment shows that IWOA-TCN-Attention model can effectively realize the prediction of ship motion, reduce the error of motion prediction and improve the prediction accuracy.</p><p><strong>the following conclusions can be drawn</strong>.</p><p><strong>in line with our conclusion</strong>: The new calculation results are in line with our conclusions.</p><p><strong>For a more quantitative investigation, :</strong> For a more quantitative investigation, the root mean squared errors at several specific time instants are evaluated for the entire test dataset.</p><p><strong>For a more quantitative analysis of****：</strong>Forfr a more quantitative analysis of the prediction performance according to the input motion record, the total mean squared errors (the average value for the entire window and the whole test dataset) were compared for different record lengths as shown</p><h2 id="文章观点总结"><a href="#文章观点总结" class="headerlink" title="文章观点总结"></a>文章观点总结</h2><p><strong>the immediate goal of the present study was demonstration of</strong>：the immediate goal of the present study was demonstration of the consistency of the method and selection of the best metric.</p><p><strong>is versatile.</strong> The IWOA-TCN-Attention prediction model proposed in this paper is versatile.</p><p><strong>To sum up</strong>, 综上所述</p><p>and the following conclusions can be drawn：</p><h2 id="说明-解释"><a href="#说明-解释" class="headerlink" title="说明\解释"></a>说明\解释</h2><p>**which will be discussed and specified later;**：C is a constant observation matrix of appropriate dimensions which will be discussed and specified later;</p><p><strong>It can be inferred that</strong>：It can be inferred that the memory effects of past roll motions are greater than those of other motion modes.</p><h2 id="结论阐述"><a href="#结论阐述" class="headerlink" title="结论阐述"></a>结论阐述</h2><p><strong>It can be clearly confirmed that</strong>：It can be clearly confirmed that without the memory vector, the forecasting results are remarkably different from the exact values.</p><p><strong>The testing results demonstrate</strong>：The testing results demonstrate that it is valid to set the record length to 30.0 s in the present model.</p><h1 id="英语语法"><a href="#英语语法" class="headerlink" title="英语语法"></a>英语语法</h1><h2 id="定语从句"><a href="#定语从句" class="headerlink" title="定语从句"></a>定语从句</h2><p>定语从句是英语中的一个重要语法概念，用于修饰名词或代词，提供更详细的信息或描述。定语从句通常由关系代词（如that, which, who, whom, whose）或关系副词（如when, where, why）引导，它们在从句中担任特定的语法功能。</p><p>以下是定语从句的一些基本要点和示例：</p><ol><li><p><strong>关系代词</strong>：</p></li><li><ul><li><p><strong>that</strong> 和 <strong>which</strong> 用于修饰事物。</p></li><li><ul><li>示例：The book <strong>that</strong> I bought yesterday is very       interesting.（我昨天买的那本书很有趣。）</li><li>注意：在限制性定语从句中，如果先行词是不定代词（如all, everything, something, nothing等）或先行词被序数词、最高级、the only, the very等修饰时，通常使用that。</li></ul></li><li><p><strong>who</strong> 和 <strong>whom</strong> 用于修饰人。</p></li><li><ul><li>示例：The man <strong>who</strong> spoke to me was my teacher.（和我说话的那个人是我的老师。）</li><li>注意：在口语和非正式书面语中，有时可以用that或which代替who或whom。</li></ul></li><li><p><strong>whose</strong> 用于表示所有关系。</p></li><li><ul><li>示例：The girl <strong>whose</strong> car was stolen called the police.（车被偷的那个女孩报了警。）</li></ul></li></ul></li><li><p><strong>关系副词</strong>：</p></li><li><ul><li><p><strong>when</strong> 用于表示时间。</p></li><li><ul><li>示例：I remember the day <strong>when</strong> we first met.（我记得我们第一次见面的那天。）</li></ul></li><li><p><strong>where</strong> 用于表示地点。</p></li><li><ul><li>示例：This is the place <strong>where</strong> I grew up.（这是我成长的地方。）</li></ul></li><li><p><strong>why</strong> 用于表示原因（较少见，通常可以用that或for which替代）。</p></li><li><ul><li>示例：I don’t know the reason <strong>why</strong> he is late.（我不知道他为什么迟到。）</li></ul></li></ul></li><li><p><strong>限制性定语从句与非限制性定语从句</strong>：</p></li><li><ul><li><strong>限制性定语从句</strong>提供必要的信息，没有它，句子的意义就不完整。限制性定语从句与主句之间没有逗号分隔。</li><li><strong>非限制性定语从句</strong>提供额外的信息，没有它，句子的基本意义仍然完整。非限制性定语从句与主句之间有逗号分隔。</li></ul></li><li><p><strong>省略关系代词的情况</strong>：</p></li><li><ul><li>在某些情况下，尤其是非正式场合，关系代词可以被省略，特别是当定语从句很短且关系代词在从句中担任宾语时。</li><li>示例：I like movies (that) you recommended.（我喜欢你推荐的电影。）</li></ul></li></ol><p>掌握定语从句的关键在于理解关系代词和关系副词的作用，以及它们在句子中的语法功能。通过多读多写，你可以逐渐熟悉并熟练使用定语从句。</p><h3 id="限制性定语从句"><a href="#限制性定语从句" class="headerlink" title="限制性定语从句"></a>限制性定语从句</h3><p>限制性定语从句提供了对名词或代词的必要信息，使得句子的意义更加明确和具体。限制性定语从句与它所修饰的名词或代词紧密相连，不能省略，否则句子的意思会变得不完整或模糊。限制性定语从句与主句之间通常没有逗号分隔。</p><p>例如：</p><ul><li>The book <strong>that     I read last night</strong> was very interesting.（我昨晚读的那本书很有趣。）</li></ul><p>在这个例子中，“that I read last night”是一个限制性定语从句，它限定了“the book”的具体内容，即“我昨晚读的那本”。如果我们去掉这个定语从句，句子的意思就会变得不明确。</p><h3 id="非限制性定语从句"><a href="#非限制性定语从句" class="headerlink" title="非限制性定语从句"></a>非限制性定语从句</h3><p>非限制性定语从句提供了关于名词或代词的额外信息，但并不限制其意义。非限制性定语从句与主句之间通常用逗号分隔，即使去掉非限制性定语从句，主句的意思仍然完整。非限制性定语从句主要用于补充、解释或附加说明主句的内容。</p><p>例如：</p><ul><li>My house, <strong>which     was built in the 1950s</strong>, is in need of repair.（我的房子，建于20世纪50年代，需要修理。）</li></ul><p>在这个例子中，“which was built in the 1950s”是一个非限制性定语从句，它提供了关于“my house”的额外信息，但并不限制“my house”的含义。即使我们去掉这个定语从句，句子的基本意思——“我的房子需要修理”——仍然是完整的。</p><h3 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a>总结</h3><ul><li><strong>限制性定语从句</strong>：提供必要信息，不能省略，没有逗号分隔，限定名词或代词的具体含义。</li><li><strong>非限制性定语从句</strong>：提供额外信息，可以省略，有逗号分隔，不限制名词或代词的含义。</li></ul><p>理解限制性定语从句和非限制性定语从句的区别对于正确使用定语从句和构建清晰、准确的句子非常重要。通过多读多写，你可以逐渐熟悉并掌握这两种定语从句的用法</p><h1 id="船舶"><a href="#船舶" class="headerlink" title="船舶"></a>船舶</h1><p>stable course tracking of 稳定的航向跟踪</p><p>the lateral thruster 侧推</p><p>steering system 转向系统</p><p>autonomous</p><p>surface vehicles (ASVs), </p><p>autonomous underwater vehicles(AUVs), </p><p>autonomous wave gliders,</p><p>autonomous sailboats,</p><p>mimics the actions of a helmsman</p><p>a temporal constraint 时间约束</p><p>is defined in Cartesian coordinates，定义在笛卡尔坐标系下</p><p><strong>steering the ship</strong>    <strong>驾驶船舶</strong></p><p>acceleration and retardation 加速和减速</p><h2 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h2><p>maritime operational safety and efficiency.</p><p>is essential in decision-making when performing motions sensitive activities.</p><h1 id="水"><a href="#水" class="headerlink" title="水"></a>水</h1><p>Riparian adj. 河边的；水滨的</p><h1 id="人工智能"><a href="#人工智能" class="headerlink" title="人工智能"></a>人工智能</h1><p>the generalization capability 泛化能力</p><p>benchmark models 基准模型</p><h2 id="模型效果"><a href="#模型效果" class="headerlink" title="模型效果"></a>模型效果</h2><p>performs better in both training efficiency and prediction accuracy.</p><h2 id="模型的进步"><a href="#模型的进步" class="headerlink" title="模型的进步"></a>模型的进步</h2><p><strong>highlight the essential features in data and reduce the influence of unimportant features to speed up the model’s training speed and prediction accuracy</strong></p><h2 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h2><p>The model consists of the input layer, TCN network layer, Attention mechanism, and output layer.</p><p><strong>输入</strong></p><p>The input of this layer is the output vector of</p><h1 id="环境干扰长句积累"><a href="#环境干扰长句积累" class="headerlink" title="环境干扰长句积累"></a>环境干扰长句积累</h1><p>The operation performance of marine vehicles is significantly vulnerable to external disturbances induced by wind, waves, and ocean currents in complex marine environments. </p><h1 id="中文论文写作"><a href="#中文论文写作" class="headerlink" title="中文论文写作"></a>中文论文写作</h1><p>目前In particular, digital services based on short-term deterministic future estimates for ocean environments and the hydrodynamic (HD) performances of the ship can support the operator’s decision-making for immediate navigation which can avoid any sudden risk or failure, such as excessive motions, structural damage, cargo loss, and capsizing. T…主要集中于…</p><p>为了克服定点浮标和载人监测船的 缺陷，减少对监测系统的投入，扩大探测范围，提高系统的智能化水平，提高监 测站的性能和探测投资的经济效益，实现智能化、自动化、低成本的大区域海洋 水面环境资源的可靠监测，有必要开发一种，，，</p><p>针对。。。等问题展开了研究。提出了以。。。，实现了。。。。通过海试验证了。。。能力，成功实现了。。。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2023/12/28/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/"/>
    <url>/2023/12/28/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/</url>
    
    <content type="html"><![CDATA[<h1 id="时间序列"><a href="#时间序列" class="headerlink" title="时间序列"></a>时间序列</h1><p>  在时间序列中，按时间顺序排列的数据在一个特定的列中，该列通常表示为时间戳、日期或时间。</p><p>时间序列主要由：长期运动或趋势、季节性短期运动、周期性短期运动、随机或不规则波动。</p><p>时间序列预测是一种通过一系列时间，通过研究过去现象的行为和表现，并假设未来的事件将与历史趋势和行为相似从而进行预测的方法。</p><p><strong>机器学习</strong></p><p>机器学习主要有三类：监督学习（分类和回归等）、无监督学习（聚类分析、异常监测和主成分分析）、强化学习（决策）</p><p>时间序列数据可以表示为监督学习问题：数据科学家通常利用先前的时间步并用作输入，然后利用下一个时间步作为模型的输出，将其时间序列数据集转换为监督学习问题。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1]时间序列预测 基于机器学习和Python实现 佛朗西斯卡·拉泽里 ISBN978-7-111-69746-6</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>相关学习链接</title>
    <link href="/2023/12/22/%E7%9B%B8%E5%85%B3%E5%AD%A6%E4%B9%A0%E8%BF%9E%E6%8E%A5/"/>
    <url>/2023/12/22/%E7%9B%B8%E5%85%B3%E5%AD%A6%E4%B9%A0%E8%BF%9E%E6%8E%A5/</url>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><h1 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h1><p><a href="https://numpy.org.cn/">Numpy</a></p><h1 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h1><p><a href="https://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling">scikit_learn</a></p><h2 id="Pytorch"><a href="#Pytorch" class="headerlink" title="Pytorch"></a>Pytorch</h2><p><a href="https://pytorch.org/docs/stable/index.html">Pytorch官网手册</a><br><a href="https://speech.ee.ntu.edu.tw/~hylee/ml/2021-spring.php">李宏毅2021 Spring</a><br><a href="https://enzo-miman.github.io/#/README">Enzo 课件</a><br><a href="https://www.cnblogs.com/nickchen121/p/15105048.html">水论文程序猿</a><br><a href="https://blog.csdn.net/qq_33746593/article/details/107202590">位置编码与注意力机制</a></p><p><a href="https://zh-v2.d2l.ai/">《动手学深度学习》 — 动手学深度学习 2.0.0 documentation (d2l.ai)</a></p><p><a href="https://space.bilibili.com/1567748478">跟李沐学AI的个人空间-跟李沐学AI个人主页-哔哩哔哩视频 (bilibili.com)</a></p><p><a href="https://zhuanlan.zhihu.com/p/95368411">pytorch必须掌握的4种边界Padding方法 - 知乎 (zhihu.com)</a></p><p><a href="https://allenwind.github.io/blog/8912/">Embedding层讲解</a></p><h3 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h3><p><a href="https://kazemnejad.com/blog/transformer_architecture_positional_encoding/#proposed-method">T one</a><br><a href="https://nlp.seas.harvard.edu/2018/04/03/attention.html#model-architecture">T 2</a><br><a href="https://zhuanlan.zhihu.com/p/403433120">T 3</a></p><p>[一文教你彻底理解Transformer中Positional Encoding - 知乎 (zhihu.com)](<a href="https://zhuanlan.zhihu.com/p/338592312#%E6%80%8E%E4%B9%88%E6%A0%B7%E5%8E%BB%E5%81%9Apositional">https://zhuanlan.zhihu.com/p/338592312#怎么样去做positional</a> Encoding？)</p><h3 id="强化学习"><a href="#强化学习" class="headerlink" title="强化学习"></a>强化学习</h3><p><a href="https://github.com/xccds/Ten_Minute_RL">xccds&#x2F;Ten_Minute_RL (github.com)</a></p><h2 id="Logging"><a href="#Logging" class="headerlink" title="Logging"></a>Logging</h2><p><a href="https://mp.weixin.qq.com/s/9_gb7Fv8FKvYtjBSOev9Ag">30分钟吃掉wandb模型训练可视化 (qq.com)</a></p><p><a href="https://docs.wandb.ai/guides/sweeps/sweep-config-keys#early_terminate">Sweep configuration options | Weights &amp; Biases Documentation (wandb.ai)</a></p><h1 id="网站博客搭建"><a href="#网站博客搭建" class="headerlink" title="网站博客搭建"></a>网站博客搭建</h1><p><a href="https://zhuanlan.zhihu.com/p/547520780?utm_id=0">Hexo搭建</a></p><p><a href="https://blog.csdn.net/K1052176873/article/details/122879462">Hexo 多机</a></p><p><a href="https://zhuanlan.zhihu.com/p/265077468">hexo博客如何插入图片</a></p><p>Windows命令行进入对应文件路径：</p><p><strong>C:\WINDOWS\system32&gt;D:</strong></p><p><em><strong>D:&gt;cd BBlog</strong></em></p><p><code>hexo clean</code> 删除 public 文件夹，即删除旧的博客文章</p><p><code>hexo g</code> 生成 public 文件夹，即生成新的博客文章相关 html 文件</p><p><code>hexo d</code> 将博客推送到 github</p><p>补充：后续写文章、修改配置后的保存推送操作</p><p>至此，网站部署至master分支，整个网站备份至hexo分支。当网站的配置或文章修改后都要将远程仓库更新。首先，依次执行<br>‘’’git add .<code>git commit -m ChangeFiles（更新信息内容可改)</code>git push （或者git push origin hexo)’’’<br>保证hexo分支版本最新。然后执行<br>‘’’hexo d -g’’’</p><h1 id="控制"><a href="#控制" class="headerlink" title="控制"></a>控制</h1><p><a href="https://www.zhihu.com/question/25347270">(45 封私信 &#x2F; 80 条消息) 想学习自适应控制、滑模控制、模糊控制、鲁棒控制，如何打下基石，该看些什么书？ - 知乎 (zhihu.com)</a></p><h1 id="机器人"><a href="#机器人" class="headerlink" title="机器人"></a>机器人</h1><p><a href="https://www.zhihu.com/question/61879863/answer/3336818984">(33 封私信 &#x2F; 32 条消息) 学习机器人运动学，动力学需要哪些数学基础课程？ - 知乎 (zhihu.com)</a></p><p><a href="https://ww2.mathworks.cn/campaigns/offers/next/getting-started-with-motion-planning-in-matlab-ebook.html?s_v1=55087&elqem=4398968_EM_CN_DIR_24-06_MOE-CG&elqTrackId=6bd354b4164d420abc2a42769ff7130b&elq=bbea92b2272a4984b74afc7fdcb53a20&elqaid=55087&elqat=1&elqCampaignId=20978">使用 MATLAB 进行运动规划 - MATLAB &amp; Simulink (mathworks.cn)</a></p><h2 id="海洋机器人"><a href="#海洋机器人" class="headerlink" title="海洋机器人"></a>海洋机器人</h2><h2 id="资料网站"><a href="#资料网站" class="headerlink" title="资料网站"></a>资料网站</h2><p>(<a href="https://zh.z-library.se/">Z-Library – 世界上最大的电子图书馆。自由访问知识和文化。</a>)</p><p>(<a href="https://www.tboxn.com/#term-80">Tbox导航 | 只收录优质在线工具的导航网站 (tboxn.com)</a>)</p><p><a href="https://zotero-chinese.github.io/zotero-plugins/#/">Zotero 插件商店 - Zotero 中文社区 (zotero-chinese.github.io)</a></p><p><a href="https://www.emojiall.com/zh-hans">Emoji大全 | Emoji表情符号词典 📓 | EmojiAll中文官方网站</a></p><h1 id="期刊会议"><a href="#期刊会议" class="headerlink" title="期刊会议"></a>期刊会议</h1><p><a href="https://zhuanlan.zhihu.com/p/585191008">盘点一下，人工智能顶刊顶会有哪些？ - 知乎 (zhihu.com)</a></p><h2 id="人工智能会议"><a href="#人工智能会议" class="headerlink" title="人工智能会议"></a>人工智能会议</h2><p><a href="https://blog.csdn.net/zffustb/article/details/114916952">部分计算机会议和期刊论文的下载方法_acm论文下载-CSDN博客</a></p><p><a href="https://aaai.org/aaai-publications/aaai-conference-proceedings/">AAAI Conference Proceedings - AAAI</a></p><h2 id="机器人会议"><a href="#机器人会议" class="headerlink" title="机器人会议"></a>机器人会议</h2><p><a href="https://ieeexplore.ieee.org/xpl/conhome/1000393/all-proceedings">IROS</a></p><h2 id="科研网页"><a href="#科研网页" class="headerlink" title="科研网页"></a>科研网页</h2><p><a href="https://www.fossen.biz/publications/">Publication Database (fossen.biz)</a></p><p><a href="https://www.webofscience.com/wos/author/record/652943">彭周华 Web of Science</a></p><p><a href="https://www.webofscience.com/wos/author/record/1877572">古楠 - Web of Science </a></p><p><a href="https://www.webofscience.com/wos/author/record/1821774">王宁 - Web of Science</a></p><p><a href="https://www.webofscience.com/wos/author/record/1017232">向先波 - Web of Science</a></p><p><a href="https://www.webofscience.com/wos/author/record/396948">严新平 - Web of Science</a></p><p><a href="https://www.webofscience.com/wos/author/record/217990">张海涛 - Web of Science</a></p><p><a href="https://www.webofscience.com/wos/author/record/2191269">马勇 - Web of Science</a></p><p><a href="https://www.webofscience.com/wos/author/record/420875">柳晨光 - Web of Science</a></p><p><a href="https://webofscience.clarivate.cn/wos/author/record/54691349">王宏东 - Web of Science)</a></p><h1 id="科研工具"><a href="#科研工具" class="headerlink" title="科研工具"></a>科研工具</h1><h2 id="Origin"><a href="#Origin" class="headerlink" title="Origin"></a>Origin</h2><p>【Origin科研绘图超快速上手指南】<a href="https://www.bilibili.com/video/BV1BA411i7PT?vd_source=2ec9cc7a2d133f3a19434aaf945dabd6">https://www.bilibili.com/video/BV1BA411i7PT?vd_source=2ec9cc7a2d133f3a19434aaf945dabd6</a></p><p><img src="/%E7%9B%B8%E5%85%B3%E5%AD%A6%E4%B9%A0%E8%BF%9E%E6%8E%A5/image-20240229194903383.png" alt="image-20240229194903383"></p><p><a href="https://www.zhihu.com/question/525797309">(46 封私信 &#x2F; 80 条消息) 为什么我的origin图标绘制不显示book数据 ？ - 知乎 (zhihu.com)</a></p><p>[Origin学会粘贴格式，告别重复排版！-王飞的博客嘿嘿 (upcwangfei.com)](<a href="https://www.upcwangfei.com/original-article/2021/04/20/1162/#:~:text=Origin%E5%AD%A6%E4%BC%9A%E7%B2%98%E8%B4%B4%E6%A0%BC%E5%BC%8F%EF%BC%8C%E5%91%8A%E5%88%AB%E9%87%8D%E5%A4%8D%E6%8E%92%E7%89%88%EF%BC%81">https://www.upcwangfei.com/original-article/2021/04/20/1162/#:~:text=Origin学会粘贴格式，告别重复排版！</a> 1 01、在调整好格式的图上方鼠标右键选择[复制格式]-[所有格样式式]。 2 02、在需要调整格式的图上方鼠标右键点击（注意，鼠标左键不要点击）选择[粘贴格式]。 3 03、这样，瞬间就设置好了图的格式，非常快速！ 动图演示,求关注！ 小号防丢 关注一波 公众号的自动回复快到上限了 为了能够发布资源 关注下备用号嘿~~ 原文始发于微信公众号（大飞鸽软件助手）： Origin学会粘贴格式，告别重复排版！)</p><h2 id="Latex"><a href="#Latex" class="headerlink" title="Latex"></a>Latex</h2><p><a href="https://zhuanlan.zhihu.com/p/464237097">【LaTeX应用】常用数学公式和符号 - 知乎 (zhihu.com)</a></p><h1 id="计算机基础"><a href="#计算机基础" class="headerlink" title="计算机基础"></a>计算机基础</h1><p>[U盘启动盘还原的方法_u盘设置u盘启动怎么还原-CSDN博客](<a href="https://blog.csdn.net/weixin_45305215/article/details/126067988#:~:text=U%E7%9B%98%E5%90%AF%E5%8A%A8%E7%9B%98%E8%BF%98%E5%8E%9F%E7%9A%84%E6%96%B9%E6%B3%95">https://blog.csdn.net/weixin_45305215/article/details/126067988#:~:text=U盘启动盘还原的方法</a> 1 1、先将u盘插入到电脑，然后在电脑上按下win%2Br快捷键打开运行菜单，输入”cmd”回车确定打开命令提示符页面。 2 2、 然后在命令提示符输入”diskpart”回车确定。 3 3、,后面输几，比如这里是1。 6 6、选择磁盘1，也就是u盘后，在DISKPART&gt;右侧继续输入命令”clean”回车确认，这样就会清除u盘信息。 7 7、然后可以在磁盘管理界面看见u盘变成了一个未分配的磁盘了。 8 8、鼠标右键单击未分配的磁盘空间，选择新建简单卷。 更多项目)</p><p><a href="https://xujinzh.github.io/page/2/#content-inner">https://xujinzh.github.io/page/2/#content-inner</a></p><p><a href="https://www.bilibili.com/read/cv16202697/">https://www.bilibili.com/read/cv16202697/</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>Learning Link</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
